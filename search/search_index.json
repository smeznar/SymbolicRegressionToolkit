{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#srtoolkit-symbolic-regression-equation-discovery-benchmark-toolkit","title":"SRToolkit: Symbolic Regression / Equation Discovery Benchmark Toolkit","text":"<p>Documentation:: https://smeznar.github.io/SymbolicRegressionToolkit</p>"},{"location":"#what-is-srtoolkit","title":"What is SRToolkit?","text":"<p>The SRToolkit is a comprehensive Python toolkit designed to accelerate research and development in  Symbolic Regression (SR) / Equation Discovery (ED). It provides a robust, easy-to-use framework for  benchmarking, rapid prototyping, and mathematical expression manipulation.</p>"},{"location":"#core-features","title":"Core Features","text":"<p>SRToolkit provides a straightforward interface for:</p> <ul> <li> <p>Benchmarking Symbolic Regression algorithms using built-in datasets (currently Feynman and Nguyen) or custom data.</p> </li> <li> <p>Converting expressions into expression trees or fast, callable NumPy functions.</p> </li> <li> <p>Generating random expressions by defining the symbol space or a grammar.</p> </li> <li> <p>Estimating constant parameters of expressions against real-world data.</p> </li> <li> <p>Comparing and measuring the distance between expressions.</p> </li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>To install the latest stable release of the package, run the following command in your terminal: <pre><code>pip install symbolic-regression-toolkit\n</code></pre></p> <p>Alternatively, you can install the latest build directly from the repository with the command:</p> <pre><code>pip install git+https://github.com/smeznar/SymbolicRegressionToolkit\n</code></pre>"},{"location":"#examples","title":"Examples","text":""},{"location":"#1-expression-manipulation-the-toolkit-core","title":"1. Expression Manipulation (The Toolkit Core)","text":"<p>SRToolkit offers fundamental utilities for working with mathematical expressions as tokens, trees, and executable code\u2014the building blocks for any SR approach.</p> <pre><code>import numpy as np\nfrom SRToolkit.utils import expr_to_executable_function, tokens_to_tree, SymbolLibrary, expr_to_latex\n\n# Create an executable function from the expression\nexpr = expr_to_executable_function([\"X_0\", \"+\", \"X_1\", \"*\", \"C\"])\n\n# Calculate the output at two points (1, 2) and (2, 5) with C=3\ndata_points = np.array([[1, 2], [2, 5]])\nconstants = [3]\noutput = expr(data_points, constants)\n# Variable \"output\" should now contain np.array([7, 17])\n\n# Create a SymbolLibrary defining the symbol space for 2 variables\nsl = SymbolLibrary.default_symbols(num_variables=2)\n\n# Create an expression tree from the token list\nexpr_tree = tokens_to_tree([\"X_0\", \"+\", \"X_1\", \"*\", \"C\"], sl)\n\n# Transform the expression into a list of symbols in postfix notation\npostfix_expr = expr_tree.to_list(notation=\"postfix\")\n\n# Create a LaTeX string of the expression for clear presentation\nexpr_latex = expr_to_latex(expr_tree, sl)\n</code></pre>"},{"location":"#2-benchmarking-and-evaluation-the-main-use-case","title":"2. Benchmarking and Evaluation (The Main Use Case)","text":"<p>The primary advantage of SRToolkit is its robust benchmarking framework, allowing you to quickly evaluate and compare different Symbolic Regression approaches.</p> <pre><code>from SRToolkit.dataset import SR_benchmark\nfrom SRToolkit.utils import generate_n_expressions\n\n# Create the Feynman benchmark suite\nfeynman = SR_benchmark.feynman(\"./data/feynman\")\n\n# List datasets in the benchmark and select the first 2-variable one\ndataset_name = feynman.list_datasets(verbose=False, num_variables=2)[0]\n\n# Create the dataset and the dedicated evaluator object\ndataset = feynman.create_dataset(dataset_name)\nevaluator = dataset.create_evaluator()\n\n# Generate 100 random expressions for a baseline evaluation\nexpressions = generate_n_expressions(dataset.symbol_library, 100)\n\n# Evaluate the expressions and print their error\nfor expr in expressions:\n    rmse = evaluator.evaluate_expr(expr)\n    print(f\"Expr: {''.join(expr)}, Error: {rmse}\")\n\n# Get structured results of the evaluation, focusing on the 20 best expressions\nresults = evaluator.get_results(top_k=20)\n</code></pre> <p>Additional examples can be found in the <code>examples</code> folder or in the official documentation.</p>"},{"location":"#roadmap","title":"Roadmap \ud83d\uddfa\ufe0f","text":"<p>In future releases, our primary focus will be on benchmarking and comparability:</p> <ul> <li> <p>Benchmarking Core: Add the ability to save/load benchmark runs and automatically evaluate multiple ED/SR approaches.</p> </li> <li> <p>SR Library: Create a library of easy-to-use and comparable ED/SR approach implementations.</p> </li> <li> <p>Advanced Expressions (Distant Plan): Implement support for different types of expressions, such as ODEs and PDEs.</p> </li> <li> <p>Constraints: Implement more robust expression generation constraints using techniques like attribute grammars.</p> </li> </ul>"},{"location":"#contributing","title":"Contributing \ud83e\udd1d","text":"<p>We welcome contributions! Whether you're adding a new benchmark, implementing an SR approach, fixing a bug, or improving the documentation, please feel free to submit a Pull Request (PR) with a clear description of your changes.</p> <p>We are especially looking for contributions of:</p> <ul> <li> <p>New Benchmarks and Datasets (e.g., datasets from physics, finance, etc.).</p> </li> <li> <p>Implementations of additional Symbolic Regression Approaches (once the core framework for comparison is finalized).</p> </li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#symbolicregressiontoolkit-140-2025-10-28","title":"SymbolicRegressionToolkit-1.4.0 (2025-10-28)","text":"<ul> <li>Updated documentation</li> <li>Rewrote the SR_dataset and SR_benchmark classes</li> <li>New readme and logo</li> </ul> <p>New Features:</p> <ul> <li>Added ResultAugmenter to augment result of evaluation with additional measures, simplification of best expressions, etc.</li> <li>Added distance measures</li> <li>Added BED as a possible ranking measure for evaluation</li> </ul>"},{"location":"changelog/#symbolicregressiontoolkit-132-2025-07-07","title":"SymbolicRegressionToolkit-1.3.2 (2025-07-07)","text":"<ul> <li>Updated documentation</li> </ul> <p>New Feature:</p> <ul> <li>Added a way to generate expressions</li> <li>Expression simplification now more or less works</li> </ul> <p>Bug Fixes:</p> <ul> <li>Feynman dataset and Nguyen datasets are now almost done</li> <li>Small fixes to different functionalities</li> </ul>"},{"location":"changelog/#symbolicregressiontoolkit-126-2025-04-26","title":"SymbolicRegressionToolkit-1.2.6 (2025-04-26)","text":"<ul> <li>Updated documentation</li> <li>Added the change log</li> </ul> <p>New Features:</p> <ul> <li>Expressions can now be transformed into latex code</li> <li>Added Dataset and benchmark objects that create evaluators for Symbolic Regression models</li> <li>Added modified versions of feynman and nguyen benchmarks</li> </ul> <p>Bug Fixes:</p> <ul> <li>Fixed expressions with constants only evaluating to one value instead of an array</li> </ul>"},{"location":"changelog/#symbolicregressiontoolkit-110-2024-12-10","title":"SymbolicRegressionToolkit-1.1.0 (2024-12-10)","text":"<ul> <li>Project restructure</li> </ul> <p>New Features:</p> <ul> <li>Added documentation</li> <li>Expanded upon examples</li> </ul>"},{"location":"changelog/#symbolicregressiontoolkit-100-2024-12-06","title":"SymbolicRegressionToolkit-1.0.0 (2024-12-06)","text":"<ul> <li>Initial release</li> <li>Expression compilation</li> <li>Parameter estimation</li> <li>Model evaluation</li> <li>Examples for parameter estimation and performance evaluation</li> </ul>"},{"location":"references/","title":"Symbolic Regression Toolkit Module","text":""},{"location":"references/#SRToolkit","title":"SRToolkit","text":"<p>Symbolic Regression Toolkit</p> <p>This package provides a Python-based toolkit for equation discovery/symbolic regression.</p> <p>Modules:</p> Name Description <code>dataset</code> <p>The module containing classes for working with Datasets and Benchmarks.</p> <code>utils</code> <p>The module containing utility classes and functions.</p> <code>evaluation</code> <p>The module containing classes and functions for estimating parameters and evaluating Symbolic Regression models.</p>"},{"location":"references/approaches/","title":"Approaches Submodule","text":""},{"location":"references/approaches/#SRToolkit.approaches","title":"SRToolkit.approaches","text":"<p>This module contains implementations of symbolic regression approaches. Class SR_approach is the base class for all symbolic regression approaches.</p> <p>Modules:</p> Name Description <code>sr_approach</code> <p>The base class for all symbolic regression approaches.</p> <code>ProGED</code> <p>The ProGED approach - Probabilistic grammar-based equation discovery.</p>"},{"location":"references/approaches/#SRToolkit.approaches.SR_approach","title":"SR_approach","text":"<pre><code>SR_approach(name: str)\n</code></pre> <p>The base class for all symbolic regression approaches. Any symbolic regression approach should inherit from this class.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the approach.</p> required Source code in <code>SRToolkit/approaches/sr_approach.py</code> <pre><code>def __init__(self, name: str):\n    \"\"\"\n    The base class for all symbolic regression approaches. Any symbolic regression approach should inherit from\n    this class.\n\n    Args:\n        name: The name of the approach.\n    \"\"\"\n    self.name = name\n</code></pre>"},{"location":"references/approaches/#SRToolkit.approaches.SR_approach.search","title":"search","text":"<pre><code>search(sr_evaluator: SR_evaluator, seed: Optional[int] = None)\n</code></pre> <p>Run the symbolic regression search.</p> <p>Implementations should use the provided evaluator to score generated expressions. All evaluation results are stored inside <code>sr_evaluator</code>, so nothing is returned.</p> <p>Parameters:</p> Name Type Description Default <code>sr_evaluator</code> <code>SR_evaluator</code> <p>Evaluator used for scoring expressions.</p> required <code>seed</code> <code>Optional[int]</code> <p>Random seed used for generating expressions.</p> <code>None</code> Source code in <code>SRToolkit/approaches/sr_approach.py</code> <pre><code>def search(self, sr_evaluator: SR_evaluator, seed: Optional[int] = None):\n    \"\"\"\n    Run the symbolic regression search.\n\n    Implementations should use the provided evaluator to score generated expressions.\n    All evaluation results are stored inside `sr_evaluator`, so nothing is returned.\n\n    Args:\n        sr_evaluator: Evaluator used for scoring expressions.\n        seed: Random seed used for generating expressions.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"references/approaches/#SRToolkit.approaches.SR_approach.clone","title":"clone","text":"<pre><code>clone() -&gt; SR_approach\n</code></pre> <p>Clones the SR_approach instance. This is used to make multiple independent copies of the approach and making multiple independent evaluations/parallel evaluations of the approach possible. If the approach is stateless, returning self is sufficient, otherwise a deep copy of the approach should be returned. This allows us to do pretraining and finetuning of the approach independently.</p> Source code in <code>SRToolkit/approaches/sr_approach.py</code> <pre><code>def clone(self) -&gt; \"SR_approach\":\n    \"\"\"\n    Clones the SR_approach instance. This is used to make multiple independent copies of the approach and making\n    multiple independent evaluations/parallel evaluations of the approach possible. If the approach is stateless,\n    returning self is sufficient, otherwise a deep copy of the approach should be returned. This allows us to do\n    pretraining and finetuning of the approach independently.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"references/approaches/ProGED/","title":"ProGED","text":""},{"location":"references/approaches/ProGED/#SRToolkit.approaches.ProGED","title":"SRToolkit.approaches.ProGED","text":"<p>This module contains the ProGED approach - Probabilistic grammar-based equation discovery.</p>"},{"location":"references/approaches/ProGED/#SRToolkit.approaches.ProGED.ProGED","title":"ProGED","text":"<pre><code>ProGED(grammar: Union[str, SymbolLibrary], verbose: bool = False)\n</code></pre> <p>               Bases: <code>SR_approach</code></p> <p>A slimmed down version of the ProGED approach. You can find the full version of the approach at https://github.com/brencej/ProGED and the paper presenting the approach at https://www.sciencedirect.com/science/article/pii/S0950705121003403.</p> <p>The approach randomly samples expressions from a probabilistic grammar and evaluates them on the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>grammar</code> <code>Union[str, SymbolLibrary]</code> <p>The grammar to use for sampling expressions. Can be either a string or a SymbolLibrary object. Using a string let's you define a custom grammar.</p> required <code>verbose</code> <code>bool</code> <p>If True, prints the expression and its error if the expression is better than the current best.</p> <code>False</code> Source code in <code>SRToolkit/approaches/ProGED.py</code> <pre><code>def __init__(self, grammar: Union[str, SymbolLibrary], verbose: bool = False):\n    super().__init__(\"ProGED\")\n    self.grammar = grammar\n    self.verbose = verbose\n</code></pre>"},{"location":"references/approaches/ProGED/#SRToolkit.approaches.ProGED.ProGED.search","title":"search","text":"<pre><code>search(sr_evaluator: SR_evaluator, seed: Optional[int] = None)\n</code></pre> <p>Samples expressions from the grammar using the Monte Carlo approach and evaluates them on the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>sr_evaluator</code> <code>SR_evaluator</code> <p>The evaluator used for scoring expressions.</p> required <code>seed</code> <code>Optional[int]</code> <p>The seed used for random number generation.</p> <code>None</code> Source code in <code>SRToolkit/approaches/ProGED.py</code> <pre><code>def search(self, sr_evaluator: SR_evaluator, seed: Optional[int] = None):\n    \"\"\"\n    Samples expressions from the grammar using the Monte Carlo approach and evaluates them on the dataset.\n\n    Args:\n        sr_evaluator: The evaluator used for scoring expressions.\n        seed: The seed used for random number generation.\n    \"\"\"\n    # TODO: Take care of seeding for the generate_n_expressions function\n    min_error = float(\"inf\")\n    while sr_evaluator.total_evaluations &lt; sr_evaluator.max_evaluations and min_error &gt; sr_evaluator.success_threshold:\n        expr = generate_n_expressions(self.grammar, 1, verbose=False)[0]\n        error = sr_evaluator.evaluate_expr(expr)\n        if error &lt; min_error:\n            min_error = error\n            if self.verbose:\n                print(f\"New best expression {''.join(expr)} with error {min_error} after {sr_evaluator.total_evaluations} evaluations.\")\n        min_error = min(min_error, error)\n</code></pre>"},{"location":"references/approaches/ProGED/#SRToolkit.approaches.ProGED.ProGED.clone","title":"clone","text":"<pre><code>clone()\n</code></pre> <p>Clones the ProGED approach.</p> <p>Returns:</p> Type Description <p>The approach is stateless, so this method only returns the object itself.</p> Source code in <code>SRToolkit/approaches/ProGED.py</code> <pre><code>def clone(self):\n    \"\"\"\n    Clones the ProGED approach.\n\n    Returns:\n        The approach is stateless, so this method only returns the object itself.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"references/approaches/sr_approach/","title":"SR Approach","text":""},{"location":"references/approaches/sr_approach/#SRToolkit.approaches.sr_approach","title":"SRToolkit.approaches.sr_approach","text":"<p>This module contains the SR_approach class, which is the base class for all symbolic regression approaches.</p>"},{"location":"references/approaches/sr_approach/#SRToolkit.approaches.sr_approach.SR_approach","title":"SR_approach","text":"<pre><code>SR_approach(name: str)\n</code></pre> <p>The base class for all symbolic regression approaches. Any symbolic regression approach should inherit from this class.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the approach.</p> required Source code in <code>SRToolkit/approaches/sr_approach.py</code> <pre><code>def __init__(self, name: str):\n    \"\"\"\n    The base class for all symbolic regression approaches. Any symbolic regression approach should inherit from\n    this class.\n\n    Args:\n        name: The name of the approach.\n    \"\"\"\n    self.name = name\n</code></pre>"},{"location":"references/approaches/sr_approach/#SRToolkit.approaches.sr_approach.SR_approach.search","title":"search","text":"<pre><code>search(sr_evaluator: SR_evaluator, seed: Optional[int] = None)\n</code></pre> <p>Run the symbolic regression search.</p> <p>Implementations should use the provided evaluator to score generated expressions. All evaluation results are stored inside <code>sr_evaluator</code>, so nothing is returned.</p> <p>Parameters:</p> Name Type Description Default <code>sr_evaluator</code> <code>SR_evaluator</code> <p>Evaluator used for scoring expressions.</p> required <code>seed</code> <code>Optional[int]</code> <p>Random seed used for generating expressions.</p> <code>None</code> Source code in <code>SRToolkit/approaches/sr_approach.py</code> <pre><code>def search(self, sr_evaluator: SR_evaluator, seed: Optional[int] = None):\n    \"\"\"\n    Run the symbolic regression search.\n\n    Implementations should use the provided evaluator to score generated expressions.\n    All evaluation results are stored inside `sr_evaluator`, so nothing is returned.\n\n    Args:\n        sr_evaluator: Evaluator used for scoring expressions.\n        seed: Random seed used for generating expressions.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"references/approaches/sr_approach/#SRToolkit.approaches.sr_approach.SR_approach.clone","title":"clone","text":"<pre><code>clone() -&gt; SR_approach\n</code></pre> <p>Clones the SR_approach instance. This is used to make multiple independent copies of the approach and making multiple independent evaluations/parallel evaluations of the approach possible. If the approach is stateless, returning self is sufficient, otherwise a deep copy of the approach should be returned. This allows us to do pretraining and finetuning of the approach independently.</p> Source code in <code>SRToolkit/approaches/sr_approach.py</code> <pre><code>def clone(self) -&gt; \"SR_approach\":\n    \"\"\"\n    Clones the SR_approach instance. This is used to make multiple independent copies of the approach and making\n    multiple independent evaluations/parallel evaluations of the approach possible. If the approach is stateless,\n    returning self is sufficient, otherwise a deep copy of the approach should be returned. This allows us to do\n    pretraining and finetuning of the approach independently.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"references/dataset/","title":"Dataset Submodule","text":""},{"location":"references/dataset/#SRToolkit.dataset","title":"SRToolkit.dataset","text":"<p>This module contains data sets and benchmarks for symbolic regression. A dataset represents a single equation with specific data, constraints for evaluation, etc. A benchmark is a collection of datasets. Our library provides the user with two modified version of popular equation discovery benchmarks. Specifically Feynman and Nguyen.</p> <p>Modules:</p> Name Description <code>sr_dataset</code> <p>The module containing the SRDataset class, which can be used to create a dataset and easily evaluate equation discovery approaches.</p> <code>sr_benchmark</code> <p>The module containing the SRBenchmark class, which can be used to create a benchmark i.e. a collection of datasets.</p>"},{"location":"references/dataset/#SRToolkit.dataset.SR_dataset","title":"SR_dataset","text":"<pre><code>SR_dataset(X: ndarray, symbol_library: SymbolLibrary, ranking_function: str = 'rmse', y: Optional[ndarray] = None, max_evaluations: int = -1, ground_truth: Optional[Union[List[str], Node, ndarray]] = None, original_equation: Optional[str] = None, success_threshold: Optional[float] = None, result_augmenters: Optional[List[ResultAugmenter]] = None, seed: Optional[int] = None, dataset_metadata: Optional[dict] = None, **kwargs)\n</code></pre> <p>Initializes an instance of the SR_dataset class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n&gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n&gt;&gt;&gt; evaluator = dataset.create_evaluator()\n&gt;&gt;&gt; evaluator.evaluate_expr([\"sin\", \"(\", \"X_0\", \")\"]) &lt; dataset.success_threshold\nFalse\n&gt;&gt;&gt; evaluator.evaluate_expr([\"u-\", \"C\", \"*\", \"X_1\", \"+\", \"X_0\"]) &lt; dataset.success_threshold\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data to be used in calculation of the error/ranking function. We assume that X is a 2D array with the shape (n_samples, n_features).</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use.</p> required <code>ranking_function</code> <code>str</code> <p>The ranking function to use. Currently, \"rmse\" and \"bed\" are supported. RMSE is the standard ranking function in symbolic regression, calculating the error between the ground truth values and outputs of expressions with fitted free parameters. BED is a stochastic measure that calculates the behavioral distance between two expressions that can contain free parameters. Its advantage is that expressions with lots of parameters are less likely to overfit, and thus the measure focuses more on structure identification.</p> <code>'rmse'</code> <code>y</code> <code>Optional[ndarray]</code> <p>The target values to be used in parameter estimation if the ranking function is \"rmse\".</p> <code>None</code> <code>max_evaluations</code> <code>int</code> <p>The maximum number of expressions to evaluate. Less than 0 means no limit.</p> <code>-1</code> <code>ground_truth</code> <code>Optional[Union[List[str], Node, ndarray]]</code> <p>The ground truth expression, represented as a list of tokens (strings) in the infix notation, a SRToolkit.utils.Node object, or a numpy array representing behavior (see SRToolkit.utils.create_behavior_matrix for more details).</p> <code>None</code> <code>original_equation</code> <code>Optional[str]</code> <p>The original equation from which the ground truth expression was generated).</p> <code>None</code> <code>success_threshold</code> <code>Optional[float]</code> <p>The threshold for determining whether an expression is successful or not. If None,</p> <code>None</code> <code>result_augmenters</code> <code>Optional[List[ResultAugmenter]]</code> <p>Optional list of objects that augment the results returned by the \"get_results\" function.</p> <code>None</code> <code>seed</code> <code>Optional[int]</code> <p>The seed to use for random number generation/reproducibility. Default is None, which means no seed is used.</p> <code>None</code> <code>dataset_metadata</code> <code>Optional[dict]</code> <p>An optional dictionary containing metadata about this evaluation. This could include information such as the name of the dataset, a citation for the dataset, number of variables, etc.</p> <code>None</code> <p>Other Parameters:</p> Name Type Description <code>method</code> <code>str</code> <p>The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested. Default is \"L-BFGS-B\".</p> <code>tol</code> <code>float</code> <p>The tolerance for termination. Default is 1e-6.</p> <code>gtol</code> <code>float</code> <p>The tolerance for the gradient norm. Default is 1e-3.</p> <code>max_iter</code> <code>int</code> <p>The maximum number of iterations. Default is 100.</p> <code>constant_bounds</code> <code>Tuple[float, float]</code> <p>A tuple of two elements, specifying the lower and upper bounds for the constant values. Default is (-5, 5).</p> <code>initialization</code> <code>str</code> <p>The method to use for initializing the constant values. Currently, only \"random\" and \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\" creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".</p> <code>max_constants</code> <code>int</code> <p>The maximum number of constants allowed in the expression. Default is 8.</p> <code>max_expr_length</code> <code>int</code> <p>The maximum length of the expression. Default is -1 (no limit).</p> <code>num_points_sampled</code> <code>int</code> <p>The number of points to sample when estimating the behavior of an expression. Default is 64. If num_points_sampled==-1, then the number of points sampled is equal to the number of points in the dataset.</p> <code>bed_X</code> <code>Optional[ndarray]</code> <p>Points used for BED evaluation. If None and domain_bounds are given, points are sampled from the domain. If None and domain_bounds are not givem, points are randomly selected from X. Default is None.</p> <code>num_consts_sampled</code> <code>int</code> <p>Number of constants sampled for BED evaluation. Default is 32.</p> <code>domain_bounds</code> <code>Optional[List[Tuple[float, float]]]</code> <p>Bounds for the domain to be used if bed_X is None to sample random points. Default is None.</p> Source code in <code>SRToolkit/dataset/sr_dataset.py</code> <pre><code>def __init__(\n    self,\n    X: np.ndarray,\n    symbol_library: SymbolLibrary,\n    ranking_function: str = \"rmse\",\n    y: Optional[np.ndarray] = None,\n    max_evaluations: int = -1,\n    ground_truth: Optional[Union[List[str], Node, np.ndarray]] = None,\n    original_equation: Optional[str] = None,\n    success_threshold: Optional[float] = None,\n    result_augmenters: Optional[List[ResultAugmenter]] = None,\n    seed: Optional[int] = None,\n    dataset_metadata: Optional[dict] = None,\n    **kwargs,\n):\n    \"\"\"\n    Initializes an instance of the SR_dataset class.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n        &gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n        ...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n        &gt;&gt;&gt; evaluator = dataset.create_evaluator()\n        &gt;&gt;&gt; evaluator.evaluate_expr([\"sin\", \"(\", \"X_0\", \")\"]) &lt; dataset.success_threshold\n        False\n        &gt;&gt;&gt; evaluator.evaluate_expr([\"u-\", \"C\", \"*\", \"X_1\", \"+\", \"X_0\"]) &lt; dataset.success_threshold\n        True\n\n    Args:\n        X: The input data to be used in calculation of the error/ranking function. We assume that X is a 2D array\n            with the shape (n_samples, n_features).\n        symbol_library: The symbol library to use.\n        ranking_function: The ranking function to use. Currently, \"rmse\" and \"bed\" are supported. RMSE is the\n            standard ranking function in symbolic regression, calculating the error between the ground truth values\n            and outputs of expressions with fitted free parameters. BED is a stochastic measure that calculates\n            the behavioral distance between two expressions that can contain free parameters. Its advantage is that\n            expressions with lots of parameters are less likely to overfit, and thus the measure focuses more on\n            structure identification.\n        y: The target values to be used in parameter estimation if the ranking function is \"rmse\".\n        max_evaluations: The maximum number of expressions to evaluate. Less than 0 means no limit.\n        ground_truth: The ground truth expression, represented as a list of tokens (strings) in the infix notation,\n            a SRToolkit.utils.Node object, or a numpy array representing behavior\n            (see SRToolkit.utils.create_behavior_matrix for more details).\n        original_equation: The original equation from which the ground truth expression was generated).\n        success_threshold: The threshold for determining whether an expression is successful or not. If None,\n        result_augmenters: Optional list of objects that augment the results returned by the \"get_results\" function.\n        seed: The seed to use for random number generation/reproducibility. Default is None, which means no seed is used.\n        dataset_metadata: An optional dictionary containing metadata about this evaluation. This could include\n            information such as the name of the dataset, a citation for the dataset, number of variables, etc.\n\n    Keyword Arguments:\n        method (str): The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested.\n            Default is \"L-BFGS-B\".\n        tol (float): The tolerance for termination. Default is 1e-6.\n        gtol (float): The tolerance for the gradient norm. Default is 1e-3.\n        max_iter (int): The maximum number of iterations. Default is 100.\n        constant_bounds (Tuple[float, float]): A tuple of two elements, specifying the lower and upper bounds for\n            the constant values. Default is (-5, 5).\n        initialization (str): The method to use for initializing the constant values. Currently, only \"random\" and\n            \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\"\n            creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".\n        max_constants (int): The maximum number of constants allowed in the expression. Default is 8.\n        max_expr_length (int): The maximum length of the expression. Default is -1 (no limit).\n        num_points_sampled (int): The number of points to sample when estimating the behavior of an expression.\n            Default is 64. If num_points_sampled==-1, then the number of points sampled is equal to the number of\n            points in the dataset.\n        bed_X (Optional[np.ndarray]): Points used for BED evaluation. If None and domain_bounds are given, points\n            are sampled from the domain. If None and domain_bounds are not givem, points are randomly selected\n            from X. Default is None.\n        num_consts_sampled (int): Number of constants sampled for BED evaluation. Default is 32.\n        domain_bounds (Optional[List[Tuple[float, float]]]): Bounds for the domain to be used if bed_X is None to\n            sample random points. Default is None.\n    \"\"\"\n    self.X = X\n    self.symbol_library = symbol_library\n    self.y = y\n    self.max_evaluations = max_evaluations\n    self.success_threshold = success_threshold\n    self.ranking_function = ranking_function\n    self.ground_truth = ground_truth\n    self.original_equation = original_equation\n    self.result_augmenters = result_augmenters\n    self.kwargs = kwargs\n\n    # See if symbols contain a symbol for constants\n    symbols_metadata = self.symbol_library.symbols.values()\n    self.contains_constants = any(\n        [symbol[\"type\"] == \"const\" for symbol in symbols_metadata]\n    )\n\n    self.seed = seed\n    self.dataset_metadata = dataset_metadata\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_dataset.evaluate_approach","title":"evaluate_approach","text":"<pre><code>evaluate_approach(sr_approach: SR_approach, num_experiments: int = 1, top_k: int = 20, initial_seed: int = None, results: Optional[SR_results] = None) -&gt; SR_results\n</code></pre> <p>Evaluates an SR_approach on this dataset.</p> <p>Parameters:</p> Name Type Description Default <code>sr_approach</code> <code>SR_approach</code> <p>An instance of SR_approach that will be evaluated on this dataset.</p> required <code>num_experiments</code> <code>int</code> <p>The number of times the approach should be evaluated on this dataset.</p> <code>1</code> <code>top_k</code> <code>int</code> <p>Number of the best expressions presented in the results</p> <code>20</code> <code>seed</code> <p>The seed used for random number generation. If None, the seed from the dataset is used.</p> required <code>results</code> <code>Optional[SR_results]</code> <p>An optional SR_results object to which the results of the evaluation will be added. If None, a new SR_results object will be created.</p> <code>None</code> <p>Returns:</p> Type Description <code>SR_results</code> <p>The results of the evaluation.</p> Source code in <code>SRToolkit/dataset/sr_dataset.py</code> <pre><code>def evaluate_approach(self, sr_approach: SR_approach, num_experiments: int = 1, top_k: int = 20,\n                      initial_seed: int = None, results: Optional[SR_results] = None) -&gt; SR_results:\n    \"\"\"\n    Evaluates an SR_approach on this dataset.\n\n    Args:\n        sr_approach: An instance of SR_approach that will be evaluated on this dataset.\n        num_experiments: The number of times the approach should be evaluated on this dataset.\n        top_k: Number of the best expressions presented in the results\n        seed: The seed used for random number generation. If None, the seed from the dataset is used.\n        results: An optional SR_results object to which the results of the evaluation will be added. If None,\n            a new SR_results object will be created.\n\n    Returns:\n        The results of the evaluation.\n    \"\"\"\n    if initial_seed is None:\n        seed = self.seed\n    else:\n        seed = initial_seed\n\n    if results is None:\n        results = SR_results()\n\n    for experiment in range(num_experiments):\n        print(f\"Running experiment {experiment+1}/{num_experiments}\")\n        if seed is not None:\n            seed += 1\n\n        evaluator = self.create_evaluator(seed)\n        approach = sr_approach.clone()\n        approach.search(evaluator, seed)\n        results += evaluator.get_results(approach.name, top_k)\n    return results\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_dataset.create_evaluator","title":"create_evaluator","text":"<pre><code>create_evaluator(metadata: dict = None, seed: int = None) -&gt; SR_evaluator\n</code></pre> <p>Creates an instance of the SR_evaluator class from this dataset.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n&gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n&gt;&gt;&gt; evaluator = dataset.create_evaluator()\n&gt;&gt;&gt; evaluator.evaluate_expr([\"sin\", \"(\", \"X_0\", \")\"])\n8.056453977203414\n&gt;&gt;&gt; evaluator.evaluate_expr([\"X_1\", \"+\", \"X_0\"])\n0.0\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>dict</code> <p>An optional dictionary containing metadata about this evaluation. This could include information such as the dataset used, the model used, seed, etc.</p> <code>None</code> <code>seed</code> <code>int</code> <p>An optional seed to be used for the random number generator. If None, the seed from the dataset is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>SR_evaluator</code> <p>An instance of the SR_evaluator class.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>if an error occurs when creating the evaluator.</p> Source code in <code>SRToolkit/dataset/sr_dataset.py</code> <pre><code>def create_evaluator(self, metadata: dict = None, seed: int = None) -&gt; SR_evaluator:\n    \"\"\"\n    Creates an instance of the SR_evaluator class from this dataset.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n        &gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n        ...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n        &gt;&gt;&gt; evaluator = dataset.create_evaluator()\n        &gt;&gt;&gt; evaluator.evaluate_expr([\"sin\", \"(\", \"X_0\", \")\"])\n        8.056453977203414\n        &gt;&gt;&gt; evaluator.evaluate_expr([\"X_1\", \"+\", \"X_0\"])\n        0.0\n\n    Args:\n        metadata: An optional dictionary containing metadata about this evaluation. This could include\n            information such as the dataset used, the model used, seed, etc.\n        seed: An optional seed to be used for the random number generator. If None, the seed from the dataset is used.\n\n    Returns:\n        An instance of the SR_evaluator class.\n\n    Raises:\n        Exception: if an error occurs when creating the evaluator.\n    \"\"\"\n    if metadata is None:\n        metadata = dict()\n    metadata[\"dataset_metadata\"] = self.dataset_metadata\n\n    if seed is None:\n        seed = self.seed\n\n    try:\n        return SR_evaluator(\n            X=self.X,\n            y=self.y,\n            max_evaluations=self.max_evaluations,\n            success_threshold=self.success_threshold,\n            ranking_function=self.ranking_function,\n            ground_truth=self.ground_truth,\n            result_augmenters=self.result_augmenters,\n            symbol_library=self.symbol_library,\n            seed=seed,\n            metadata=metadata,\n            **self.kwargs,\n        )\n    except Exception as e:\n        print(f\"Error creating evaluator: {e}\")\n        raise e\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_dataset.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Returns a string describing this dataset.</p> <p>The string describes the target expression, symbols that should be used, and the success threshold. It also includes any constraints that should be followed when evaluating a model on this dataset. These constraints include the maximum number of expressions to evaluate, the maximum length of the expression, and the maximum number of constants allowed in the expression. If the symbol library contains a symbol for constants, the string also includes the range of constants.</p> <p>For other metadata, please refer to the attribute self.dataset_metadata.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n&gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n&gt;&gt;&gt; str(dataset)\n'Dataset for target expression z = x + y. When evaluating your model on this dataset, you should limit your generative model to only produce expressions using the following symbols: +, -, *, /, ^, u-, sqrt, sin, cos, exp, tan, arcsin, arccos, arctan, sinh, cosh, tanh, floor, ceil, ln, log, ^-1, ^2, ^3, ^4, ^5, pi, e, C, X_0, X_1.\\nExpressions will be ranked based on the RMSE ranking function.\\nExpressions are deemed successful if the root mean squared error is less than 1e-06. However, we advise that you check the best performing expressions manually to ensure they are correct.\\nDataset uses the default limitations (extra arguments) from the SR_evaluator.The expressions in the dataset can contain constants/free parameters.\\nFor other metadata, please refer to the attribute self.dataset_metadata.'\n</code></pre> <p>Returns:</p> Type Description <code>str</code> <p>A string describing this dataset.</p> Source code in <code>SRToolkit/dataset/sr_dataset.py</code> <pre><code>def __str__(self) -&gt; str:\n    r\"\"\"\n    Returns a string describing this dataset.\n\n    The string describes the target expression, symbols that should be used,\n    and the success threshold. It also includes any constraints that should\n    be followed when evaluating a model on this dataset. These constraints include the maximum\n    number of expressions to evaluate, the maximum length of the expression,\n    and the maximum number of constants allowed in the expression. If the\n    symbol library contains a symbol for constants, the string also includes\n    the range of constants.\n\n    For other metadata, please refer to the attribute self.dataset_metadata.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n        &gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n        ...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n        &gt;&gt;&gt; str(dataset)\n        'Dataset for target expression z = x + y. When evaluating your model on this dataset, you should limit your generative model to only produce expressions using the following symbols: +, -, *, /, ^, u-, sqrt, sin, cos, exp, tan, arcsin, arccos, arctan, sinh, cosh, tanh, floor, ceil, ln, log, ^-1, ^2, ^3, ^4, ^5, pi, e, C, X_0, X_1.\\nExpressions will be ranked based on the RMSE ranking function.\\nExpressions are deemed successful if the root mean squared error is less than 1e-06. However, we advise that you check the best performing expressions manually to ensure they are correct.\\nDataset uses the default limitations (extra arguments) from the SR_evaluator.The expressions in the dataset can contain constants/free parameters.\\nFor other metadata, please refer to the attribute self.dataset_metadata.'\n\n    Returns:\n        A string describing this dataset.\n    \"\"\"\n    description = f\"Dataset for target expression {self.original_equation}.\"\n    description += (\n        f\" When evaluating your model on this dataset, you should limit your generative model to only \"\n        f\"produce expressions using the following symbols: {str(self.symbol_library)}.\\nExpressions will be \"\n        f\"ranked based on the {self.ranking_function.upper()} ranking function.\\n\"\n    )\n\n    if self.success_threshold is not None:\n        description += (\"Expressions are deemed successful if the root mean squared error is less than \"\n                        f\"{self.success_threshold}. However, we advise that you check the best performing \"\n                        f\"expressions manually to ensure they are correct.\\n\")\n\n    if len(self.kwargs) == 0:\n        description += \"Dataset uses the default limitations (extra arguments) from the SR_evaluator.\"\n    else:\n        limitations = \"Non default limitations (extra arguments) from the SR_evaluators are:\"\n        for key, value in self.kwargs.items():\n            limitations += f\" {key}={value}, \"\n        limitations = limitations[:-2] + \".\\n\"\n        description += limitations\n\n    if self.contains_constants:\n        description += f\"The expressions in the dataset can contain constants/free parameters.\\n\"\n\n    description += \"For other metadata, please refer to the attribute self.dataset_metadata.\"\n\n    return description\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_dataset.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of this dataset. This is mainly used for saving the dataset to disk.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n&gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n&gt;&gt;&gt; dataset.to_dict(\"data/example_ds\", \"test_dataset\")\n{'symbol_library': {'type': 'SymbolLibrary', 'symbols': {'+': {'symbol': '+', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} + {}', 'latex_str': '{} + {}'}, '-': {'symbol': '-', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} - {}', 'latex_str': '{} - {}'}, '*': {'symbol': '*', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} * {}', 'latex_str': '{} \\\\cdot {}'}, '/': {'symbol': '/', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} / {}', 'latex_str': '\\\\frac{{{}}}{{{}}}'}, '^': {'symbol': '^', 'type': 'op', 'precedence': 2, 'np_fn': '{} = np.power({},{})', 'latex_str': '{}^{{{}}}'}, 'u-': {'symbol': 'u-', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = -{}', 'latex_str': '- {}'}, 'sqrt': {'symbol': 'sqrt', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sqrt({})', 'latex_str': '\\\\sqrt {{{}}}'}, 'sin': {'symbol': 'sin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sin({})', 'latex_str': '\\\\sin {}'}, 'cos': {'symbol': 'cos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cos({})', 'latex_str': '\\\\cos {}'}, 'exp': {'symbol': 'exp', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.exp({})', 'latex_str': 'e^{{{}}}'}, 'tan': {'symbol': 'tan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tan({})', 'latex_str': '\\\\tan {}'}, 'arcsin': {'symbol': 'arcsin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arcsin({})', 'latex_str': '\\\\arcsin {}'}, 'arccos': {'symbol': 'arccos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arccos({})', 'latex_str': '\\\\arccos {}'}, 'arctan': {'symbol': 'arctan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arctan({})', 'latex_str': '\\\\arctan {}'}, 'sinh': {'symbol': 'sinh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sinh({})', 'latex_str': '\\\\sinh {}'}, 'cosh': {'symbol': 'cosh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cosh({})', 'latex_str': '\\\\cosh {}'}, 'tanh': {'symbol': 'tanh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tanh({})', 'latex_str': '\\\\tanh {}'}, 'floor': {'symbol': 'floor', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.floor({})', 'latex_str': '\\\\lfloor {} \\\\rfloor'}, 'ceil': {'symbol': 'ceil', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.ceil({})', 'latex_str': '\\\\lceil {} \\\\rceil'}, 'ln': {'symbol': 'ln', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log({})', 'latex_str': '\\\\ln {}'}, 'log': {'symbol': 'log', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log10({})', 'latex_str': '\\\\log_{{10}} {}'}, '^-1': {'symbol': '^-1', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = 1/{}', 'latex_str': '{}^{{-1}}'}, '^2': {'symbol': '^2', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**2', 'latex_str': '{}^2'}, '^3': {'symbol': '^3', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**3', 'latex_str': '{}^3'}, '^4': {'symbol': '^4', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**4', 'latex_str': '{}^4'}, '^5': {'symbol': '^5', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**5', 'latex_str': '{}^5'}, 'pi': {'symbol': 'pi', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.pi)', 'latex_str': '\\\\pi'}, 'e': {'symbol': 'e', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.e)', 'latex_str': 'e'}, 'C': {'symbol': 'C', 'type': 'const', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], C[{}])', 'latex_str': 'C_{{{}}}'}, 'X_0': {'symbol': 'X_0', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 0]', 'latex_str': 'X_{0}'}, 'X_1': {'symbol': 'X_1', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 1]', 'latex_str': 'X_{1}'}}, 'preamble': ['import numpy as np'], 'num_variables': 2}, 'ranking_function': 'rmse', 'max_evaluations': 10000, 'success_threshold': 1e-06, 'original_equation': 'z = x + y', 'seed': None, 'dataset_metadata': None, 'kwargs': {}, 'result_augmenters': None, 'ground_truth': ['X_0', '+', 'X_1'], 'dataset_path': 'data/example_ds/test_dataset.npz'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>The path to the directory where the data in the dataset should be saved.</p> required <code>name</code> <code>str</code> <p>The name of the dataset. This will be used to name the files containing the dataset data.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary representation of this dataset.</p> Source code in <code>SRToolkit/dataset/sr_dataset.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    r\"\"\"\n    Creates a dictionary representation of this dataset. This is mainly used for saving the dataset to disk.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n        &gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n        ...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n        &gt;&gt;&gt; dataset.to_dict(\"data/example_ds\", \"test_dataset\")\n        {'symbol_library': {'type': 'SymbolLibrary', 'symbols': {'+': {'symbol': '+', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} + {}', 'latex_str': '{} + {}'}, '-': {'symbol': '-', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} - {}', 'latex_str': '{} - {}'}, '*': {'symbol': '*', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} * {}', 'latex_str': '{} \\\\cdot {}'}, '/': {'symbol': '/', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} / {}', 'latex_str': '\\\\frac{{{}}}{{{}}}'}, '^': {'symbol': '^', 'type': 'op', 'precedence': 2, 'np_fn': '{} = np.power({},{})', 'latex_str': '{}^{{{}}}'}, 'u-': {'symbol': 'u-', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = -{}', 'latex_str': '- {}'}, 'sqrt': {'symbol': 'sqrt', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sqrt({})', 'latex_str': '\\\\sqrt {{{}}}'}, 'sin': {'symbol': 'sin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sin({})', 'latex_str': '\\\\sin {}'}, 'cos': {'symbol': 'cos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cos({})', 'latex_str': '\\\\cos {}'}, 'exp': {'symbol': 'exp', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.exp({})', 'latex_str': 'e^{{{}}}'}, 'tan': {'symbol': 'tan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tan({})', 'latex_str': '\\\\tan {}'}, 'arcsin': {'symbol': 'arcsin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arcsin({})', 'latex_str': '\\\\arcsin {}'}, 'arccos': {'symbol': 'arccos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arccos({})', 'latex_str': '\\\\arccos {}'}, 'arctan': {'symbol': 'arctan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arctan({})', 'latex_str': '\\\\arctan {}'}, 'sinh': {'symbol': 'sinh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sinh({})', 'latex_str': '\\\\sinh {}'}, 'cosh': {'symbol': 'cosh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cosh({})', 'latex_str': '\\\\cosh {}'}, 'tanh': {'symbol': 'tanh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tanh({})', 'latex_str': '\\\\tanh {}'}, 'floor': {'symbol': 'floor', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.floor({})', 'latex_str': '\\\\lfloor {} \\\\rfloor'}, 'ceil': {'symbol': 'ceil', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.ceil({})', 'latex_str': '\\\\lceil {} \\\\rceil'}, 'ln': {'symbol': 'ln', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log({})', 'latex_str': '\\\\ln {}'}, 'log': {'symbol': 'log', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log10({})', 'latex_str': '\\\\log_{{10}} {}'}, '^-1': {'symbol': '^-1', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = 1/{}', 'latex_str': '{}^{{-1}}'}, '^2': {'symbol': '^2', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**2', 'latex_str': '{}^2'}, '^3': {'symbol': '^3', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**3', 'latex_str': '{}^3'}, '^4': {'symbol': '^4', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**4', 'latex_str': '{}^4'}, '^5': {'symbol': '^5', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**5', 'latex_str': '{}^5'}, 'pi': {'symbol': 'pi', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.pi)', 'latex_str': '\\\\pi'}, 'e': {'symbol': 'e', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.e)', 'latex_str': 'e'}, 'C': {'symbol': 'C', 'type': 'const', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], C[{}])', 'latex_str': 'C_{{{}}}'}, 'X_0': {'symbol': 'X_0', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 0]', 'latex_str': 'X_{0}'}, 'X_1': {'symbol': 'X_1', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 1]', 'latex_str': 'X_{1}'}}, 'preamble': ['import numpy as np'], 'num_variables': 2}, 'ranking_function': 'rmse', 'max_evaluations': 10000, 'success_threshold': 1e-06, 'original_equation': 'z = x + y', 'seed': None, 'dataset_metadata': None, 'kwargs': {}, 'result_augmenters': None, 'ground_truth': ['X_0', '+', 'X_1'], 'dataset_path': 'data/example_ds/test_dataset.npz'}\n\n    Args:\n        base_path: The path to the directory where the data in the dataset should be saved.\n        name: The name of the dataset. This will be used to name the files containing the dataset data.\n\n    Returns:\n        A dictionary representation of this dataset.\n    \"\"\"\n    output = {\n        \"symbol_library\": self.symbol_library.to_dict(),\n        \"ranking_function\": self.ranking_function,\n        \"max_evaluations\": self.max_evaluations,\n        \"success_threshold\": self.success_threshold,\n        \"original_equation\": self.original_equation,\n        \"seed\": self.seed,\n        \"dataset_metadata\": self.dataset_metadata,\n    }\n\n    if self.kwargs is not None and \"bed_X\" in self.kwargs and isinstance(self.kwargs[\"bed_X\"], np.ndarray):\n        self.kwargs[\"bed_X\"] = self.kwargs[\"bed_X\"].tolist()\n\n    output[\"kwargs\"] = self.kwargs\n\n    if self.result_augmenters is None:\n        output[\"result_augmenters\"] = None\n    else:\n        output[\"result_augmenters\"] = [ag.to_dict(base_path, name) for ag in self.result_augmenters]\n\n    if not os.path.isdir(base_path):\n        os.makedirs(base_path)\n\n    if self.ground_truth is None:\n        output[\"ground_truth\"] = None\n    else:\n        if isinstance(self.ground_truth, list):\n            output[\"ground_truth\"] = self.ground_truth\n        elif isinstance(self.ground_truth, Node):\n            output[\"ground_truth\"] = self.ground_truth.to_list()\n        elif isinstance(self.ground_truth, np.ndarray) and not os.path.exists(f\"{base_path}/{name}_gt.npy\"):\n            np.save(f\"{base_path}/{name}_gt.npy\", self.ground_truth)\n            output[\"ground_truth\"] = f\"{base_path}/{name}_gt.npy\"\n\n    if not os.path.exists(f\"{base_path}/{name}.npz\"):\n        if self.y is None:\n            np.savez(f\"{base_path}/{name}.npz\", X=self.X)\n        else:\n            np.savez(f\"{base_path}/{name}.npz\", X=self.X, y=self.y)\n    output[\"dataset_path\"] = f\"{base_path}/{name}.npz\"\n\n    return output\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_dataset.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(d: dict, augmentation_map: Dict[str, Type[ResultAugmenter]] = None) -&gt; SR_dataset\n</code></pre> <p>Creates an instance of the SR_dataset class from its dictionary representation. This is mainly used for loading the dataset from disk.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from SRToolkit.evaluation.result_augmentation import RESULT_AUGMENTERS\n&gt;&gt;&gt; dataset_dict = {'symbol_library': {'type': 'SymbolLibrary', 'symbols': {'+': {'symbol': '+', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} + {}', 'latex_str': '{} + {}'}, '-': {'symbol': '-', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} - {}', 'latex_str': '{} - {}'}, '*': {'symbol': '*', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} * {}', 'latex_str': '{} \\cdot {}'}, '/': {'symbol': '/', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} / {}', 'latex_str': '\\frac{{{}}}{{{}}}'}, '^': {'symbol': '^', 'type': 'op', 'precedence': 2, 'np_fn': '{} = np.power({},{})', 'latex_str': '{}^{{{}}}'}, 'u-': {'symbol': 'u-', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = -{}', 'latex_str': '- {}'}, 'sqrt': {'symbol': 'sqrt', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sqrt({})', 'latex_str': '\\sqrt {{{}}}'}, 'sin': {'symbol': 'sin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sin({})', 'latex_str': '\\sin {}'}, 'cos': {'symbol': 'cos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cos({})', 'latex_str': '\\cos {}'}, 'exp': {'symbol': 'exp', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.exp({})', 'latex_str': 'e^{{{}}}'}, 'tan': {'symbol': 'tan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tan({})', 'latex_str': '\\tan {}'}, 'arcsin': {'symbol': 'arcsin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arcsin({})', 'latex_str': '\\arcsin {}'}, 'arccos': {'symbol': 'arccos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arccos({})', 'latex_str': '\\arccos {}'}, 'arctan': {'symbol': 'arctan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arctan({})', 'latex_str': '\\arctan {}'}, 'sinh': {'symbol': 'sinh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sinh({})', 'latex_str': '\\sinh {}'}, 'cosh': {'symbol': 'cosh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cosh({})', 'latex_str': '\\cosh {}'}, 'tanh': {'symbol': 'tanh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tanh({})', 'latex_str': '\\tanh {}'}, 'floor': {'symbol': 'floor', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.floor({})', 'latex_str': '\\lfloor {} \\rfloor'}, 'ceil': {'symbol': 'ceil', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.ceil({})', 'latex_str': '\\lceil {} \\rceil'}, 'ln': {'symbol': 'ln', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log({})', 'latex_str': '\\ln {}'}, 'log': {'symbol': 'log', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log10({})', 'latex_str': '\\log_{{10}} {}'}, '^-1': {'symbol': '^-1', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = 1/{}', 'latex_str': '{}^{{-1}}'}, '^2': {'symbol': '^2', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**2', 'latex_str': '{}^2'}, '^3': {'symbol': '^3', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**3', 'latex_str': '{}^3'}, '^4': {'symbol': '^4', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**4', 'latex_str': '{}^4'}, '^5': {'symbol': '^5', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**5', 'latex_str': '{}^5'}, 'pi': {'symbol': 'pi', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.pi)', 'latex_str': '\\pi'}, 'e': {'symbol': 'e', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.e)', 'latex_str': 'e'}, 'C': {'symbol': 'C', 'type': 'const', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], C[{}])', 'latex_str': 'C_{{{}}}'}, 'X_0': {'symbol': 'X_0', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 0]', 'latex_str': 'X_{0}'}, 'X_1': {'symbol': 'X_1', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 1]', 'latex_str': 'X_{1}'}}, 'preamble': ['import numpy as np'], 'num_variables': 2}, 'ranking_function': 'rmse', 'max_evaluations': 10000, 'success_threshold': 1e-06, 'original_equation': 'z = x + y', 'seed': None, 'dataset_metadata': None, 'kwargs': {}, 'result_augmenters': None, 'ground_truth': ['X_0', '+', 'X_1'], 'dataset_path': 'data/example_ds/test_dataset.npz'}\n&gt;&gt;&gt; dataset = SR_dataset.from_dict(dataset_dict)\n&gt;&gt;&gt; dataset.X.shape\n(3, 2)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>The dictionary representation of the dataset.</p> required <code>augmentation_map</code> <code>Dict[str, Type[ResultAugmenter]]</code> <p>A dictionary mapping the names of the result augmentation classes to their respective classes. When default value (None) is used, the SRToolit.evaluation.result_augmentation.RESULT_AUGMENTERS dictionary is used.</p> <code>None</code> Source code in <code>SRToolkit/dataset/sr_dataset.py</code> <pre><code>@staticmethod\ndef from_dict(d: dict, augmentation_map: Dict[str, Type[ResultAugmenter]]=None) -&gt; \"SR_dataset\":\n    \"\"\"\n    Creates an instance of the SR_dataset class from its dictionary representation. This is mainly used for\n    loading the dataset from disk.\n\n    Examples:\n        &gt;&gt;&gt; from SRToolkit.evaluation.result_augmentation import RESULT_AUGMENTERS\n        &gt;&gt;&gt; dataset_dict = {'symbol_library': {'type': 'SymbolLibrary', 'symbols': {'+': {'symbol': '+', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} + {}', 'latex_str': '{} + {}'}, '-': {'symbol': '-', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} - {}', 'latex_str': '{} - {}'}, '*': {'symbol': '*', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} * {}', 'latex_str': '{} \\\\cdot {}'}, '/': {'symbol': '/', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} / {}', 'latex_str': '\\\\frac{{{}}}{{{}}}'}, '^': {'symbol': '^', 'type': 'op', 'precedence': 2, 'np_fn': '{} = np.power({},{})', 'latex_str': '{}^{{{}}}'}, 'u-': {'symbol': 'u-', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = -{}', 'latex_str': '- {}'}, 'sqrt': {'symbol': 'sqrt', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sqrt({})', 'latex_str': '\\\\sqrt {{{}}}'}, 'sin': {'symbol': 'sin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sin({})', 'latex_str': '\\\\sin {}'}, 'cos': {'symbol': 'cos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cos({})', 'latex_str': '\\\\cos {}'}, 'exp': {'symbol': 'exp', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.exp({})', 'latex_str': 'e^{{{}}}'}, 'tan': {'symbol': 'tan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tan({})', 'latex_str': '\\\\tan {}'}, 'arcsin': {'symbol': 'arcsin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arcsin({})', 'latex_str': '\\\\arcsin {}'}, 'arccos': {'symbol': 'arccos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arccos({})', 'latex_str': '\\\\arccos {}'}, 'arctan': {'symbol': 'arctan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arctan({})', 'latex_str': '\\\\arctan {}'}, 'sinh': {'symbol': 'sinh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sinh({})', 'latex_str': '\\\\sinh {}'}, 'cosh': {'symbol': 'cosh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cosh({})', 'latex_str': '\\\\cosh {}'}, 'tanh': {'symbol': 'tanh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tanh({})', 'latex_str': '\\\\tanh {}'}, 'floor': {'symbol': 'floor', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.floor({})', 'latex_str': '\\\\lfloor {} \\\\rfloor'}, 'ceil': {'symbol': 'ceil', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.ceil({})', 'latex_str': '\\\\lceil {} \\\\rceil'}, 'ln': {'symbol': 'ln', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log({})', 'latex_str': '\\\\ln {}'}, 'log': {'symbol': 'log', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log10({})', 'latex_str': '\\\\log_{{10}} {}'}, '^-1': {'symbol': '^-1', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = 1/{}', 'latex_str': '{}^{{-1}}'}, '^2': {'symbol': '^2', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**2', 'latex_str': '{}^2'}, '^3': {'symbol': '^3', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**3', 'latex_str': '{}^3'}, '^4': {'symbol': '^4', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**4', 'latex_str': '{}^4'}, '^5': {'symbol': '^5', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**5', 'latex_str': '{}^5'}, 'pi': {'symbol': 'pi', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.pi)', 'latex_str': '\\\\pi'}, 'e': {'symbol': 'e', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.e)', 'latex_str': 'e'}, 'C': {'symbol': 'C', 'type': 'const', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], C[{}])', 'latex_str': 'C_{{{}}}'}, 'X_0': {'symbol': 'X_0', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 0]', 'latex_str': 'X_{0}'}, 'X_1': {'symbol': 'X_1', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 1]', 'latex_str': 'X_{1}'}}, 'preamble': ['import numpy as np'], 'num_variables': 2}, 'ranking_function': 'rmse', 'max_evaluations': 10000, 'success_threshold': 1e-06, 'original_equation': 'z = x + y', 'seed': None, 'dataset_metadata': None, 'kwargs': {}, 'result_augmenters': None, 'ground_truth': ['X_0', '+', 'X_1'], 'dataset_path': 'data/example_ds/test_dataset.npz'}\n        &gt;&gt;&gt; dataset = SR_dataset.from_dict(dataset_dict)\n        &gt;&gt;&gt; dataset.X.shape\n        (3, 2)\n\n    Args:\n        d: The dictionary representation of the dataset.\n        augmentation_map: A dictionary mapping the names of the result augmentation classes to their respective\n            classes. When default value (None) is used, the SRToolit.evaluation.result_augmentation.RESULT_AUGMENTERS dictionary is used.\n    \"\"\"\n    if augmentation_map is None:\n        from SRToolkit.evaluation.result_augmentation import RESULT_AUGMENTERS\n        augmentation_map = RESULT_AUGMENTERS\n    try:\n        data = np.load(d[\"dataset_path\"])\n        X = data[\"X\"]\n        if \"y\" in data:\n            y = data[\"y\"]\n        else:\n            y = None\n    except:\n        raise Exception(f\"[SR_dataset.from_dict] Could not load dataset from {d['dataset_path']}\")\n\n    if \"ground_truth\" in d and isinstance(d[\"ground_truth\"], list) or d[\"ground_truth\"] is None:\n        ground_truth = d[\"ground_truth\"]\n    else:\n        try:\n            ground_truth = np.load(d[\"ground_truth\"])\n        except:\n            raise Exception(f\"[SR_dataset.from_dict] Could not load ground truth from {d['ground_truth']}\")\n\n    if not \"result_augmenters\" in d:\n        raise Exception(\"[SR_dataset.from_dict] Could not find result_augmenters keyword in the provided dictionary.\")\n\n    if d[\"result_augmenters\"] is None:\n        result_augmenters = None\n    else:\n        result_augmenters = [augmentation_map[ag_data[\"type\"]].from_dict(ag_data, augmentation_map)\n                             for ag_data in d[\"result_augmenters\"]]\n\n    if \"bed_X\" in d[\"kwargs\"] and d[\"kwargs\"][\"bed_X\"] is not None:\n        d[\"kwargs\"][\"bed_X\"] = np.array(d[\"kwargs\"][\"bed_X\"])\n\n    try:\n        return SR_dataset(X,\n                          SymbolLibrary.from_dict(d[\"symbol_library\"]),\n                          ranking_function=d[\"ranking_function\"],\n                          y=y,\n                          max_evaluations=d[\"max_evaluations\"],\n                          ground_truth=ground_truth,\n                          original_equation=d[\"original_equation\"],\n                          success_threshold=d[\"success_threshold\"],\n                          result_augmenters=result_augmenters,\n                          seed=d[\"seed\"],\n                          dataset_metadata=d[\"dataset_metadata\"],\n                          **d[\"kwargs\"])\n    except Exception as e:\n        raise Exception(f\"[SR_dataset.from_dict] Error creating dataset: {e}\")\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_benchmark","title":"SR_benchmark","text":"<pre><code>SR_benchmark(benchmark_name: str, base_dir: str, datasets: Optional[List[Union[SR_dataset, Tuple[str, SR_dataset]]]] = None, augmentation_map: dict = None, metadata: dict = None)\n</code></pre> <p>Initializes an instance of the SR_benchmark class. You can find examples of how to use this class in the feynman and nguyen methods below.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; len(benchmark.list_datasets(verbose=False))\n100\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>benchmark_name</code> <code>str</code> <p>The name of this benchmark.</p> required <code>base_dir</code> <code>str</code> <p>The directory where the datasets will be stored.</p> required <code>datasets</code> <code>Optional[List[Union[SR_dataset, Tuple[str, SR_dataset]]]]</code> <p>A list of SR_dataset instances or tuples containing the name of the dataset and an instance of SR_dataset. When name of the dataset is not provided, the dataset will be named 'benchmark_name'_'index of dataset in the list + 1'</p> <code>None</code> <code>augmentation_map</code> <code>dict</code> <p>A dictionary mapping augmenter names to their respective classes.</p> <code>None</code> <code>metadata</code> <code>dict</code> <p>An optional dictionary containing metadata about this benchmark. This could include information such as the name of the benchmark, a citation for the benchmark, number of datasets, etc.</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If elements in the \"datasets\" argument are not instances of SR_dataset or tuples containing the name of the dataset and an instance of SR_dataset.</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>def __init__(self, benchmark_name: str, base_dir: str,\n             datasets: Optional[List[Union[SR_dataset, Tuple[str, SR_dataset]]]] = None,\n             augmentation_map: dict = None, metadata: dict = None):\n    \"\"\"\n    Initializes an instance of the SR_benchmark class. You can find examples of how to use this class in the\n    feynman and nguyen methods below.\n\n    Examples:\n        &gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; len(benchmark.list_datasets(verbose=False))\n        100\n\n    Args:\n        benchmark_name: The name of this benchmark.\n        base_dir: The directory where the datasets will be stored.\n        datasets: A list of SR_dataset instances or tuples containing the name of the dataset and an instance of\n            SR_dataset. When name of the dataset is not provided, the dataset will be named\n            'benchmark_name'_'index of dataset in the list + 1'\n        augmentation_map: A dictionary mapping augmenter names to their respective classes.\n        metadata: An optional dictionary containing metadata about this benchmark. This could include information\n            such as the name of the benchmark, a citation for the benchmark, number of datasets, etc.\n\n    Raises:\n        Exception: If elements in the \"datasets\" argument are not instances of SR_dataset or tuples containing\n            the name of the dataset and an instance of SR_dataset.\n    \"\"\"\n    self.benchmark_name = benchmark_name\n    self.base_dir = base_dir\n    if augmentation_map is None:\n        self.augmentation_map = RESULT_AUGMENTERS\n    self.datasets = {}\n    self.metadata = {} if metadata is None else metadata\n    if datasets is not None:\n        for i, dataset in enumerate(datasets):\n            if isinstance(dataset, SR_dataset):\n                self.add_dataset_instance(benchmark_name + \"_\" + str(i+1), dataset)\n            elif isinstance(dataset, tuple) and isinstance(dataset[0], str) and isinstance(dataset[1], SR_dataset):\n                self.add_dataset_instance(dataset[0], dataset[1])\n            else:\n                raise ValueError(\"[SR_benchmark] Dataset inside the datasets argument must be either a tuple \"\n                                 \"(name, SR_dataset) or a SR_dataset instance.\")\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_benchmark.add_dataset_instance","title":"add_dataset_instance","text":"<pre><code>add_dataset_instance(dataset_name: str, dataset: SR_dataset)\n</code></pre> <p>Adds an instance of the SR_dataset class to the benchmark.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; dataset = benchmark.create_dataset('I.16.6')\n&gt;&gt;&gt; isinstance(dataset, SR_dataset)\nTrue\n&gt;&gt;&gt; bm = SR_benchmark(\"BM\", \"data/bm\")\n&gt;&gt;&gt; bm.add_dataset_instance(\"I.16.6\", dataset)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name of the dataset.</p> required <code>dataset</code> <code>SR_dataset</code> <p>An instance of the SR_dataset class.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If the dataset name already exists in the benchmark.</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>def add_dataset_instance(self, dataset_name: str, dataset: SR_dataset):\n    \"\"\"\n    Adds an instance of the SR_dataset class to the benchmark.\n\n    Examples:\n        &gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; dataset = benchmark.create_dataset('I.16.6')\n        &gt;&gt;&gt; isinstance(dataset, SR_dataset)\n        True\n        &gt;&gt;&gt; bm = SR_benchmark(\"BM\", \"data/bm\")\n        &gt;&gt;&gt; bm.add_dataset_instance(\"I.16.6\", dataset)\n\n    Args:\n         dataset_name: The name of the dataset.\n         dataset: An instance of the SR_dataset class.\n\n    Raises:\n        Exception: If the dataset name already exists in the benchmark.\n    \"\"\"\n    if dataset_name in self.datasets:\n        raise ValueError(f\"Dataset {dataset_name} already exists in the benchmark.\")\n    else:\n        self.datasets[dataset_name] = {}\n    self.datasets[dataset_name][\"sr_dataset\"] = dataset\n    self.datasets[dataset_name][\"num_variables\"] = dataset.X.shape[1]\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_benchmark.add_dataset","title":"add_dataset","text":"<pre><code>add_dataset(dataset: Union[str, array, Tuple[array, array]], symbol_library: SymbolLibrary, dataset_name: Optional[str] = None, ranking_function: str = 'rmse', max_evaluations: int = -1, ground_truth: Optional[Union[List[str], Node, ndarray]] = None, original_equation: Optional[str] = None, success_threshold: Optional[float] = None, result_augmenters: Optional[List[ResultAugmenter]] = None, seed: Optional[int] = None, dataset_metadata: Optional[dict] = None, **kwargs)\n</code></pre> <p>Adds a dataset to the benchmark.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; fey_benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; benchmark = SR_benchmark(\"BM\", \"data/bm\")\n&gt;&gt;&gt; benchmark.add_dataset(\"data/feynman/I.14.3.npz\", SymbolLibrary.default_symbols(3),\n...       dataset_name=\"I.14.3\", ranking_function=\"rmse\", ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\"],\n...       original_equation=\"U = m*g*z\", max_evaluations=100000, max_expression_length=50,\n...       success_threshold=1e-7, dataset_metadata={}, constant_range=[-5.0, 5.0], result_augmenters=[],\n...       seed = 42)\n&gt;&gt;&gt; len(benchmark.list_datasets(verbose=False))\n1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[str, array, Tuple[array, array]]</code> <p>Data used in the dataset. Can be: - A string representing the path to a NumPy archive (.npz) containing the dataset. It should either the absolute path to the data, path relative to the base_dir 'base_dir'/'dataset', or empty, in that case the dataset will be loaded from 'base_dir'/'dataset_name'.npz. The .npz file must contain the features (saved in 'X') and if 'rmse' is used as the ranking function, the target (saved in 'y'). - A 2d numpy array containing the features (X). If 'rmse' is used as the ranking function, ground truth should also be provided to calculate the target (y). Once added, the data will be saved at 'base_dir'/'dataset_name'.npz. - A tuple containing the features (X) and the target (y). If 'bed' is used as the ranking function, the target will be ignored. Once added, the data will be saved at 'base_dir'/'dataset_name'.npz.</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use.</p> required <code>dataset_name</code> <code>Optional[str]</code> <p>The name of the dataset. If None, a name will be generated automatically as 'benchmark_name'_'index+1'.</p> <code>None</code> <code>ranking_function</code> <code>str</code> <p>The ranking function used during evaluation. Can be: 'rmse', 'bed'.</p> <code>'rmse'</code> <code>max_evaluations</code> <code>int</code> <p>The maximum number of expressions to evaluate. Less than 0 means no limit.</p> <code>-1</code> <code>ground_truth</code> <code>Optional[Union[List[str], Node, ndarray]]</code> <p>The ground truth expression. Can either a list of symbols, a SRToolkit.utils.Node, or a numpy array representing behavior of an expressions. When 'bed' is used as the ranking function, ground truth must be provided.</p> <code>None</code> <code>original_equation</code> <code>Optional[str]</code> <p>The original equation from which the ground truth expression was generated.</p> <code>None</code> <code>success_threshold</code> <code>Optional[float]</code> <p>The threshold below which the experiment is considered successful. If None, the threshold will be calculated automatically. See SRToolkit.evaluation.SR_evaluator for more details.</p> <code>None</code> <code>result_augmenters</code> <code>Optional[List[ResultAugmenter]]</code> <p>The list of result augmenters to use.</p> <code>None</code> <code>seed</code> <code>Optional[int]</code> <p>The seed to use for random number generation. If None, number generation will be random.</p> <code>None</code> <code>dataset_metadata</code> <code>Optional[dict]</code> <p>An optional dictionary containing metadata about this dataset. This could include information such as the name of the dataset, a citation for the dataset, number of variables, etc.</p> <code>None</code> <p>Other Parameters:</p> Name Type Description <code>method</code> <code>str</code> <p>The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested. Default is \"L-BFGS-B\".</p> <code>tol</code> <code>float</code> <p>The tolerance for termination. Default is 1e-6.</p> <code>gtol</code> <code>float</code> <p>The tolerance for the gradient norm. Default is 1e-3.</p> <code>max_iter</code> <code>int</code> <p>The maximum number of iterations. Default is 100.</p> <code>constant_bounds</code> <code>Tuple[float, float]</code> <p>A tuple of two elements, specifying the lower and upper bounds for the constant values. Default is (-5, 5).</p> <code>initialization</code> <code>str</code> <p>The method to use for initializing the constant values. Currently, only \"random\" and \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\" creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".</p> <code>max_constants</code> <code>int</code> <p>The maximum number of constants allowed in the expression. Default is 8.</p> <code>max_expr_length</code> <code>int</code> <p>The maximum length of the expression. Default is -1 (no limit).</p> <code>num_points_sampled</code> <code>int</code> <p>The number of points to sample when estimating the behavior of an expression. Default is 64. If num_points_sampled==-1, then the number of points sampled is equal to the number of points in the dataset.</p> <code>bed_X</code> <code>Optional[ndarray]</code> <p>Points used for BED evaluation. If None and domain_bounds are given, points are sampled from the domain. If None and domain_bounds are not givem, points are randomly selected from X. Default is None.</p> <code>num_consts_sampled</code> <code>int</code> <p>Number of constants sampled for BED evaluation. Default is 32.</p> <code>domain_bounds</code> <code>Optional[List[Tuple[float, float]]]</code> <p>Bounds for the domain to be used if bed_X is None to sample random points. Default is None.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When BED ranking function is used but ground truth is not provided. When dataset is given as a string (directory) that doesn't exist, is not a valid .npz file, or is a .npz file that doesn't contain one array for the BED ranking function (X) or two array for the RMSE ranking function (X, y). When the argument dataset is an array, ranking function RMSE and there is no ground truth or the expression given as the ground truth cannot be evaluated...</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>def add_dataset(\n    self,\n    dataset: Union[str, np.array, Tuple[np.array, np.array]],\n    symbol_library: SymbolLibrary,\n    dataset_name: Optional[str] = None,\n    ranking_function: str = \"rmse\",\n    max_evaluations: int = -1,\n    ground_truth: Optional[Union[List[str], Node, np.ndarray]] = None,\n    original_equation: Optional[str] = None,\n    success_threshold: Optional[float] = None,\n    result_augmenters: Optional[List[ResultAugmenter]] = None,\n    seed: Optional[int] = None,\n    dataset_metadata: Optional[dict] = None,\n    **kwargs\n):\n    \"\"\"\n    Adds a dataset to the benchmark.\n\n    Examples:\n        &gt;&gt;&gt; fey_benchmark = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; benchmark = SR_benchmark(\"BM\", \"data/bm\")\n        &gt;&gt;&gt; benchmark.add_dataset(\"data/feynman/I.14.3.npz\", SymbolLibrary.default_symbols(3),\n        ...       dataset_name=\"I.14.3\", ranking_function=\"rmse\", ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\"],\n        ...       original_equation=\"U = m*g*z\", max_evaluations=100000, max_expression_length=50,\n        ...       success_threshold=1e-7, dataset_metadata={}, constant_range=[-5.0, 5.0], result_augmenters=[],\n        ...       seed = 42)\n        &gt;&gt;&gt; len(benchmark.list_datasets(verbose=False))\n        1\n\n    Args:\n        dataset: Data used in the dataset. Can be:\n            - A string representing the path to a NumPy archive (.npz) containing the dataset. It should either\n            the absolute path to the data, path relative to the base_dir 'base_dir'/'dataset', or empty, in that\n            case the dataset will be loaded from 'base_dir'/'dataset_name'.npz. The .npz file must contain the\n            features (saved in 'X') and if 'rmse' is used as the ranking function, the target (saved in 'y').\n            - A 2d numpy array containing the features (X). If 'rmse' is used as the ranking function, ground truth\n            should also be provided to calculate the target (y). Once added, the data will be saved at\n            'base_dir'/'dataset_name'.npz.\n            - A tuple containing the features (X) and the target (y). If 'bed' is used as the ranking function,\n            the target will be ignored. Once added, the data will be saved at 'base_dir'/'dataset_name'.npz.\n        symbol_library: The symbol library to use.\n        dataset_name: The name of the dataset. If None, a name will be generated automatically as\n            'benchmark_name'_'index+1'.\n        ranking_function: The ranking function used during evaluation. Can be: 'rmse', 'bed'.\n        max_evaluations: The maximum number of expressions to evaluate. Less than 0 means no limit.\n        ground_truth: The ground truth expression. Can either a list of symbols, a SRToolkit.utils.Node, or a\n            numpy array representing behavior of an expressions. When 'bed' is used as the ranking function,\n            ground truth must be provided.\n        original_equation: The original equation from which the ground truth expression was generated.\n        success_threshold: The threshold below which the experiment is considered successful. If None, the\n            threshold will be calculated automatically. See SRToolkit.evaluation.SR_evaluator for more details.\n        result_augmenters: The list of result augmenters to use.\n        seed: The seed to use for random number generation. If None, number generation will be random.\n        dataset_metadata: An optional dictionary containing metadata about this dataset. This could include\n            information such as the name of the dataset, a citation for the dataset, number of variables, etc.\n\n    Keyword Arguments:\n        method (str): The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested.\n            Default is \"L-BFGS-B\".\n        tol (float): The tolerance for termination. Default is 1e-6.\n        gtol (float): The tolerance for the gradient norm. Default is 1e-3.\n        max_iter (int): The maximum number of iterations. Default is 100.\n        constant_bounds (Tuple[float, float]): A tuple of two elements, specifying the lower and upper bounds for\n            the constant values. Default is (-5, 5).\n        initialization (str): The method to use for initializing the constant values. Currently, only \"random\" and\n            \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\"\n            creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".\n        max_constants (int): The maximum number of constants allowed in the expression. Default is 8.\n        max_expr_length (int): The maximum length of the expression. Default is -1 (no limit).\n        num_points_sampled (int): The number of points to sample when estimating the behavior of an expression.\n            Default is 64. If num_points_sampled==-1, then the number of points sampled is equal to the number of\n            points in the dataset.\n        bed_X (Optional[np.ndarray]): Points used for BED evaluation. If None and domain_bounds are given, points\n            are sampled from the domain. If None and domain_bounds are not givem, points are randomly selected\n            from X. Default is None.\n        num_consts_sampled (int): Number of constants sampled for BED evaluation. Default is 32.\n        domain_bounds (Optional[List[Tuple[float, float]]]): Bounds for the domain to be used if bed_X is None to\n            sample random points. Default is None.\n\n    Raises:\n        ValueError: When BED ranking function is used but ground truth is not provided. When dataset is given as\n            a string (directory) that doesn't exist, is not a valid .npz file, or is a .npz file that doesn't\n            contain one array for the BED ranking function (X) or two array for the RMSE ranking function (X, y).\n            When the argument dataset is an array, ranking function RMSE and there is no ground truth or the\n            expression given as the ground truth cannot be evaluated...\n    \"\"\"\n    if dataset_name is None:\n        dataset_name = f\"{self.benchmark_name}_{len(self.datasets)+1}\"\n\n    self.datasets[dataset_name] = {}\n    self.datasets[dataset_name][\"symbol_library\"] = symbol_library.to_dict()\n    self.datasets[dataset_name][\"ranking_function\"] = ranking_function\n    self.datasets[dataset_name][\"max_evaluations\"] = max_evaluations\n\n    self.datasets[dataset_name][\"success_threshold\"] = success_threshold\n    self.datasets[dataset_name][\"result_augmenters\"] = [re.to_dict(self.base_dir, dataset_name) for re in result_augmenters]\n    self.datasets[dataset_name][\"seed\"] = seed\n    self.datasets[dataset_name][\"dataset_metadata\"] = copy.deepcopy(self.metadata).update(dataset_metadata)\n\n    if \"bed_X\" in kwargs and kwargs[\"bed_X\"] is not None:\n        kwargs[\"bed_X\"] = kwargs[\"bed_X\"].tolist()\n\n    self.datasets[dataset_name][\"kwargs\"] = kwargs\n    self.datasets[dataset_name][\"original_equation\"] = original_equation\n    self.datasets[dataset_name][\"ground_truth\"] = ground_truth\n\n    if ground_truth is None:\n        if ranking_function == \"bed\":\n            raise ValueError(\"[SR_benchmark.add_dataset] For 'bed' ranking, the ground truth must be provided. \")\n        else:\n            print(f\"[SR_benchmark.add_dataset] 'ground_truth' argument not provided. We recommend providing it \"\n                  f\"for more transparent evaluation.\")\n    else:\n        if original_equation is None:\n            if isinstance(ground_truth, str):\n                self.datasets[dataset_name][\"original_equation\"] = \"y = \" + ground_truth\n            elif isinstance(ground_truth, list):\n                self.datasets[dataset_name][\"original_equation\"] = \"y = \" + \"\".join(ground_truth)\n\n    if isinstance(dataset, str):\n        dataset_path = None\n        if os.path.exists(dataset):\n            dataset_path = dataset\n        elif dataset != \"\" and os.path.exists(f\"{self.base_dir}/{dataset}\"):\n            dataset_path = f\"{self.base_dir}/{dataset}\"\n        elif os.path.exists(f\"{self.base_dir}/{dataset_name}.npz\"):\n            dataset_path = f\"{self.base_dir}/{dataset_name}.npz\"\n\n        if dataset_path is None:\n            error_msg = (\n                f\"[SR_benchmark.add_dataset] Could not find the dataset file. \"\n                f\"Expected locations:\\n\"\n                f\"- Absolute path: '{dataset}'\\n\"\n                f\"- Relative to base_dir: '{self.base_dir}/{dataset}'\\n\"\n                f\"- NPZ with the name of the dataset in base_dir: '{self.base_dir}/{dataset_name}.npz'\"\n            )\n            raise FileNotFoundError(error_msg)\n\n        self.datasets[dataset_name][\"dataset_path\"] = dataset_path\n\n        try:\n            data = np.load(self.datasets[dataset_name][\"dataset_path\"], allow_pickle=False)\n        except IOError as e:\n            error_msg = (\n                f\"[SR_benchmark.add_dataset] Could not load dataset from path '{self.datasets[dataset_name]}' \"\n                f\"using np.load. The file may be corrupt or not a valid NumPy archive (.npz). \"\n                f\"Original error: {e}\"\n            )\n            raise IOError(error_msg) from e\n\n        if ranking_function == \"rmse\":\n            if not (isinstance(data, np.lib.npyio.NpzFile) and \"X\" in data and \"y\" in data):\n                error_msg = (\n                    f\"[SR_benchmark.add_dataset] For 'rmse' ranking, the dataset file \"\n                    f\"('{self.datasets[dataset_name]['dataset_path']}') must be a .npz NumPy archive containing \"\n                    f\"both 'X' (features) and 'y' (targets). It should be created via `np.savez(path, X=X, y=y)`.\"\n                )\n                raise ValueError(error_msg)\n\n        elif ranking_function == \"bed\":\n            if not (isinstance(data, np.lib.npyio.NpzFile) and \"X\" in data):\n                error_msg = (\n                    f\"[SR_benchmark.add_dataset] For 'bed' ranking, the dataset file \"\n                    f\"('{self.datasets[dataset_name]['dataset_path']}') must be a .npz NumPy archive \"\n                    f\"containing 'X' (features). It should be created via `np.savez(path, X=X)`.\"\n                )\n                raise ValueError(error_msg)\n\n        num_variables = data['X'].shape[1]\n\n    elif isinstance(dataset, np.ndarray):\n        if ranking_function == \"rmse\" and ground_truth is not None:\n            try:\n                expr = expr_to_executable_function(ground_truth, symbol_library)\n                y = expr(dataset, None)\n            except Exception as e:\n                raise Exception(f\"[SR_benchmark.add_dataset] Could not evaluate the ground truth. \"\n                                f\"Original error: {e}\")\n            if not os.path.isdir(self.base_dir):\n                os.makedirs(self.base_dir)\n            np.savez(f\"{self.base_dir}/{dataset_name}.npz\", X=dataset, y=y, allow_pickle=False)\n        elif ranking_function == \"rmse\" and ground_truth is None:\n            raise ValueError(\"[SR_benchmark.add_dataset] For 'rmse' ranking, if the dataset argument is a numpy \"\n                             \"array, the ground truth must be provided in order for the target values to be \"\n                             \"calculated.\")\n        elif ranking_function == \"bed\":\n            if not os.path.isdir(self.base_dir):\n                os.makedirs(self.base_dir)\n            np.savez(f\"{self.base_dir}/{dataset_name}.npz\", X=dataset, allow_pickle=False)\n\n        self.datasets[dataset_name][\"dataset_path\"] = f\"{self.base_dir}/{dataset_name}.npz\"\n        num_variables = dataset.shape[1]\n\n    elif isinstance(dataset, tuple):\n        if not isinstance(dataset[0], np.ndarray) or not isinstance(dataset[1], np.ndarray):\n            raise ValueError(\"[SR_benchmark.add_dataset] When dataset argument is provided as a tuple, both \"\n                             \"values must be a numpy array. The first array represents the features ('X'), \"\n                             \"the second array represents the targets ('y').\")\n        if ranking_function == \"bed\":\n            print(f\"[SR_benchmark.add_dataset] 'bed' ranking only utilizes the array with feature. Array with \"\n                  f\"targets will be ignored.\")\n        if not os.path.isdir(self.base_dir):\n            os.makedirs(self.base_dir)\n        np.savez(f\"{self.base_dir}/{dataset_name}.npz\", X=dataset[0], y=dataset[1], allow_pickle=False)\n        self.datasets[dataset_name][\"dataset_path\"] = f\"{self.base_dir}/{dataset_name}.npz\"\n        num_variables = dataset[0].shape[1]\n\n    else:\n        raise ValueError(\"[SR_benchmark.add_dataset] The dataset argument must be a string, a numpy array, \"\n                         \"or a tuple containing two numpy arrays.\")\n\n    self.datasets[dataset_name][\"num_variables\"] = num_variables\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_benchmark.create_dataset","title":"create_dataset","text":"<pre><code>create_dataset(dataset_name: str) -&gt; SR_dataset\n</code></pre> <p>Creates an instance of a dataset from the given dataset name.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; dataset = benchmark.create_dataset('I.16.6')\n&gt;&gt;&gt; dataset.X.shape\n(10000, 3)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name of the dataset to create.</p> required <p>Returns:</p> Type Description <code>SR_dataset</code> <p>A SR_dataset instance containing the data, ground truth expression, and metadata for the given dataset.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset name is not found in the available datasets.</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>def create_dataset(self, dataset_name: str) -&gt; SR_dataset:\n    \"\"\"\n    Creates an instance of a dataset from the given dataset name.\n\n    Examples:\n        &gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; dataset = benchmark.create_dataset('I.16.6')\n        &gt;&gt;&gt; dataset.X.shape\n        (10000, 3)\n\n    Args:\n        dataset_name: The name of the dataset to create.\n\n    Returns:\n        A SR_dataset instance containing the data, ground truth expression, and metadata for the given dataset.\n\n    Raises:\n        ValueError: If the dataset name is not found in the available datasets.\n    \"\"\"\n    if dataset_name in self.datasets:\n        if \"sr_dataset\" in self.datasets[dataset_name]:\n            return self.datasets[dataset_name][\"sr_dataset\"]\n        else:\n            try:\n                return SR_dataset.from_dict(self.datasets[dataset_name], self.augmentation_map)\n            except Exception as e:\n                raise ValueError(f\"[SR_benchmark.create_dataset] Could not create SR_dataset from the given \"\n                                 f\"given dictionary. Original error: {e}\")\n\n    else:\n        raise ValueError(f\"Dataset {dataset_name} not found\")\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_benchmark.list_datasets","title":"list_datasets","text":"<pre><code>list_datasets(verbose=True, num_variables: int = -1) -&gt; List[str]\n</code></pre> <p>Lists the available datasets.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; len(benchmark.list_datasets(num_variables=2, verbose=False))\n15\n&gt;&gt;&gt; datasets_with_8_vars = benchmark.list_datasets(num_variables=8, verbose=False)\n&gt;&gt;&gt; datasets_with_8_vars[0]\n'II.36.38'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>If True, also prints out a description of each dataset.</p> <code>True</code> <code>num_variables</code> <code>int</code> <p>If not -1, only show datasets with the given number of variables.</p> <code>-1</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of dataset names.</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>def list_datasets(self, verbose=True, num_variables: int = -1) -&gt; List[str]:\n    \"\"\"\n    Lists the available datasets.\n\n    Examples:\n        &gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; len(benchmark.list_datasets(num_variables=2, verbose=False))\n        15\n        &gt;&gt;&gt; datasets_with_8_vars = benchmark.list_datasets(num_variables=8, verbose=False)\n        &gt;&gt;&gt; datasets_with_8_vars[0]\n        'II.36.38'\n\n    Args:\n        verbose (bool): If True, also prints out a description of each dataset.\n        num_variables (int): If not -1, only show datasets with the given number of variables.\n\n    Returns:\n        A list of dataset names.\n    \"\"\"\n    datasets = [\n        dataset_name\n        for dataset_name in self.datasets\n        if num_variables &lt; 0\n        or self.datasets[dataset_name][\"num_variables\"] == num_variables\n    ]\n    datasets = sorted(\n        datasets,\n        key=lambda dataset_name: (\n            self.datasets[dataset_name][\"num_variables\"],\n            dataset_name,\n        ),\n    )\n\n    if verbose:\n        part1 = []\n        part2 = []\n        part3 = []\n        max_length_1 = 0\n        max_length_2 = 0\n        for d in datasets:\n            if self.datasets[d][\"num_variables\"] == 1:\n                variable_str = \"1 variable\"\n            elif self.datasets[d][\"num_variables\"] &lt; 1:\n                variable_str = \"Amount of variables unknown\"\n            else:\n                variable_str = f\"{self.datasets[d]['num_variables']} variables\"\n            part1.append(d+\":\")\n            part2.append(variable_str)\n            part3.append(self.datasets[d][\"original_equation\"])\n            if len(d)+1 &gt; max_length_1:\n                max_length_1 = len(d)+1\n            if len(variable_str) &gt; max_length_2:\n                max_length_2 = len(variable_str)\n\n        for p1, p2, p3 in zip(part1, part2, part3):\n            print(f\"{p1:&lt;{max_length_1}} {p2:&lt;{max_length_2}}, Expression: {p3}\")\n    return datasets\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_benchmark.download_benchmark_data","title":"download_benchmark_data  <code>staticmethod</code>","text":"<pre><code>download_benchmark_data(url, directory_path)\n</code></pre> <p>Downloads a benchmark dataset from the given url to the given directory path.</p> <p>This function will first check if the directory_path exists. If not, it will create it. Then it will check if the directory_path is empty. If it is not empty, it will not download the data. If it is empty, it will download the data from the given url and extract it to the directory_path.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; url = \"https://raw.githubusercontent.com/smeznar/SymbolicRegressionToolkit/master/data/feynman.zip\"\n&gt;&gt;&gt; dataset_directory = 'data/feynman'\n&gt;&gt;&gt; SR_benchmark.download_benchmark_data(url, dataset_directory)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The url of the benchmark dataset to download.</p> required <code>directory_path</code> <code>str</code> <p>The path of the directory where the dataset should be downloaded.</p> required Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>@staticmethod\ndef download_benchmark_data(url, directory_path):\n    \"\"\"\n    Downloads a benchmark dataset from the given url to the given directory path.\n\n    This function will first check if the directory_path exists. If not, it will create it. Then it will check if the directory_path is empty. If it is not empty, it will not download the data. If it is empty, it will download the data from the given url and extract it to the directory_path.\n\n    Examples:\n        &gt;&gt;&gt; url = \"https://raw.githubusercontent.com/smeznar/SymbolicRegressionToolkit/master/data/feynman.zip\"\n        &gt;&gt;&gt; dataset_directory = 'data/feynman'\n        &gt;&gt;&gt; SR_benchmark.download_benchmark_data(url, dataset_directory)\n\n    Args:\n        url (str): The url of the benchmark dataset to download.\n        directory_path (str): The path of the directory where the dataset should be downloaded.\n    \"\"\"\n    if not os.path.exists(directory_path):\n        os.makedirs(directory_path)\n\n    # Check if directory_path is empty\n    if not os.listdir(directory_path):\n        http_response = urlopen(url)\n        zipfile = ZipFile(BytesIO(http_response.read()))\n        zipfile.extractall(path=directory_path)\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_benchmark.save_benchmark","title":"save_benchmark","text":"<pre><code>save_benchmark()\n</code></pre> <p>Saves the benchmark to a json file. The json file will contain the metadata about datasets and metadata of the benchmark. Data is not directly saved to the json file, but contains paths to the datasets.</p> <p>Saved data can be loaded using SR_benchmark.load_benchmark method.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; benchmark.save_benchmark()\n</code></pre> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>def save_benchmark(self):\n    \"\"\"\n    Saves the benchmark to a json file. The json file will contain the metadata about datasets\n    and metadata of the benchmark. Data is not directly saved to the json file, but contains paths to the datasets.\n\n    Saved data can be loaded using SR_benchmark.load_benchmark method.\n\n    Examples:\n        &gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; benchmark.save_benchmark()\n    \"\"\"\n    datasets = []\n    for dataset_name, dataset_info in self.datasets.items():\n        if \"sr_dataset\" in dataset_info:\n            datasets.append({\"name\": dataset_name,\n                             \"info\": dataset_info[\"sr_dataset\"].to_dict(self.base_dir, dataset_name)})\n        else:\n            datasets.append({\"name\": dataset_name,\n                             \"info\": dataset_info})\n\n    output = {\"datasets\": datasets,\n              \"metadata\": self.metadata,\n              \"name\": self.benchmark_name}\n\n    with open(f\"{self.base_dir}/dataset_info.json\", \"w\") as f:\n        json.dump(output, f)\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_benchmark.load_benchmark","title":"load_benchmark  <code>staticmethod</code>","text":"<pre><code>load_benchmark(base_dir: str) -&gt; SR_benchmark\n</code></pre> <p>Loads a benchmark stored at the base directory, returning an instance of SR_benchmark.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; b1 = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; b2 = SR_benchmark.load_benchmark('data/feynman')\n&gt;&gt;&gt; len(b1.list_datasets(verbose=False))\n100\n&gt;&gt;&gt; len(b2.list_datasets(verbose=False))\n100\n&gt;&gt;&gt; dataset_name = b2.list_datasets(verbose=False)[0]\n&gt;&gt;&gt; dataset = b2.create_dataset(dataset_name)\n&gt;&gt;&gt; rmse = dataset.create_evaluator().evaluate_expr(dataset.ground_truth)\n&gt;&gt;&gt; rmse &lt; dataset.success_threshold\nTrue\n</code></pre> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>@staticmethod\ndef load_benchmark(base_dir: str) -&gt; \"SR_benchmark\":\n    \"\"\"\n    Loads a benchmark stored at the base directory, returning an instance of SR_benchmark.\n\n    Examples:\n        &gt;&gt;&gt; b1 = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; b2 = SR_benchmark.load_benchmark('data/feynman')\n        &gt;&gt;&gt; len(b1.list_datasets(verbose=False))\n        100\n        &gt;&gt;&gt; len(b2.list_datasets(verbose=False))\n        100\n        &gt;&gt;&gt; dataset_name = b2.list_datasets(verbose=False)[0]\n        &gt;&gt;&gt; dataset = b2.create_dataset(dataset_name)\n        &gt;&gt;&gt; rmse = dataset.create_evaluator().evaluate_expr(dataset.ground_truth)\n        &gt;&gt;&gt; rmse &lt; dataset.success_threshold\n        True\n\n    \"\"\"\n    with open(f\"{base_dir}/dataset_info.json\", \"r\") as f:\n        data = json.load(f)\n\n    datasets = {}\n    for dataset_info in data[\"datasets\"]:\n        datasets[dataset_info[\"name\"]] = dataset_info[\"info\"]\n\n    benchmark = SR_benchmark(data[\"name\"], base_dir, metadata=data[\"metadata\"])\n    benchmark.datasets = datasets\n    return benchmark\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_benchmark.feynman","title":"feynman  <code>staticmethod</code>","text":"<pre><code>feynman(dataset_directory: str, seed: Optional[int] = None) -&gt; SR_benchmark\n</code></pre> <p>Downloads the Feynman benchmark dataset, sets up symbol libraries, and adds predefined datasets to the benchmark.</p> <p>This method downloads the Feynman benchmark dataset from a specified URL, initializes symbol libraries for symbolic regression with varying numbers of variables, and adds multiple predefined datasets to the benchmark with their respective equations and metadata. For each data set, we randomly sampled 10,000 examples instead of 1,000,000 as in the original paper.</p> <p>For more information about the Feynman benchmark, see the following paper: https://doi.org/10.1126/sciadv.aay2631</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; for dataset in benchmark.list_datasets(verbose=False):\n...     ds = benchmark.create_dataset(dataset)\n...     rmse = ds.create_evaluator().evaluate_expr(ds.ground_truth)\n...     if rmse &gt; ds.success_threshold:\n...         print(f'Failed dataset: {dataset} with RMSE {rmse}')\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dataset_directory</code> <code>str</code> <p>The directory path where the benchmark dataset will be downloaded and stored or where it will be loaded from.</p> required <code>seed</code> <code>Optional[int]</code> <p>The seed to use for the random number generator. If None, the random number generation will not be seeded</p> <code>None</code> <p>Returns:</p> Name Type Description <code>SR_benchmark</code> <code>SR_benchmark</code> <p>An instance of the SR_benchmark class containing the predefined datasets.</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>    @staticmethod\n    def feynman(dataset_directory: str, seed: Optional[int] = None) -&gt; \"SR_benchmark\":\n        \"\"\"\n        Downloads the Feynman benchmark dataset, sets up symbol libraries, and adds predefined datasets to the benchmark.\n\n        This method downloads the Feynman benchmark dataset from a specified URL, initializes symbol libraries for\n        symbolic regression with varying numbers of variables, and adds multiple predefined datasets to the benchmark\n        with their respective equations and metadata. For each data set, we randomly sampled 10,000 examples instead\n        of 1,000,000 as in the original paper.\n\n        For more information about the Feynman benchmark, see the following paper: &lt;https://doi.org/10.1126/sciadv.aay2631&gt;\n\n        Examples:\n            &gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n            &gt;&gt;&gt; for dataset in benchmark.list_datasets(verbose=False):\n            ...     ds = benchmark.create_dataset(dataset)\n            ...     rmse = ds.create_evaluator().evaluate_expr(ds.ground_truth)\n            ...     if rmse &gt; ds.success_threshold:\n            ...         print(f'Failed dataset: {dataset} with RMSE {rmse}')\n\n        Args:\n            dataset_directory: The directory path where the benchmark dataset will be downloaded and stored or where\n                it will be loaded from.\n            seed: The seed to use for the random number generator. If None, the random number generation will not\n                be seeded\n\n        Returns:\n            SR_benchmark: An instance of the SR_benchmark class containing the predefined datasets.\n        \"\"\"\n        url = \"https://raw.githubusercontent.com/smeznar/SymbolicRegressionToolkit/master/data/feynman.zip\"\n\n        metadata = {\"description\": \"Feynman benchmark containing 100 equations from the domain of physics. \"\n                                   \"Expressions can contain up to 9 variables.\",\n                    \"citation\": \"\"\"@article{Tegmark2020Feynman,\n  title={{AI Feynman: A physics-inspired method for symbolic regression}},\n  author={Udrescu, Silviu-Marian and Tegmark, Max},\n  journal={Science Advances},\n  volume={6},\n  number={16},\n  pages={eaay2631},\n  year={2020},\n  publisher={American Association for the Advancement of Science}\n}\n\"\"\"\n                    }\n\n        SR_benchmark.download_benchmark_data(url, dataset_directory)\n\n        sl_1v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 1)\n        sl_2v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 2)\n        sl_3v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 3)\n        sl_4v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 4)\n        sl_5v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 5)\n        sl_6v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 6)\n        sl_8v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 8)\n        sl_9v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 9)\n\n        benchmark = SR_benchmark(\"feynman\", dataset_directory)\n        benchmark.metadata = metadata\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.16.6\",\n            ranking_function=\"rmse\",\n            max_evaluations=100000,\n            ground_truth = [\"(\", \"X_2\", \"+\",\"X_1\",\")\",\"/\",\"(\",\"1\",\"+\",\"(\",\"X_2\",\"*\",\"X_1\",\")\",\"/\",\"(\",\"X_0\",\"^2\",\")\",\")\"], # noqa: F401\n            original_equation=\"v1 = (u+v)/(1+u*v/c^2)\",\n            success_threshold=1e-7,\n            result_augmenters=[],\n            seed = seed,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            max_expression_length=50,\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.15.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"u-\", \"X_0\", \"*\", \"X_1\", \"*\", \"cos\", \"(\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"E_n = -mom*B*cos(theta)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.27.16\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"^2\"], # noqa: F401\n            original_equation=\"flux = epsilon*c*Ef^2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_6v,\n            dataset_name=\"I.11.19\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_3\", \"+\", \"X_1\", \"*\", \"X_4\", \"+\", \"X_2\", \"*\", \"X_5\"], # noqa: F401\n            original_equation=\"A = x1*y1+x2*y2+x3*y3\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.15.3x\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"-\", \"X_1\", \"*\", \"X_3\", \")\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"x1 = (x-u*t)/sqrt(1-u^2/c^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.10.7\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"m = m_0/sqrt(1-v^2/c^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_9v,\n            dataset_name=\"I.9.18\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_2\", \"*\", \"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"(\", \"X_4\", \"-\", \"X_3\", \")\", \"^2\", \"+\", \"(\", \"X_6\", \"-\", \"X_5\", \")\", \"^2\", \"+\", \"(\", \"X_8\", \"-\", \"X_7\", \")\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"F = G*m1*m2/((x2-x1)^2+(y2-y1)^2+(z2-z1)^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.15.3t\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_3\", \"-\", \"X_2\", \"*\", \"X_0\", \"/\", \"X_1\", \"^2\", \")\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_2\", \"^2\", \"/\", \"X_1\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"t1 = (t-u*x/c^2)/sqrt(1-u^2/c^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_8v,\n            dataset_name=\"II.36.38\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"*\", \"X_1\", \")\", \"/\", \"(\", \"X_2\", \"*\", \"X_3\", \")\", \"+\", \"(\", \"(\", \"X_0\", \"*\", \"X_4\", \")\", \"/\", \"(\", \"X_5\", \"*\", \"X_6\", \"^2\", \"*\", \"X_2\", \"*\", \"X_3\", \")\", \")\", \"*\", \"X_7\"], # noqa: F401\n            original_equation=\"f = mom*H/(kb*T)+(mom*alpha)/(epsilon*c**2*kb*T)*M\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.43.43\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"1\", \"/\", \"(\", \"X_0\", \"-\", \"1\", \")\", \")\", \"*\", \"X_1\", \"*\", \"X_3\", \"/\", \"X_2\"], # noqa: F401\n            original_equation=\"kappa = 1/(gamma-1)*kb*v/A\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.15.5\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"u-\", \"X_0\", \"*\", \"X_1\", \"*\", \"cos\", \"(\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"E_n = -p_d*Ef*cos(theta)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.37.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"+\", \"X_1\", \"+\", \"2\", \"*\", \"sqrt\", \"(\", \"X_0\", \"*\", \"X_1\", \")\", \"*\", \"cos\", \"(\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"Int = I1+I2+2*sqrt(I1*I2)*cos(delta)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"II.6.11\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"1\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_0\", \")\", \")\", \"*\", \"X_1\", \"*\", \"cos\", \"(\", \"X_2\", \")\", \"/\", \"X_3\", \"^2\"], # noqa: F401\n            original_equation=\"Volt = 1/(4*pi*epsilon)*p_d*cos(theta)/r^2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"III.7.38\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"2\", \"*\", \"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\"], # noqa: F401\n            original_equation=\"omega = 2*mom*B/(h/(2*pi))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.34.2a\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"2\", \"*\", \"pi\", \"*\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"l = q*v/(2*pi*r)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.13.23\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"rho_c = rho_c_0/sqrt(1-v^2/c^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.29.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"X_1\"], # noqa: F401\n            original_equation=\"k = omega/c\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.38.12\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"4\", \"*\", \"pi\", \"*\", \"X_3\", \"*\", \"(\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"^2\", \"/\", \"(\", \"X_0\", \"*\", \"X_1\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"r = 4*pi*epsilon*(h/(2*pi))^2/(m*q^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"III.15.27\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"2\", \"*\", \"pi\", \"*\", \"X_0\", \"/\", \"(\", \"X_1\", \"*\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"k = 2*pi*alpha/(n*d)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"I.41.16\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"*\", \"X_0\", \"^3\", \"/\", \"(\", \"pi\", \"^2\", \"*\", \"X_4\", \"^2\", \"*\", \"(\", \"exp\", \"(\", \"(\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"*\", \"X_0\", \"/\", \"(\", \"X_3\", \"*\", \"X_1\", \")\", \")\", \"-\", \"1\", \")\", \")\"], # noqa: F401\n            original_equation=\"L_rad = h/(2*pi)*omega^3/(pi^2*c^2*(exp((h/(2*pi))*omega/(kb*T))-1))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.48.20\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_2\", \"^2\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"E_n = m*c^2/sqrt(1-v^2/c^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.11.20\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"^2\", \"*\", \"X_2\", \"/\", \"(\", \"3\", \"*\", \"X_3\", \"*\", \"X_4\", \")\"], # noqa: F401\n            original_equation=\"Pol = n_rho*p_d^2*Ef/(3*kb*T)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.25.13\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"X_1\"], # noqa: F401\n            original_equation=\"Volt = q/C\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"III.15.12\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"2\", \"*\", \"X_0\", \"*\", \"(\", \"1\", \"-\", \"cos\", \"(\", \"X_1\", \"*\", \"X_2\", \")\", \")\"], # noqa: F401\n            original_equation=\"E_n = 2*U*(1-cos(k*d))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.24.6\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"0.25\", \"*\", \"X_0\", \"*\", \"(\", \"X_1\", \"^2\", \"+\", \"X_2\", \"^2\", \")\", \"*\", \"X_3\", \"^2\"], # noqa: F401\n            original_equation=\"E_n = 1/2*m*(omega^2+omega_0^2)*1/2*x^2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.34.27\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_1\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"*\", \"X_0\"], # noqa: F401\n            original_equation=\"E_n =(h/(2*pi))*omega\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.43.31\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_2\", \"*\", \"X_1\"], # noqa: F401\n            original_equation=\"D = mob*kb*T\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.29.16\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"sqrt\", \"(\", \"X_0\", \"^2\", \"+\", \"X_1\", \"^2\", \"-\", \"2\", \"*\", \"X_0\", \"*\", \"X_1\", \"*\", \"cos\", \"(\", \"X_2\", \"-\", \"X_3\", \")\", \")\"], # noqa: F401\n            original_equation=\"x = sqrt(x1^2+x2^2-2*x1*x2*cos(theta1-theta2))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.18.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"*\", \"X_2\", \"+\", \"X_1\", \"*\", \"X_3\", \")\", \"/\", \"(\", \"X_0\", \"+\", \"X_1\", \")\"], # noqa: F401\n            original_equation=\"r = (m1*r1+m2*r2)/(m1+m2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_6v,\n            dataset_name=\"II.6.15a\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_1\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_0\", \")\", \")\", \"*\", \"(\", \"3\", \"*\", \"X_5\", \"/\", \"(\", \"X_2\", \"^2\", \"*\", \"X_2\", \"^3\", \")\", \")\", \"*\", \"sqrt\", \"(\", \"X_3\", \"^2\", \"+\", \"X_4\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"Ef = p_d/(4*pi*epsilon)*3*z/r^5*sqrt(x^2+y^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.30.3\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"sin\", \"(\", \"X_2\", \"*\", \"X_1\", \"/\", \"2\", \")\", \"^2\", \"/\", \"sin\", \"(\", \"X_1\", \"/\", \"2\", \")\", \"^2\"], # noqa: F401\n            original_equation=\"Int = Int_0*sin(n*theta/2)^2/sin(theta/2)^2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_6v,\n            dataset_name=\"III.9.52\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"/\", \"(\", \"X_3\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \")\", \"*\", \"sin\", \"(\", \"(\", \"X_4\", \"-\", \"X_5\", \")\", \"*\", \"X_2\", \"/\", \"2\", \")\", \"^2\", \"/\", \"(\", \"(\", \"X_4\", \"-\", \"X_5\", \")\", \"*\", \"X_2\", \"/\", \"2\", \")\", \"^2\"], # noqa: F401\n            original_equation=\"prob = (p_d*Ef*t/(h/(2*pi)))*sin((omega-omega_0)*t/2)^2/((omega-omega_0)*t/2)^2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.34.2\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"/\", \"2\"], # noqa: F401\n            original_equation=\"mom = q*v*r/2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.39.11\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"1\", \"/\", \"(\", \"X_0\", \"-\", \"1\", \")\", \")\", \"*\", \"X_1\", \"*\", \"X_2\"], # noqa: F401\n            original_equation=\"E_n = (1/(gamma-1))*pr*V\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"II.11.28\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"1\", \"+\", \"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"1\", \"-\", \"(\", \"X_0\", \"*\", \"X_1\", \"/\", \"3\", \")\", \")\"], # noqa: F401\n            original_equation=\"theta = 1+n*alpha/(1-(n*alpha/3))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"II.3.24\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_1\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"flux = Pwr/(4*pi*r^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.24.17\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"sqrt\", \"(\", \"X_0\", \"^2\", \"/\", \"X_1\", \"^2\", \"-\", \"pi\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"k = sqrt(omega^2/c^2-pi^2/d^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"II.13.17\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"1\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_0\", \"*\", \"X_1\", \"^2\", \")\", \")\", \"*\", \"2\", \"*\", \"X_2\", \"/\", \"X_3\"], # noqa: F401\n            original_equation=\"B = 1/(4*pi*epsilon*c^2)*2*I/r\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.12.5\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\"], # noqa: F401\n            original_equation=\"F = q2*Ef\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.35.18\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"(\", \"exp\", \"(\", \"X_3\", \"*\", \"X_4\", \"/\", \"(\", \"X_1\", \"*\", \"X_2\", \")\", \")\", \"+\", \"exp\", \"(\", \"u-\", \"X_3\", \"*\", \"X_4\", \"/\", \"(\", \"X_1\", \"*\", \"X_2\", \")\", \")\", \")\"], # noqa: F401\n            original_equation=\"n = n_0/(exp(mom*B/(kb*T))+exp(-mom*B/(kb*T)))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"II.34.11\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"X_3\", \")\"], # noqa: F401\n            original_equation=\"omega = g_*q*B/(2*m)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.34.29a\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"E_n = q*h/(4*pi*m)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_6v,\n            dataset_name=\"I.32.17\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"0.5\", \"*\", \"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"^2\", \")\", \"*\", \"(\", \"8\", \"*\", \"pi\", \"*\", \"X_3\", \"^2\", \"/\", \"3\", \")\", \"*\", \"(\", \"(\", \"X_4\", \"^2\", \"*\", \"X_4\", \"^2\", \")\", \"/\", \"(\", \"X_4\", \"^2\", \"-\", \"X_5\", \"^2\", \")\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"Pwr = (1/2*epsilon*c*Ef**2)*(8*pi*r**2/3)*(omega**4/(omega**2-omega_0**2)**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.35.21\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"tanh\", \"(\", \"X_1\", \"*\", \"X_2\", \"/\", \"(\", \"X_3\", \"*\", \"X_4\", \")\", \")\"], # noqa: F401\n            original_equation=\"M = n_rho*mom*tanh(mom*B/(kb*T))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"I.44.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"*\", \"ln\", \"(\", \"X_4\", \"/\", \"X_3\", \")\"], # noqa: F401\n            original_equation=\"E_n = n*kb*T*ln(V2/V1)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"III.4.32\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"1\", \"/\", \"(\", \"exp\", \"(\", \"(\", \"X_0\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"*\", \"X_1\", \"/\", \"(\", \"X_2\", \"*\", \"X_3\", \")\", \")\", \"-\", \"1\", \")\"], # noqa: F401\n            original_equation=\"n = 1/(exp((h/(2*pi))*omega/(kb*T))-1)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.10.9\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"/\", \"X_1\", \")\", \"*\", \"1\", \"/\", \"(\", \"1\", \"+\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"Ef = sigma_den/epsilon*1/(1+chi)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"II.38.3\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_3\", \"/\", \"X_2\"], # noqa: F401\n            original_equation=\"F = Y*A*x/d\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.6.2b\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"exp\", \"(\", \"u-\", \"(\", \"(\", \"(\", \"X_1\", \"-\", \"X_2\", \")\", \"/\", \"X_0\", \")\", \"^2\", \")\", \"/\", \"2\", \")\", \"/\", \"(\", \"sqrt\", \"(\", \"2\", \"*\", \"pi\", \")\", \"*\", \"X_0\", \")\"], # noqa: F401\n            original_equation=\"f = exp(-((theta-theta1)/sigma)**2/2)/(sqrt(2*pi)*sigma)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"II.8.31\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"^2\", \"/\", \"2\"], # noqa: F401\n            original_equation=\"E_den = epsilon*Ef**2/2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_1v,\n            dataset_name=\"I.6.2a\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"exp\", \"(\", \"u-\", \"X_0\", \"^2\", \"/\", \"2\", \")\", \"/\", \"sqrt\", \"(\", \"2\", \"*\", \"pi\", \")\"], # noqa: F401\n            original_equation=\"f = exp(-theta**2/2)/sqrt(2*pi)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"III.12.43\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"X_1\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\"], # noqa: F401\n            original_equation=\"L = n*(h/(2*pi))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"III.17.37\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"1\", \"+\", \"X_1\", \"*\", \"cos\", \"(\", \"X_2\", \")\", \")\"], # noqa: F401\n            original_equation=\"f = beta*(1+alpha*cos(theta))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"III.10.19\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"sqrt\", \"(\", \"X_1\", \"^2\", \"+\", \"X_2\", \"^2\", \"+\", \"X_3\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"E_n = mom*sqrt(Bx**2+By**2+Bz**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_6v,\n            dataset_name=\"II.11.7\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"1\", \"+\", \"X_4\", \"*\", \"X_5\", \"*\", \"cos\", \"(\", \"X_3\", \")\", \"/\", \"(\", \"X_1\", \"*\", \"X_2\", \")\", \")\"], # noqa: F401\n            original_equation=\"n = n_0*(1+p_d*Ef*cos(theta)/(kb*T))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.39.1\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"1.5\", \"*\", \"X_0\", \"*\", \"X_1\"], # noqa: F401\n            original_equation=\"E_n = 3/2*pr*V\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.37.1\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"1\", \"+\", \"X_2\", \")\", \"*\", \"X_1\"], # noqa: F401\n            original_equation=\"E_n = mom*(1+chi)*B\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.12.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_2\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_1\", \"*\", \"X_2\", \"^3\", \")\"], # noqa: F401\n            original_equation=\"Ef = q1*r/(4*pi*epsilon*r**3)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"II.27.18\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"^2\"], # noqa: F401\n            original_equation=\"E_den = epsilon*Ef**2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.12.2\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_3\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_2\", \"*\", \"X_3\", \"^3\", \")\"], # noqa: F401\n            original_equation=\"F = q1*q2*r/(4*pi*epsilon*r**3)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"III.13.18\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"2\", \"*\", \"X_0\", \"*\", \"X_1\", \"^2\", \"*\", \"X_2\", \"/\", \"(\", \"X_3\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\"], # noqa: F401\n            original_equation=\"v = 2*E_n*d**2*k/(h/(2*pi))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.11.3\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"X_2\", \"*\", \"(\", \"X_3\", \"^2\", \"-\", \"X_4\", \"^2\", \")\", \")\"], # noqa: F401\n            original_equation=\"x = q*Ef/(m*(omega_0**2-omega**2))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_6v,\n            dataset_name=\"I.40.1\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"exp\", \"(\", \"u-\", \"X_1\", \"*\", \"X_4\", \"*\", \"X_2\", \"/\", \"(\", \"X_5\", \"*\", \"X_3\", \")\", \")\"], # noqa: F401\n            original_equation=\"n = n_0*exp(-m*g*x/(kb*T))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"III.21.20\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"u-\", \"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"/\", \"X_3\"], # noqa: F401\n            original_equation=\"j = -rho_c_0*q*A_vec/m\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.43.16\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"/\", \"X_3\"], # noqa: F401\n            original_equation=\"v = mu_drift*q*Volt/d\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.15.10\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"p = m_0*v/sqrt(1-v**2/c**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.30.5\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"arcsin\", \"(\", \"X_0\", \"/\", \"(\", \"X_2\", \"*\", \"X_1\", \")\", \")\"], # noqa: F401\n            original_equation=\"theta = arcsin(lambd/(n*d))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.50.26\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"cos\", \"(\", \"X_1\", \"*\", \"X_2\", \")\", \"+\", \"X_3\", \"*\", \"cos\", \"(\", \"X_1\", \"*\", \"X_2\", \")\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"x = x1*(cos(omega*t)+alpha*cos(omega*t)**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"I.12.11\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"X_1\", \"+\", \"X_2\", \"*\", \"X_3\", \"*\", \"sin\", \"(\", \"X_4\", \")\", \")\"], # noqa: F401\n            original_equation=\"F = q*(Ef+B*v*sin(theta))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.6.2\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"exp\", \"(\", \"u-\", \"(\", \"(\", \"X_1\", \"/\", \"X_0\", \")\", \"^2\", \")\", \"/\", \"2\", \")\", \"/\", \"(\", \"sqrt\", \"(\", \"2\", \"*\", \"pi\", \")\", \"*\", \"X_0\", \")\"], # noqa: F401\n            original_equation=\"f = exp(-(theta/sigma)**2/2)/(sqrt(2*pi)*sigma)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.14.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"0.5\", \"*\", \"X_0\", \"*\", \"X_1\", \"^2\"], # noqa: F401\n            original_equation=\"U = 1/2*k_spring*x**2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.47.23\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"sqrt\", \"(\", \"X_0\", \"*\", \"X_1\", \"/\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"c = sqrt(gamma*pr/rho)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.8.7\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"0.6\", \"*\", \"X_0\", \"^2\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_1\", \"*\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"E_n = 3/5*q**2/(4*pi*epsilon*d)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"III.15.14\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"^2\", \"/\", \"(\", \"2\", \"*\", \"X_1\", \"*\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"m = (h/(2*pi))**2/(2*E_n*d**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.34.14\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"(\", \"1\", \"+\", \"(\", \"X_1\", \"/\", \"X_0\", \")\", \")\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_0\", \"^2\", \")\", \")\", \"*\", \"X_2\"], # noqa: F401\n            original_equation=\"omega = ((1+v/c)/sqrt(1-v**2/c**2))*omega_0\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"III.8.54\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"sin\", \"(\", \"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \")\", \"^2\"], # noqa: F401\n            original_equation=\"prob = sin(E_n*t/(h/(2*pi)))**2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.26.2\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"arcsin\", \"(\", \"X_0\", \"*\", \"sin\", \"(\", \"X_1\", \")\", \")\"], # noqa: F401\n            original_equation=\"theta1 = arcsin(n*sin(theta2))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"III.19.51\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"u-\", \"X_0\", \"*\", \"(\", \"X_1\", \"^2\", \"*\", \"X_1\", \"^2\", \")\", \"/\", \"(\", \"(\", \"2\", \"*\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_4\", \")\", \"^2\", \")\", \"*\", \"(\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"^2\", \")\", \"*\", \"(\", \"1\", \"/\", \"X_3\", \"^2\", \")\", \")\"], # noqa: F401\n            original_equation=\"E_n = -m*q**4/(2*(4*pi*epsilon)**2*(h/(2*pi))**2)*(1/n**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"III.4.33\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"*\", \"X_1\", \"/\", \"(\", \"exp\", \"(\", \"(\", \"X_0\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"*\", \"X_1\", \"/\", \"(\", \"X_2\", \"*\", \"X_3\", \")\", \")\", \"-\", \"1\", \")\"], # noqa: F401\n            original_equation=\"E_n = (h/(2*pi))*omega/(exp((h/(2*pi))*omega/(kb*T))-1)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.34.1\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_2\", \"/\", \"(\", \"1\", \"-\", \"X_1\", \"/\", \"X_0\", \")\"], # noqa: F401\n            original_equation=\"omega = omega_0/(1-v/c)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"II.11.27\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"1\", \"-\", \"(\", \"X_0\", \"*\", \"X_1\", \"/\", \"3\", \")\", \")\", \")\", \"*\", \"X_2\", \"*\", \"X_3\"], # noqa: F401\n            original_equation=\"Pol = n*alpha/(1-(n*alpha/3))*epsilon*Ef\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.13.34\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"j = rho_c_0*v/sqrt(1-v**2/c**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.4.23\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_1\", \"*\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"Volt = q/(4*pi*epsilon*r)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.32.5\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"^2\", \"*\", \"X_1\", \"^2\", \"/\", \"(\", \"6\", \"*\", \"pi\", \"*\", \"X_2\", \"*\", \"X_3\", \"^3\", \")\"], # noqa: F401\n            original_equation=\"Pwr = q**2*a**2/(6*pi*epsilon*c**3)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"I.13.12\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_4\", \"*\", \"X_0\", \"*\", \"X_1\", \"*\", \"(\", \"1\", \"/\", \"X_3\", \"-\", \"1\", \"/\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"U = G*m1*m2*(1/r2-1/r1)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.2.42\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"X_2\", \"-\", \"X_1\", \")\", \"*\", \"X_3\", \"/\", \"X_4\"], # noqa: F401\n            original_equation=\"Pwr = kappa*(T2-T1)*A/d\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.27.6\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"1\", \"/\", \"(\", \"1\", \"/\", \"X_0\", \"+\", \"X_2\", \"/\", \"X_1\", \")\"], # noqa: F401\n            original_equation=\"foc = 1/(1/d1+n/d2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"III.14.14\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"exp\", \"(\", \"X_1\", \"*\", \"X_2\", \"/\", \"(\", \"X_3\", \"*\", \"X_4\", \")\", \")\", \"-\", \"1\", \")\"], # noqa: F401\n            original_equation=\"I = I_0*(exp(q*Volt/(kb*T))-1)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.18.12\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"sin\", \"(\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"tau = r*F*sin(theta)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.18.14\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"*\", \"sin\", \"(\", \"X_3\", \")\"], # noqa: F401\n            original_equation=\"L = m*r*v*sin(theta)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.21.32\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_1\", \"*\", \"X_2\", \"*\", \"(\", \"1\", \"-\", \"X_3\", \"/\", \"X_4\", \")\", \")\"], # noqa: F401\n            original_equation=\"Volt = q/(4*pi*epsilon*r*(1-v/c))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"II.38.14\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"(\", \"2\", \"*\", \"(\", \"1\", \"+\", \"X_1\", \")\", \")\"], # noqa: F401\n            original_equation=\"mu_S = Y/(2*(1+sigma))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.34.8\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"/\", \"X_3\"], # noqa: F401\n            original_equation=\"omega = q*v*B/p\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.8.14\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"sqrt\", \"(\", \"(\", \"X_1\", \"-\", \"X_0\", \")\", \"^2\", \"+\", \"(\", \"X_3\", \"-\", \"X_2\", \")\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"d = sqrt((x2-x1)**2+(y2-y1)**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"II.6.15b\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_1\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_0\", \")\", \")\", \"*\", \"3\", \"*\", \"cos\", \"(\", \"X_2\", \")\", \"*\", \"sin\", \"(\", \"X_2\", \")\", \"/\", \"X_3\", \"^3\"], # noqa: F401\n            original_equation=\"E_f = p_d/(4*pi*epsilon)*3*cos(theta)*sin(theta)/r**3\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.12.1\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\"], # noqa: F401\n            original_equation=\"F = mu*Nn\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.34.29b\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_3\", \"*\", \"X_4\", \"*\", \"X_2\", \"/\", \"(\", \"X_1\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\"], # noqa: F401\n            original_equation=\"E_n = g_*mom*B*Jz/(h/(2*pi))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.13.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"0.5\", \"*\", \"X_0\", \"*\", \"(\", \"X_1\", \"^2\", \"+\", \"X_2\", \"^2\", \"+\", \"X_3\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"K = 1/2*m*(v**2+u**2+w**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.39.22\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_3\", \"*\", \"X_1\", \"/\", \"X_2\"], # noqa: F401\n            original_equation=\"pr = n*kb*T/V\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.14.3\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\"], # noqa: F401\n            original_equation=\"U = m*g*z\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n\n        return benchmark\n</code></pre>"},{"location":"references/dataset/#SRToolkit.dataset.SR_benchmark.nguyen","title":"nguyen  <code>staticmethod</code>","text":"<pre><code>nguyen(dataset_directory: str, seed: Optional[int] = None) -&gt; SR_benchmark\n</code></pre> <p>Downloads and initializes the Nguyen benchmark datasets for symbolic regression.</p> <p>This method downloads the Nguyen symbolic regression benchmark datasets from a specified URL and initializes a set of datasets using a provided dataset directory. It creates two symbol libraries for equations with one variable and two variables, respectively, and populates the benchmark with various Nguyen equations, each represented with its symbolic tokens and associated symbol library.</p> <p>For more information about the Nguyen benchmark, see the following paper: https://doi.org/10.1007/s10710-010-9121-2</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.nguyen('data/nguyen/')\n&gt;&gt;&gt; for dataset in benchmark.list_datasets(verbose=False):\n...     ds = benchmark.create_dataset(dataset)\n...     rmse = ds.create_evaluator().evaluate_expr(ds.ground_truth)\n...     if rmse &gt; ds.success_threshold:\n...         print(f'Failed dataset: {dataset} with RMSE {rmse}')\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dataset_directory</code> <code>str</code> <p>The directory path where the benchmark dataset will be downloaded and stored or where it will be loaded from.</p> required <code>seed</code> <code>Optional[int]</code> <p>The seed to use for the random number generator. If None, the random number generation will not be seeded</p> <code>None</code> <p>Returns:</p> Name Type Description <code>SR_benchmark</code> <code>SR_benchmark</code> <p>An initialized SR_benchmark instance containing the Nguyen datasets.</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>    @staticmethod\n    def nguyen(dataset_directory: str, seed: Optional[int] = None) -&gt; \"SR_benchmark\":\n        \"\"\"\n        Downloads and initializes the Nguyen benchmark datasets for symbolic regression.\n\n        This method downloads the Nguyen symbolic regression benchmark datasets from a specified URL\n        and initializes a set of datasets using a provided dataset directory. It creates two symbol libraries\n        for equations with one variable and two variables, respectively, and populates the benchmark with various\n        Nguyen equations, each represented with its symbolic tokens and associated symbol library.\n\n        For more information about the Nguyen benchmark, see the following paper: &lt;https://doi.org/10.1007/s10710-010-9121-2&gt;\n\n        Examples:\n            &gt;&gt;&gt; benchmark = SR_benchmark.nguyen('data/nguyen/')\n            &gt;&gt;&gt; for dataset in benchmark.list_datasets(verbose=False):\n            ...     ds = benchmark.create_dataset(dataset)\n            ...     rmse = ds.create_evaluator().evaluate_expr(ds.ground_truth)\n            ...     if rmse &gt; ds.success_threshold:\n            ...         print(f'Failed dataset: {dataset} with RMSE {rmse}')\n\n        Args:\n            dataset_directory: The directory path where the benchmark dataset will be downloaded and stored or where\n                it will be loaded from.\n            seed: The seed to use for the random number generator. If None, the random number generation will not\n                be seeded\n\n        Returns:\n            SR_benchmark: An initialized SR_benchmark instance containing the Nguyen datasets.\n        \"\"\"\n        url = \"https://raw.githubusercontent.com/smeznar/SymbolicRegressionToolkit/master/data/nguyen.zip\"\n        SR_benchmark.download_benchmark_data(url, dataset_directory)\n        # we create a SymbolLibrary with 1 and with 2 variables\n        # Each library contains +, -, *, /, sin, cos, exp, log, sqrt, ^2, ^3\n        sl_1v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"sin\", \"cos\", \"exp\", \"log\", \"sqrt\", \"^2\", \"^3\"], 1)\n        sl_2v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"sin\", \"cos\", \"exp\", \"log\", \"sqrt\", \"^2\", \"^3\"], 2)\n\n        metadata = {\"description\": \"Symbolic regression benchmark with 10 expressions that don't contain constant \"\n                                   \"parameters. First 4 are polynomials of different degrees. First eight expressions \"\n                                   \"contain 1 variable, last two expressions contain two variables. This benchmark \"\n                                   \"doesn't contain the original data, only expressions\",\n                    \"citation\": \"\"\"@article{Uy2011,\n    author={Uy, Nguyen Quang and Hoai, Nguyen Xuan and O'Neill, Michael and McKay, R. I. and Galv{\\'a}n-L{\\'o}pez, Edgar},\n    title={Semantically-based crossover in genetic programming: application to real-valued symbolic regression},\n    journal={Genetic Programming and Evolvable Machines},\n    year={2011},\n    month={Jun},\n    day={01},\n    volume={12},\n    number={2},\n    pages={91-119},\n}\"\"\"}\n\n        # Add datasets to the benchmark\n        benchmark = SR_benchmark(\"Nguyen\", dataset_directory, metadata=metadata)\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-1\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"X_0\", \"+\", \"X_0\", \"^2\", \"+\", \"X_0\", \"^3\"], # noqa: F401\n\t\t\toriginal_equation=\"y = x+x^2+x^3\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-2\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"X_0\", \"+\", \"X_0\", \"^2\", \"+\", \"X_0\", \"^3\", \"+\", \"X_0\", \"*\", \"X_0\", \"^3\"], # noqa: F401\n\t\t\toriginal_equation=\"y = x+x^2+x^3+x^4\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-3\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"X_0\", \"+\", \"X_0\", \"^2\", \"+\", \"X_0\", \"^3\", \"+\", \"X_0\", \"*\", \"X_0\", \"^3\", \"+\", \"X_0\", \"^2\", \"*\", \"X_0\", \"^3\"], # noqa: F401\n\t\t\toriginal_equation=\"y = x+x^2+x^3+x^4+x^5\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-4\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"X_0\", \"+\", \"X_0\", \"^2\", \"+\", \"X_0\", \"^3\", \"+\", \"X_0\", \"*\", \"X_0\", \"^3\", \"+\", \"X_0\", \"^2\", \"*\", \"X_0\", \"^3\", \"+\", \"X_0\", \"^3\", \"*\", \"X_0\", \"^3\"], # noqa: F401\n\t\t\toriginal_equation=\"y = x+x^2+x^3+x^4+x^5+x^6\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-5\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"sin\", \"(\", \"X_0\", \"^2\", \")\", \"*\", \"cos\", \"(\", \"X_0\", \")\", \"-\", \"1\"], # noqa: F401\n\t\t\toriginal_equation=\"y = sin(x^2)*cos(x)-1\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-6\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"sin\", \"(\", \"X_0\", \")\", \"+\", \"sin\", \"(\", \"X_0\", \"+\", \"X_0\", \"^2\", \")\"], # noqa: F401\n\t\t\toriginal_equation=\"y = sin(x)+sin(x+x^2)\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-7\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"log\", \"(\", \"1\", \"+\", \"X_0\", \")\", \"+\", \"log\", \"(\", \"1\", \"+\", \"X_0\", \"^2\", \")\"], # noqa: F401\n\t\t\toriginal_equation=\"y = log(1+x)+log(1+x^2)\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-8\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"sqrt\", \"(\", \"X_0\", \")\"], # noqa: F401\n\t\t\toriginal_equation=\"y = sqrt(x)\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_2v,\n\t\t\tdataset_name=\"NG-9\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"sin\", \"(\", \"X_0\", \")\", \"+\", \"sin\", \"(\", \"X_1\", \"^2\", \")\"], # noqa: F401\n\t\t\toriginal_equation=\"y = sin(x)+sin(y^2)\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_2v,\n\t\t\tdataset_name=\"NG-10\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"2\", \"*\", \"sin\", \"(\", \"X_0\", \")\", \"*\", \"cos\", \"(\", \"X_1\", \")\"], # noqa: F401\n\t\t\toriginal_equation=\"y = 2*sin(x)*cos(y)\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        return benchmark\n</code></pre>"},{"location":"references/dataset/srbenchmark/","title":"SR Benchmark","text":""},{"location":"references/dataset/srbenchmark/#SRToolkit.dataset.sr_benchmark","title":"SRToolkit.dataset.sr_benchmark","text":""},{"location":"references/dataset/srbenchmark/#SRToolkit.dataset.sr_benchmark.SR_benchmark","title":"SR_benchmark","text":"<pre><code>SR_benchmark(benchmark_name: str, base_dir: str, datasets: Optional[List[Union[SR_dataset, Tuple[str, SR_dataset]]]] = None, augmentation_map: dict = None, metadata: dict = None)\n</code></pre> <p>Initializes an instance of the SR_benchmark class. You can find examples of how to use this class in the feynman and nguyen methods below.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; len(benchmark.list_datasets(verbose=False))\n100\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>benchmark_name</code> <code>str</code> <p>The name of this benchmark.</p> required <code>base_dir</code> <code>str</code> <p>The directory where the datasets will be stored.</p> required <code>datasets</code> <code>Optional[List[Union[SR_dataset, Tuple[str, SR_dataset]]]]</code> <p>A list of SR_dataset instances or tuples containing the name of the dataset and an instance of SR_dataset. When name of the dataset is not provided, the dataset will be named 'benchmark_name'_'index of dataset in the list + 1'</p> <code>None</code> <code>augmentation_map</code> <code>dict</code> <p>A dictionary mapping augmenter names to their respective classes.</p> <code>None</code> <code>metadata</code> <code>dict</code> <p>An optional dictionary containing metadata about this benchmark. This could include information such as the name of the benchmark, a citation for the benchmark, number of datasets, etc.</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If elements in the \"datasets\" argument are not instances of SR_dataset or tuples containing the name of the dataset and an instance of SR_dataset.</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>def __init__(self, benchmark_name: str, base_dir: str,\n             datasets: Optional[List[Union[SR_dataset, Tuple[str, SR_dataset]]]] = None,\n             augmentation_map: dict = None, metadata: dict = None):\n    \"\"\"\n    Initializes an instance of the SR_benchmark class. You can find examples of how to use this class in the\n    feynman and nguyen methods below.\n\n    Examples:\n        &gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; len(benchmark.list_datasets(verbose=False))\n        100\n\n    Args:\n        benchmark_name: The name of this benchmark.\n        base_dir: The directory where the datasets will be stored.\n        datasets: A list of SR_dataset instances or tuples containing the name of the dataset and an instance of\n            SR_dataset. When name of the dataset is not provided, the dataset will be named\n            'benchmark_name'_'index of dataset in the list + 1'\n        augmentation_map: A dictionary mapping augmenter names to their respective classes.\n        metadata: An optional dictionary containing metadata about this benchmark. This could include information\n            such as the name of the benchmark, a citation for the benchmark, number of datasets, etc.\n\n    Raises:\n        Exception: If elements in the \"datasets\" argument are not instances of SR_dataset or tuples containing\n            the name of the dataset and an instance of SR_dataset.\n    \"\"\"\n    self.benchmark_name = benchmark_name\n    self.base_dir = base_dir\n    if augmentation_map is None:\n        self.augmentation_map = RESULT_AUGMENTERS\n    self.datasets = {}\n    self.metadata = {} if metadata is None else metadata\n    if datasets is not None:\n        for i, dataset in enumerate(datasets):\n            if isinstance(dataset, SR_dataset):\n                self.add_dataset_instance(benchmark_name + \"_\" + str(i+1), dataset)\n            elif isinstance(dataset, tuple) and isinstance(dataset[0], str) and isinstance(dataset[1], SR_dataset):\n                self.add_dataset_instance(dataset[0], dataset[1])\n            else:\n                raise ValueError(\"[SR_benchmark] Dataset inside the datasets argument must be either a tuple \"\n                                 \"(name, SR_dataset) or a SR_dataset instance.\")\n</code></pre>"},{"location":"references/dataset/srbenchmark/#SRToolkit.dataset.sr_benchmark.SR_benchmark.add_dataset_instance","title":"add_dataset_instance","text":"<pre><code>add_dataset_instance(dataset_name: str, dataset: SR_dataset)\n</code></pre> <p>Adds an instance of the SR_dataset class to the benchmark.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; dataset = benchmark.create_dataset('I.16.6')\n&gt;&gt;&gt; isinstance(dataset, SR_dataset)\nTrue\n&gt;&gt;&gt; bm = SR_benchmark(\"BM\", \"data/bm\")\n&gt;&gt;&gt; bm.add_dataset_instance(\"I.16.6\", dataset)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name of the dataset.</p> required <code>dataset</code> <code>SR_dataset</code> <p>An instance of the SR_dataset class.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If the dataset name already exists in the benchmark.</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>def add_dataset_instance(self, dataset_name: str, dataset: SR_dataset):\n    \"\"\"\n    Adds an instance of the SR_dataset class to the benchmark.\n\n    Examples:\n        &gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; dataset = benchmark.create_dataset('I.16.6')\n        &gt;&gt;&gt; isinstance(dataset, SR_dataset)\n        True\n        &gt;&gt;&gt; bm = SR_benchmark(\"BM\", \"data/bm\")\n        &gt;&gt;&gt; bm.add_dataset_instance(\"I.16.6\", dataset)\n\n    Args:\n         dataset_name: The name of the dataset.\n         dataset: An instance of the SR_dataset class.\n\n    Raises:\n        Exception: If the dataset name already exists in the benchmark.\n    \"\"\"\n    if dataset_name in self.datasets:\n        raise ValueError(f\"Dataset {dataset_name} already exists in the benchmark.\")\n    else:\n        self.datasets[dataset_name] = {}\n    self.datasets[dataset_name][\"sr_dataset\"] = dataset\n    self.datasets[dataset_name][\"num_variables\"] = dataset.X.shape[1]\n</code></pre>"},{"location":"references/dataset/srbenchmark/#SRToolkit.dataset.sr_benchmark.SR_benchmark.add_dataset","title":"add_dataset","text":"<pre><code>add_dataset(dataset: Union[str, array, Tuple[array, array]], symbol_library: SymbolLibrary, dataset_name: Optional[str] = None, ranking_function: str = 'rmse', max_evaluations: int = -1, ground_truth: Optional[Union[List[str], Node, ndarray]] = None, original_equation: Optional[str] = None, success_threshold: Optional[float] = None, result_augmenters: Optional[List[ResultAugmenter]] = None, seed: Optional[int] = None, dataset_metadata: Optional[dict] = None, **kwargs)\n</code></pre> <p>Adds a dataset to the benchmark.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; fey_benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; benchmark = SR_benchmark(\"BM\", \"data/bm\")\n&gt;&gt;&gt; benchmark.add_dataset(\"data/feynman/I.14.3.npz\", SymbolLibrary.default_symbols(3),\n...       dataset_name=\"I.14.3\", ranking_function=\"rmse\", ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\"],\n...       original_equation=\"U = m*g*z\", max_evaluations=100000, max_expression_length=50,\n...       success_threshold=1e-7, dataset_metadata={}, constant_range=[-5.0, 5.0], result_augmenters=[],\n...       seed = 42)\n&gt;&gt;&gt; len(benchmark.list_datasets(verbose=False))\n1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[str, array, Tuple[array, array]]</code> <p>Data used in the dataset. Can be: - A string representing the path to a NumPy archive (.npz) containing the dataset. It should either the absolute path to the data, path relative to the base_dir 'base_dir'/'dataset', or empty, in that case the dataset will be loaded from 'base_dir'/'dataset_name'.npz. The .npz file must contain the features (saved in 'X') and if 'rmse' is used as the ranking function, the target (saved in 'y'). - A 2d numpy array containing the features (X). If 'rmse' is used as the ranking function, ground truth should also be provided to calculate the target (y). Once added, the data will be saved at 'base_dir'/'dataset_name'.npz. - A tuple containing the features (X) and the target (y). If 'bed' is used as the ranking function, the target will be ignored. Once added, the data will be saved at 'base_dir'/'dataset_name'.npz.</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use.</p> required <code>dataset_name</code> <code>Optional[str]</code> <p>The name of the dataset. If None, a name will be generated automatically as 'benchmark_name'_'index+1'.</p> <code>None</code> <code>ranking_function</code> <code>str</code> <p>The ranking function used during evaluation. Can be: 'rmse', 'bed'.</p> <code>'rmse'</code> <code>max_evaluations</code> <code>int</code> <p>The maximum number of expressions to evaluate. Less than 0 means no limit.</p> <code>-1</code> <code>ground_truth</code> <code>Optional[Union[List[str], Node, ndarray]]</code> <p>The ground truth expression. Can either a list of symbols, a SRToolkit.utils.Node, or a numpy array representing behavior of an expressions. When 'bed' is used as the ranking function, ground truth must be provided.</p> <code>None</code> <code>original_equation</code> <code>Optional[str]</code> <p>The original equation from which the ground truth expression was generated.</p> <code>None</code> <code>success_threshold</code> <code>Optional[float]</code> <p>The threshold below which the experiment is considered successful. If None, the threshold will be calculated automatically. See SRToolkit.evaluation.SR_evaluator for more details.</p> <code>None</code> <code>result_augmenters</code> <code>Optional[List[ResultAugmenter]]</code> <p>The list of result augmenters to use.</p> <code>None</code> <code>seed</code> <code>Optional[int]</code> <p>The seed to use for random number generation. If None, number generation will be random.</p> <code>None</code> <code>dataset_metadata</code> <code>Optional[dict]</code> <p>An optional dictionary containing metadata about this dataset. This could include information such as the name of the dataset, a citation for the dataset, number of variables, etc.</p> <code>None</code> <p>Other Parameters:</p> Name Type Description <code>method</code> <code>str</code> <p>The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested. Default is \"L-BFGS-B\".</p> <code>tol</code> <code>float</code> <p>The tolerance for termination. Default is 1e-6.</p> <code>gtol</code> <code>float</code> <p>The tolerance for the gradient norm. Default is 1e-3.</p> <code>max_iter</code> <code>int</code> <p>The maximum number of iterations. Default is 100.</p> <code>constant_bounds</code> <code>Tuple[float, float]</code> <p>A tuple of two elements, specifying the lower and upper bounds for the constant values. Default is (-5, 5).</p> <code>initialization</code> <code>str</code> <p>The method to use for initializing the constant values. Currently, only \"random\" and \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\" creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".</p> <code>max_constants</code> <code>int</code> <p>The maximum number of constants allowed in the expression. Default is 8.</p> <code>max_expr_length</code> <code>int</code> <p>The maximum length of the expression. Default is -1 (no limit).</p> <code>num_points_sampled</code> <code>int</code> <p>The number of points to sample when estimating the behavior of an expression. Default is 64. If num_points_sampled==-1, then the number of points sampled is equal to the number of points in the dataset.</p> <code>bed_X</code> <code>Optional[ndarray]</code> <p>Points used for BED evaluation. If None and domain_bounds are given, points are sampled from the domain. If None and domain_bounds are not givem, points are randomly selected from X. Default is None.</p> <code>num_consts_sampled</code> <code>int</code> <p>Number of constants sampled for BED evaluation. Default is 32.</p> <code>domain_bounds</code> <code>Optional[List[Tuple[float, float]]]</code> <p>Bounds for the domain to be used if bed_X is None to sample random points. Default is None.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When BED ranking function is used but ground truth is not provided. When dataset is given as a string (directory) that doesn't exist, is not a valid .npz file, or is a .npz file that doesn't contain one array for the BED ranking function (X) or two array for the RMSE ranking function (X, y). When the argument dataset is an array, ranking function RMSE and there is no ground truth or the expression given as the ground truth cannot be evaluated...</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>def add_dataset(\n    self,\n    dataset: Union[str, np.array, Tuple[np.array, np.array]],\n    symbol_library: SymbolLibrary,\n    dataset_name: Optional[str] = None,\n    ranking_function: str = \"rmse\",\n    max_evaluations: int = -1,\n    ground_truth: Optional[Union[List[str], Node, np.ndarray]] = None,\n    original_equation: Optional[str] = None,\n    success_threshold: Optional[float] = None,\n    result_augmenters: Optional[List[ResultAugmenter]] = None,\n    seed: Optional[int] = None,\n    dataset_metadata: Optional[dict] = None,\n    **kwargs\n):\n    \"\"\"\n    Adds a dataset to the benchmark.\n\n    Examples:\n        &gt;&gt;&gt; fey_benchmark = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; benchmark = SR_benchmark(\"BM\", \"data/bm\")\n        &gt;&gt;&gt; benchmark.add_dataset(\"data/feynman/I.14.3.npz\", SymbolLibrary.default_symbols(3),\n        ...       dataset_name=\"I.14.3\", ranking_function=\"rmse\", ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\"],\n        ...       original_equation=\"U = m*g*z\", max_evaluations=100000, max_expression_length=50,\n        ...       success_threshold=1e-7, dataset_metadata={}, constant_range=[-5.0, 5.0], result_augmenters=[],\n        ...       seed = 42)\n        &gt;&gt;&gt; len(benchmark.list_datasets(verbose=False))\n        1\n\n    Args:\n        dataset: Data used in the dataset. Can be:\n            - A string representing the path to a NumPy archive (.npz) containing the dataset. It should either\n            the absolute path to the data, path relative to the base_dir 'base_dir'/'dataset', or empty, in that\n            case the dataset will be loaded from 'base_dir'/'dataset_name'.npz. The .npz file must contain the\n            features (saved in 'X') and if 'rmse' is used as the ranking function, the target (saved in 'y').\n            - A 2d numpy array containing the features (X). If 'rmse' is used as the ranking function, ground truth\n            should also be provided to calculate the target (y). Once added, the data will be saved at\n            'base_dir'/'dataset_name'.npz.\n            - A tuple containing the features (X) and the target (y). If 'bed' is used as the ranking function,\n            the target will be ignored. Once added, the data will be saved at 'base_dir'/'dataset_name'.npz.\n        symbol_library: The symbol library to use.\n        dataset_name: The name of the dataset. If None, a name will be generated automatically as\n            'benchmark_name'_'index+1'.\n        ranking_function: The ranking function used during evaluation. Can be: 'rmse', 'bed'.\n        max_evaluations: The maximum number of expressions to evaluate. Less than 0 means no limit.\n        ground_truth: The ground truth expression. Can either a list of symbols, a SRToolkit.utils.Node, or a\n            numpy array representing behavior of an expressions. When 'bed' is used as the ranking function,\n            ground truth must be provided.\n        original_equation: The original equation from which the ground truth expression was generated.\n        success_threshold: The threshold below which the experiment is considered successful. If None, the\n            threshold will be calculated automatically. See SRToolkit.evaluation.SR_evaluator for more details.\n        result_augmenters: The list of result augmenters to use.\n        seed: The seed to use for random number generation. If None, number generation will be random.\n        dataset_metadata: An optional dictionary containing metadata about this dataset. This could include\n            information such as the name of the dataset, a citation for the dataset, number of variables, etc.\n\n    Keyword Arguments:\n        method (str): The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested.\n            Default is \"L-BFGS-B\".\n        tol (float): The tolerance for termination. Default is 1e-6.\n        gtol (float): The tolerance for the gradient norm. Default is 1e-3.\n        max_iter (int): The maximum number of iterations. Default is 100.\n        constant_bounds (Tuple[float, float]): A tuple of two elements, specifying the lower and upper bounds for\n            the constant values. Default is (-5, 5).\n        initialization (str): The method to use for initializing the constant values. Currently, only \"random\" and\n            \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\"\n            creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".\n        max_constants (int): The maximum number of constants allowed in the expression. Default is 8.\n        max_expr_length (int): The maximum length of the expression. Default is -1 (no limit).\n        num_points_sampled (int): The number of points to sample when estimating the behavior of an expression.\n            Default is 64. If num_points_sampled==-1, then the number of points sampled is equal to the number of\n            points in the dataset.\n        bed_X (Optional[np.ndarray]): Points used for BED evaluation. If None and domain_bounds are given, points\n            are sampled from the domain. If None and domain_bounds are not givem, points are randomly selected\n            from X. Default is None.\n        num_consts_sampled (int): Number of constants sampled for BED evaluation. Default is 32.\n        domain_bounds (Optional[List[Tuple[float, float]]]): Bounds for the domain to be used if bed_X is None to\n            sample random points. Default is None.\n\n    Raises:\n        ValueError: When BED ranking function is used but ground truth is not provided. When dataset is given as\n            a string (directory) that doesn't exist, is not a valid .npz file, or is a .npz file that doesn't\n            contain one array for the BED ranking function (X) or two array for the RMSE ranking function (X, y).\n            When the argument dataset is an array, ranking function RMSE and there is no ground truth or the\n            expression given as the ground truth cannot be evaluated...\n    \"\"\"\n    if dataset_name is None:\n        dataset_name = f\"{self.benchmark_name}_{len(self.datasets)+1}\"\n\n    self.datasets[dataset_name] = {}\n    self.datasets[dataset_name][\"symbol_library\"] = symbol_library.to_dict()\n    self.datasets[dataset_name][\"ranking_function\"] = ranking_function\n    self.datasets[dataset_name][\"max_evaluations\"] = max_evaluations\n\n    self.datasets[dataset_name][\"success_threshold\"] = success_threshold\n    self.datasets[dataset_name][\"result_augmenters\"] = [re.to_dict(self.base_dir, dataset_name) for re in result_augmenters]\n    self.datasets[dataset_name][\"seed\"] = seed\n    self.datasets[dataset_name][\"dataset_metadata\"] = copy.deepcopy(self.metadata).update(dataset_metadata)\n\n    if \"bed_X\" in kwargs and kwargs[\"bed_X\"] is not None:\n        kwargs[\"bed_X\"] = kwargs[\"bed_X\"].tolist()\n\n    self.datasets[dataset_name][\"kwargs\"] = kwargs\n    self.datasets[dataset_name][\"original_equation\"] = original_equation\n    self.datasets[dataset_name][\"ground_truth\"] = ground_truth\n\n    if ground_truth is None:\n        if ranking_function == \"bed\":\n            raise ValueError(\"[SR_benchmark.add_dataset] For 'bed' ranking, the ground truth must be provided. \")\n        else:\n            print(f\"[SR_benchmark.add_dataset] 'ground_truth' argument not provided. We recommend providing it \"\n                  f\"for more transparent evaluation.\")\n    else:\n        if original_equation is None:\n            if isinstance(ground_truth, str):\n                self.datasets[dataset_name][\"original_equation\"] = \"y = \" + ground_truth\n            elif isinstance(ground_truth, list):\n                self.datasets[dataset_name][\"original_equation\"] = \"y = \" + \"\".join(ground_truth)\n\n    if isinstance(dataset, str):\n        dataset_path = None\n        if os.path.exists(dataset):\n            dataset_path = dataset\n        elif dataset != \"\" and os.path.exists(f\"{self.base_dir}/{dataset}\"):\n            dataset_path = f\"{self.base_dir}/{dataset}\"\n        elif os.path.exists(f\"{self.base_dir}/{dataset_name}.npz\"):\n            dataset_path = f\"{self.base_dir}/{dataset_name}.npz\"\n\n        if dataset_path is None:\n            error_msg = (\n                f\"[SR_benchmark.add_dataset] Could not find the dataset file. \"\n                f\"Expected locations:\\n\"\n                f\"- Absolute path: '{dataset}'\\n\"\n                f\"- Relative to base_dir: '{self.base_dir}/{dataset}'\\n\"\n                f\"- NPZ with the name of the dataset in base_dir: '{self.base_dir}/{dataset_name}.npz'\"\n            )\n            raise FileNotFoundError(error_msg)\n\n        self.datasets[dataset_name][\"dataset_path\"] = dataset_path\n\n        try:\n            data = np.load(self.datasets[dataset_name][\"dataset_path\"], allow_pickle=False)\n        except IOError as e:\n            error_msg = (\n                f\"[SR_benchmark.add_dataset] Could not load dataset from path '{self.datasets[dataset_name]}' \"\n                f\"using np.load. The file may be corrupt or not a valid NumPy archive (.npz). \"\n                f\"Original error: {e}\"\n            )\n            raise IOError(error_msg) from e\n\n        if ranking_function == \"rmse\":\n            if not (isinstance(data, np.lib.npyio.NpzFile) and \"X\" in data and \"y\" in data):\n                error_msg = (\n                    f\"[SR_benchmark.add_dataset] For 'rmse' ranking, the dataset file \"\n                    f\"('{self.datasets[dataset_name]['dataset_path']}') must be a .npz NumPy archive containing \"\n                    f\"both 'X' (features) and 'y' (targets). It should be created via `np.savez(path, X=X, y=y)`.\"\n                )\n                raise ValueError(error_msg)\n\n        elif ranking_function == \"bed\":\n            if not (isinstance(data, np.lib.npyio.NpzFile) and \"X\" in data):\n                error_msg = (\n                    f\"[SR_benchmark.add_dataset] For 'bed' ranking, the dataset file \"\n                    f\"('{self.datasets[dataset_name]['dataset_path']}') must be a .npz NumPy archive \"\n                    f\"containing 'X' (features). It should be created via `np.savez(path, X=X)`.\"\n                )\n                raise ValueError(error_msg)\n\n        num_variables = data['X'].shape[1]\n\n    elif isinstance(dataset, np.ndarray):\n        if ranking_function == \"rmse\" and ground_truth is not None:\n            try:\n                expr = expr_to_executable_function(ground_truth, symbol_library)\n                y = expr(dataset, None)\n            except Exception as e:\n                raise Exception(f\"[SR_benchmark.add_dataset] Could not evaluate the ground truth. \"\n                                f\"Original error: {e}\")\n            if not os.path.isdir(self.base_dir):\n                os.makedirs(self.base_dir)\n            np.savez(f\"{self.base_dir}/{dataset_name}.npz\", X=dataset, y=y, allow_pickle=False)\n        elif ranking_function == \"rmse\" and ground_truth is None:\n            raise ValueError(\"[SR_benchmark.add_dataset] For 'rmse' ranking, if the dataset argument is a numpy \"\n                             \"array, the ground truth must be provided in order for the target values to be \"\n                             \"calculated.\")\n        elif ranking_function == \"bed\":\n            if not os.path.isdir(self.base_dir):\n                os.makedirs(self.base_dir)\n            np.savez(f\"{self.base_dir}/{dataset_name}.npz\", X=dataset, allow_pickle=False)\n\n        self.datasets[dataset_name][\"dataset_path\"] = f\"{self.base_dir}/{dataset_name}.npz\"\n        num_variables = dataset.shape[1]\n\n    elif isinstance(dataset, tuple):\n        if not isinstance(dataset[0], np.ndarray) or not isinstance(dataset[1], np.ndarray):\n            raise ValueError(\"[SR_benchmark.add_dataset] When dataset argument is provided as a tuple, both \"\n                             \"values must be a numpy array. The first array represents the features ('X'), \"\n                             \"the second array represents the targets ('y').\")\n        if ranking_function == \"bed\":\n            print(f\"[SR_benchmark.add_dataset] 'bed' ranking only utilizes the array with feature. Array with \"\n                  f\"targets will be ignored.\")\n        if not os.path.isdir(self.base_dir):\n            os.makedirs(self.base_dir)\n        np.savez(f\"{self.base_dir}/{dataset_name}.npz\", X=dataset[0], y=dataset[1], allow_pickle=False)\n        self.datasets[dataset_name][\"dataset_path\"] = f\"{self.base_dir}/{dataset_name}.npz\"\n        num_variables = dataset[0].shape[1]\n\n    else:\n        raise ValueError(\"[SR_benchmark.add_dataset] The dataset argument must be a string, a numpy array, \"\n                         \"or a tuple containing two numpy arrays.\")\n\n    self.datasets[dataset_name][\"num_variables\"] = num_variables\n</code></pre>"},{"location":"references/dataset/srbenchmark/#SRToolkit.dataset.sr_benchmark.SR_benchmark.create_dataset","title":"create_dataset","text":"<pre><code>create_dataset(dataset_name: str) -&gt; SR_dataset\n</code></pre> <p>Creates an instance of a dataset from the given dataset name.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; dataset = benchmark.create_dataset('I.16.6')\n&gt;&gt;&gt; dataset.X.shape\n(10000, 3)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name of the dataset to create.</p> required <p>Returns:</p> Type Description <code>SR_dataset</code> <p>A SR_dataset instance containing the data, ground truth expression, and metadata for the given dataset.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset name is not found in the available datasets.</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>def create_dataset(self, dataset_name: str) -&gt; SR_dataset:\n    \"\"\"\n    Creates an instance of a dataset from the given dataset name.\n\n    Examples:\n        &gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; dataset = benchmark.create_dataset('I.16.6')\n        &gt;&gt;&gt; dataset.X.shape\n        (10000, 3)\n\n    Args:\n        dataset_name: The name of the dataset to create.\n\n    Returns:\n        A SR_dataset instance containing the data, ground truth expression, and metadata for the given dataset.\n\n    Raises:\n        ValueError: If the dataset name is not found in the available datasets.\n    \"\"\"\n    if dataset_name in self.datasets:\n        if \"sr_dataset\" in self.datasets[dataset_name]:\n            return self.datasets[dataset_name][\"sr_dataset\"]\n        else:\n            try:\n                return SR_dataset.from_dict(self.datasets[dataset_name], self.augmentation_map)\n            except Exception as e:\n                raise ValueError(f\"[SR_benchmark.create_dataset] Could not create SR_dataset from the given \"\n                                 f\"given dictionary. Original error: {e}\")\n\n    else:\n        raise ValueError(f\"Dataset {dataset_name} not found\")\n</code></pre>"},{"location":"references/dataset/srbenchmark/#SRToolkit.dataset.sr_benchmark.SR_benchmark.list_datasets","title":"list_datasets","text":"<pre><code>list_datasets(verbose=True, num_variables: int = -1) -&gt; List[str]\n</code></pre> <p>Lists the available datasets.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; len(benchmark.list_datasets(num_variables=2, verbose=False))\n15\n&gt;&gt;&gt; datasets_with_8_vars = benchmark.list_datasets(num_variables=8, verbose=False)\n&gt;&gt;&gt; datasets_with_8_vars[0]\n'II.36.38'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>If True, also prints out a description of each dataset.</p> <code>True</code> <code>num_variables</code> <code>int</code> <p>If not -1, only show datasets with the given number of variables.</p> <code>-1</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of dataset names.</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>def list_datasets(self, verbose=True, num_variables: int = -1) -&gt; List[str]:\n    \"\"\"\n    Lists the available datasets.\n\n    Examples:\n        &gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; len(benchmark.list_datasets(num_variables=2, verbose=False))\n        15\n        &gt;&gt;&gt; datasets_with_8_vars = benchmark.list_datasets(num_variables=8, verbose=False)\n        &gt;&gt;&gt; datasets_with_8_vars[0]\n        'II.36.38'\n\n    Args:\n        verbose (bool): If True, also prints out a description of each dataset.\n        num_variables (int): If not -1, only show datasets with the given number of variables.\n\n    Returns:\n        A list of dataset names.\n    \"\"\"\n    datasets = [\n        dataset_name\n        for dataset_name in self.datasets\n        if num_variables &lt; 0\n        or self.datasets[dataset_name][\"num_variables\"] == num_variables\n    ]\n    datasets = sorted(\n        datasets,\n        key=lambda dataset_name: (\n            self.datasets[dataset_name][\"num_variables\"],\n            dataset_name,\n        ),\n    )\n\n    if verbose:\n        part1 = []\n        part2 = []\n        part3 = []\n        max_length_1 = 0\n        max_length_2 = 0\n        for d in datasets:\n            if self.datasets[d][\"num_variables\"] == 1:\n                variable_str = \"1 variable\"\n            elif self.datasets[d][\"num_variables\"] &lt; 1:\n                variable_str = \"Amount of variables unknown\"\n            else:\n                variable_str = f\"{self.datasets[d]['num_variables']} variables\"\n            part1.append(d+\":\")\n            part2.append(variable_str)\n            part3.append(self.datasets[d][\"original_equation\"])\n            if len(d)+1 &gt; max_length_1:\n                max_length_1 = len(d)+1\n            if len(variable_str) &gt; max_length_2:\n                max_length_2 = len(variable_str)\n\n        for p1, p2, p3 in zip(part1, part2, part3):\n            print(f\"{p1:&lt;{max_length_1}} {p2:&lt;{max_length_2}}, Expression: {p3}\")\n    return datasets\n</code></pre>"},{"location":"references/dataset/srbenchmark/#SRToolkit.dataset.sr_benchmark.SR_benchmark.download_benchmark_data","title":"download_benchmark_data  <code>staticmethod</code>","text":"<pre><code>download_benchmark_data(url, directory_path)\n</code></pre> <p>Downloads a benchmark dataset from the given url to the given directory path.</p> <p>This function will first check if the directory_path exists. If not, it will create it. Then it will check if the directory_path is empty. If it is not empty, it will not download the data. If it is empty, it will download the data from the given url and extract it to the directory_path.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; url = \"https://raw.githubusercontent.com/smeznar/SymbolicRegressionToolkit/master/data/feynman.zip\"\n&gt;&gt;&gt; dataset_directory = 'data/feynman'\n&gt;&gt;&gt; SR_benchmark.download_benchmark_data(url, dataset_directory)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The url of the benchmark dataset to download.</p> required <code>directory_path</code> <code>str</code> <p>The path of the directory where the dataset should be downloaded.</p> required Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>@staticmethod\ndef download_benchmark_data(url, directory_path):\n    \"\"\"\n    Downloads a benchmark dataset from the given url to the given directory path.\n\n    This function will first check if the directory_path exists. If not, it will create it. Then it will check if the directory_path is empty. If it is not empty, it will not download the data. If it is empty, it will download the data from the given url and extract it to the directory_path.\n\n    Examples:\n        &gt;&gt;&gt; url = \"https://raw.githubusercontent.com/smeznar/SymbolicRegressionToolkit/master/data/feynman.zip\"\n        &gt;&gt;&gt; dataset_directory = 'data/feynman'\n        &gt;&gt;&gt; SR_benchmark.download_benchmark_data(url, dataset_directory)\n\n    Args:\n        url (str): The url of the benchmark dataset to download.\n        directory_path (str): The path of the directory where the dataset should be downloaded.\n    \"\"\"\n    if not os.path.exists(directory_path):\n        os.makedirs(directory_path)\n\n    # Check if directory_path is empty\n    if not os.listdir(directory_path):\n        http_response = urlopen(url)\n        zipfile = ZipFile(BytesIO(http_response.read()))\n        zipfile.extractall(path=directory_path)\n</code></pre>"},{"location":"references/dataset/srbenchmark/#SRToolkit.dataset.sr_benchmark.SR_benchmark.save_benchmark","title":"save_benchmark","text":"<pre><code>save_benchmark()\n</code></pre> <p>Saves the benchmark to a json file. The json file will contain the metadata about datasets and metadata of the benchmark. Data is not directly saved to the json file, but contains paths to the datasets.</p> <p>Saved data can be loaded using SR_benchmark.load_benchmark method.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; benchmark.save_benchmark()\n</code></pre> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>def save_benchmark(self):\n    \"\"\"\n    Saves the benchmark to a json file. The json file will contain the metadata about datasets\n    and metadata of the benchmark. Data is not directly saved to the json file, but contains paths to the datasets.\n\n    Saved data can be loaded using SR_benchmark.load_benchmark method.\n\n    Examples:\n        &gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; benchmark.save_benchmark()\n    \"\"\"\n    datasets = []\n    for dataset_name, dataset_info in self.datasets.items():\n        if \"sr_dataset\" in dataset_info:\n            datasets.append({\"name\": dataset_name,\n                             \"info\": dataset_info[\"sr_dataset\"].to_dict(self.base_dir, dataset_name)})\n        else:\n            datasets.append({\"name\": dataset_name,\n                             \"info\": dataset_info})\n\n    output = {\"datasets\": datasets,\n              \"metadata\": self.metadata,\n              \"name\": self.benchmark_name}\n\n    with open(f\"{self.base_dir}/dataset_info.json\", \"w\") as f:\n        json.dump(output, f)\n</code></pre>"},{"location":"references/dataset/srbenchmark/#SRToolkit.dataset.sr_benchmark.SR_benchmark.load_benchmark","title":"load_benchmark  <code>staticmethod</code>","text":"<pre><code>load_benchmark(base_dir: str) -&gt; SR_benchmark\n</code></pre> <p>Loads a benchmark stored at the base directory, returning an instance of SR_benchmark.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; b1 = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; b2 = SR_benchmark.load_benchmark('data/feynman')\n&gt;&gt;&gt; len(b1.list_datasets(verbose=False))\n100\n&gt;&gt;&gt; len(b2.list_datasets(verbose=False))\n100\n&gt;&gt;&gt; dataset_name = b2.list_datasets(verbose=False)[0]\n&gt;&gt;&gt; dataset = b2.create_dataset(dataset_name)\n&gt;&gt;&gt; rmse = dataset.create_evaluator().evaluate_expr(dataset.ground_truth)\n&gt;&gt;&gt; rmse &lt; dataset.success_threshold\nTrue\n</code></pre> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>@staticmethod\ndef load_benchmark(base_dir: str) -&gt; \"SR_benchmark\":\n    \"\"\"\n    Loads a benchmark stored at the base directory, returning an instance of SR_benchmark.\n\n    Examples:\n        &gt;&gt;&gt; b1 = SR_benchmark.feynman('data/feynman')\n        &gt;&gt;&gt; b2 = SR_benchmark.load_benchmark('data/feynman')\n        &gt;&gt;&gt; len(b1.list_datasets(verbose=False))\n        100\n        &gt;&gt;&gt; len(b2.list_datasets(verbose=False))\n        100\n        &gt;&gt;&gt; dataset_name = b2.list_datasets(verbose=False)[0]\n        &gt;&gt;&gt; dataset = b2.create_dataset(dataset_name)\n        &gt;&gt;&gt; rmse = dataset.create_evaluator().evaluate_expr(dataset.ground_truth)\n        &gt;&gt;&gt; rmse &lt; dataset.success_threshold\n        True\n\n    \"\"\"\n    with open(f\"{base_dir}/dataset_info.json\", \"r\") as f:\n        data = json.load(f)\n\n    datasets = {}\n    for dataset_info in data[\"datasets\"]:\n        datasets[dataset_info[\"name\"]] = dataset_info[\"info\"]\n\n    benchmark = SR_benchmark(data[\"name\"], base_dir, metadata=data[\"metadata\"])\n    benchmark.datasets = datasets\n    return benchmark\n</code></pre>"},{"location":"references/dataset/srbenchmark/#SRToolkit.dataset.sr_benchmark.SR_benchmark.feynman","title":"feynman  <code>staticmethod</code>","text":"<pre><code>feynman(dataset_directory: str, seed: Optional[int] = None) -&gt; SR_benchmark\n</code></pre> <p>Downloads the Feynman benchmark dataset, sets up symbol libraries, and adds predefined datasets to the benchmark.</p> <p>This method downloads the Feynman benchmark dataset from a specified URL, initializes symbol libraries for symbolic regression with varying numbers of variables, and adds multiple predefined datasets to the benchmark with their respective equations and metadata. For each data set, we randomly sampled 10,000 examples instead of 1,000,000 as in the original paper.</p> <p>For more information about the Feynman benchmark, see the following paper: https://doi.org/10.1126/sciadv.aay2631</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n&gt;&gt;&gt; for dataset in benchmark.list_datasets(verbose=False):\n...     ds = benchmark.create_dataset(dataset)\n...     rmse = ds.create_evaluator().evaluate_expr(ds.ground_truth)\n...     if rmse &gt; ds.success_threshold:\n...         print(f'Failed dataset: {dataset} with RMSE {rmse}')\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dataset_directory</code> <code>str</code> <p>The directory path where the benchmark dataset will be downloaded and stored or where it will be loaded from.</p> required <code>seed</code> <code>Optional[int]</code> <p>The seed to use for the random number generator. If None, the random number generation will not be seeded</p> <code>None</code> <p>Returns:</p> Name Type Description <code>SR_benchmark</code> <code>SR_benchmark</code> <p>An instance of the SR_benchmark class containing the predefined datasets.</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>    @staticmethod\n    def feynman(dataset_directory: str, seed: Optional[int] = None) -&gt; \"SR_benchmark\":\n        \"\"\"\n        Downloads the Feynman benchmark dataset, sets up symbol libraries, and adds predefined datasets to the benchmark.\n\n        This method downloads the Feynman benchmark dataset from a specified URL, initializes symbol libraries for\n        symbolic regression with varying numbers of variables, and adds multiple predefined datasets to the benchmark\n        with their respective equations and metadata. For each data set, we randomly sampled 10,000 examples instead\n        of 1,000,000 as in the original paper.\n\n        For more information about the Feynman benchmark, see the following paper: &lt;https://doi.org/10.1126/sciadv.aay2631&gt;\n\n        Examples:\n            &gt;&gt;&gt; benchmark = SR_benchmark.feynman('data/feynman')\n            &gt;&gt;&gt; for dataset in benchmark.list_datasets(verbose=False):\n            ...     ds = benchmark.create_dataset(dataset)\n            ...     rmse = ds.create_evaluator().evaluate_expr(ds.ground_truth)\n            ...     if rmse &gt; ds.success_threshold:\n            ...         print(f'Failed dataset: {dataset} with RMSE {rmse}')\n\n        Args:\n            dataset_directory: The directory path where the benchmark dataset will be downloaded and stored or where\n                it will be loaded from.\n            seed: The seed to use for the random number generator. If None, the random number generation will not\n                be seeded\n\n        Returns:\n            SR_benchmark: An instance of the SR_benchmark class containing the predefined datasets.\n        \"\"\"\n        url = \"https://raw.githubusercontent.com/smeznar/SymbolicRegressionToolkit/master/data/feynman.zip\"\n\n        metadata = {\"description\": \"Feynman benchmark containing 100 equations from the domain of physics. \"\n                                   \"Expressions can contain up to 9 variables.\",\n                    \"citation\": \"\"\"@article{Tegmark2020Feynman,\n  title={{AI Feynman: A physics-inspired method for symbolic regression}},\n  author={Udrescu, Silviu-Marian and Tegmark, Max},\n  journal={Science Advances},\n  volume={6},\n  number={16},\n  pages={eaay2631},\n  year={2020},\n  publisher={American Association for the Advancement of Science}\n}\n\"\"\"\n                    }\n\n        SR_benchmark.download_benchmark_data(url, dataset_directory)\n\n        sl_1v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 1)\n        sl_2v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 2)\n        sl_3v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 3)\n        sl_4v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 4)\n        sl_5v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 5)\n        sl_6v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 6)\n        sl_8v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 8)\n        sl_9v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"u-\", \"sqrt\", \"sin\", \"cos\", \"exp\",\n                                                \"arcsin\", \"tanh\", \"ln\", \"^2\", \"^3\", \"pi\", \"C\"], 9)\n\n        benchmark = SR_benchmark(\"feynman\", dataset_directory)\n        benchmark.metadata = metadata\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.16.6\",\n            ranking_function=\"rmse\",\n            max_evaluations=100000,\n            ground_truth = [\"(\", \"X_2\", \"+\",\"X_1\",\")\",\"/\",\"(\",\"1\",\"+\",\"(\",\"X_2\",\"*\",\"X_1\",\")\",\"/\",\"(\",\"X_0\",\"^2\",\")\",\")\"], # noqa: F401\n            original_equation=\"v1 = (u+v)/(1+u*v/c^2)\",\n            success_threshold=1e-7,\n            result_augmenters=[],\n            seed = seed,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            max_expression_length=50,\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.15.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"u-\", \"X_0\", \"*\", \"X_1\", \"*\", \"cos\", \"(\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"E_n = -mom*B*cos(theta)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.27.16\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"^2\"], # noqa: F401\n            original_equation=\"flux = epsilon*c*Ef^2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_6v,\n            dataset_name=\"I.11.19\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_3\", \"+\", \"X_1\", \"*\", \"X_4\", \"+\", \"X_2\", \"*\", \"X_5\"], # noqa: F401\n            original_equation=\"A = x1*y1+x2*y2+x3*y3\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.15.3x\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"-\", \"X_1\", \"*\", \"X_3\", \")\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"x1 = (x-u*t)/sqrt(1-u^2/c^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.10.7\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"m = m_0/sqrt(1-v^2/c^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_9v,\n            dataset_name=\"I.9.18\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_2\", \"*\", \"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"(\", \"X_4\", \"-\", \"X_3\", \")\", \"^2\", \"+\", \"(\", \"X_6\", \"-\", \"X_5\", \")\", \"^2\", \"+\", \"(\", \"X_8\", \"-\", \"X_7\", \")\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"F = G*m1*m2/((x2-x1)^2+(y2-y1)^2+(z2-z1)^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.15.3t\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_3\", \"-\", \"X_2\", \"*\", \"X_0\", \"/\", \"X_1\", \"^2\", \")\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_2\", \"^2\", \"/\", \"X_1\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"t1 = (t-u*x/c^2)/sqrt(1-u^2/c^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_8v,\n            dataset_name=\"II.36.38\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"*\", \"X_1\", \")\", \"/\", \"(\", \"X_2\", \"*\", \"X_3\", \")\", \"+\", \"(\", \"(\", \"X_0\", \"*\", \"X_4\", \")\", \"/\", \"(\", \"X_5\", \"*\", \"X_6\", \"^2\", \"*\", \"X_2\", \"*\", \"X_3\", \")\", \")\", \"*\", \"X_7\"], # noqa: F401\n            original_equation=\"f = mom*H/(kb*T)+(mom*alpha)/(epsilon*c**2*kb*T)*M\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.43.43\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"1\", \"/\", \"(\", \"X_0\", \"-\", \"1\", \")\", \")\", \"*\", \"X_1\", \"*\", \"X_3\", \"/\", \"X_2\"], # noqa: F401\n            original_equation=\"kappa = 1/(gamma-1)*kb*v/A\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.15.5\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"u-\", \"X_0\", \"*\", \"X_1\", \"*\", \"cos\", \"(\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"E_n = -p_d*Ef*cos(theta)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.37.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"+\", \"X_1\", \"+\", \"2\", \"*\", \"sqrt\", \"(\", \"X_0\", \"*\", \"X_1\", \")\", \"*\", \"cos\", \"(\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"Int = I1+I2+2*sqrt(I1*I2)*cos(delta)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"II.6.11\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"1\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_0\", \")\", \")\", \"*\", \"X_1\", \"*\", \"cos\", \"(\", \"X_2\", \")\", \"/\", \"X_3\", \"^2\"], # noqa: F401\n            original_equation=\"Volt = 1/(4*pi*epsilon)*p_d*cos(theta)/r^2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"III.7.38\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"2\", \"*\", \"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\"], # noqa: F401\n            original_equation=\"omega = 2*mom*B/(h/(2*pi))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.34.2a\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"2\", \"*\", \"pi\", \"*\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"l = q*v/(2*pi*r)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.13.23\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"rho_c = rho_c_0/sqrt(1-v^2/c^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.29.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"X_1\"], # noqa: F401\n            original_equation=\"k = omega/c\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.38.12\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"4\", \"*\", \"pi\", \"*\", \"X_3\", \"*\", \"(\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"^2\", \"/\", \"(\", \"X_0\", \"*\", \"X_1\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"r = 4*pi*epsilon*(h/(2*pi))^2/(m*q^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"III.15.27\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"2\", \"*\", \"pi\", \"*\", \"X_0\", \"/\", \"(\", \"X_1\", \"*\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"k = 2*pi*alpha/(n*d)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"I.41.16\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"*\", \"X_0\", \"^3\", \"/\", \"(\", \"pi\", \"^2\", \"*\", \"X_4\", \"^2\", \"*\", \"(\", \"exp\", \"(\", \"(\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"*\", \"X_0\", \"/\", \"(\", \"X_3\", \"*\", \"X_1\", \")\", \")\", \"-\", \"1\", \")\", \")\"], # noqa: F401\n            original_equation=\"L_rad = h/(2*pi)*omega^3/(pi^2*c^2*(exp((h/(2*pi))*omega/(kb*T))-1))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.48.20\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_2\", \"^2\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"E_n = m*c^2/sqrt(1-v^2/c^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.11.20\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"^2\", \"*\", \"X_2\", \"/\", \"(\", \"3\", \"*\", \"X_3\", \"*\", \"X_4\", \")\"], # noqa: F401\n            original_equation=\"Pol = n_rho*p_d^2*Ef/(3*kb*T)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.25.13\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"X_1\"], # noqa: F401\n            original_equation=\"Volt = q/C\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"III.15.12\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"2\", \"*\", \"X_0\", \"*\", \"(\", \"1\", \"-\", \"cos\", \"(\", \"X_1\", \"*\", \"X_2\", \")\", \")\"], # noqa: F401\n            original_equation=\"E_n = 2*U*(1-cos(k*d))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.24.6\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"0.25\", \"*\", \"X_0\", \"*\", \"(\", \"X_1\", \"^2\", \"+\", \"X_2\", \"^2\", \")\", \"*\", \"X_3\", \"^2\"], # noqa: F401\n            original_equation=\"E_n = 1/2*m*(omega^2+omega_0^2)*1/2*x^2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.34.27\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_1\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"*\", \"X_0\"], # noqa: F401\n            original_equation=\"E_n =(h/(2*pi))*omega\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.43.31\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_2\", \"*\", \"X_1\"], # noqa: F401\n            original_equation=\"D = mob*kb*T\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.29.16\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"sqrt\", \"(\", \"X_0\", \"^2\", \"+\", \"X_1\", \"^2\", \"-\", \"2\", \"*\", \"X_0\", \"*\", \"X_1\", \"*\", \"cos\", \"(\", \"X_2\", \"-\", \"X_3\", \")\", \")\"], # noqa: F401\n            original_equation=\"x = sqrt(x1^2+x2^2-2*x1*x2*cos(theta1-theta2))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.18.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"*\", \"X_2\", \"+\", \"X_1\", \"*\", \"X_3\", \")\", \"/\", \"(\", \"X_0\", \"+\", \"X_1\", \")\"], # noqa: F401\n            original_equation=\"r = (m1*r1+m2*r2)/(m1+m2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_6v,\n            dataset_name=\"II.6.15a\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_1\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_0\", \")\", \")\", \"*\", \"(\", \"3\", \"*\", \"X_5\", \"/\", \"(\", \"X_2\", \"^2\", \"*\", \"X_2\", \"^3\", \")\", \")\", \"*\", \"sqrt\", \"(\", \"X_3\", \"^2\", \"+\", \"X_4\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"Ef = p_d/(4*pi*epsilon)*3*z/r^5*sqrt(x^2+y^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.30.3\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"sin\", \"(\", \"X_2\", \"*\", \"X_1\", \"/\", \"2\", \")\", \"^2\", \"/\", \"sin\", \"(\", \"X_1\", \"/\", \"2\", \")\", \"^2\"], # noqa: F401\n            original_equation=\"Int = Int_0*sin(n*theta/2)^2/sin(theta/2)^2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_6v,\n            dataset_name=\"III.9.52\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"/\", \"(\", \"X_3\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \")\", \"*\", \"sin\", \"(\", \"(\", \"X_4\", \"-\", \"X_5\", \")\", \"*\", \"X_2\", \"/\", \"2\", \")\", \"^2\", \"/\", \"(\", \"(\", \"X_4\", \"-\", \"X_5\", \")\", \"*\", \"X_2\", \"/\", \"2\", \")\", \"^2\"], # noqa: F401\n            original_equation=\"prob = (p_d*Ef*t/(h/(2*pi)))*sin((omega-omega_0)*t/2)^2/((omega-omega_0)*t/2)^2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.34.2\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"/\", \"2\"], # noqa: F401\n            original_equation=\"mom = q*v*r/2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.39.11\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"1\", \"/\", \"(\", \"X_0\", \"-\", \"1\", \")\", \")\", \"*\", \"X_1\", \"*\", \"X_2\"], # noqa: F401\n            original_equation=\"E_n = (1/(gamma-1))*pr*V\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"II.11.28\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"1\", \"+\", \"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"1\", \"-\", \"(\", \"X_0\", \"*\", \"X_1\", \"/\", \"3\", \")\", \")\"], # noqa: F401\n            original_equation=\"theta = 1+n*alpha/(1-(n*alpha/3))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"II.3.24\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_1\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"flux = Pwr/(4*pi*r^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.24.17\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"sqrt\", \"(\", \"X_0\", \"^2\", \"/\", \"X_1\", \"^2\", \"-\", \"pi\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"k = sqrt(omega^2/c^2-pi^2/d^2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"II.13.17\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"1\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_0\", \"*\", \"X_1\", \"^2\", \")\", \")\", \"*\", \"2\", \"*\", \"X_2\", \"/\", \"X_3\"], # noqa: F401\n            original_equation=\"B = 1/(4*pi*epsilon*c^2)*2*I/r\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.12.5\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\"], # noqa: F401\n            original_equation=\"F = q2*Ef\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.35.18\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"(\", \"exp\", \"(\", \"X_3\", \"*\", \"X_4\", \"/\", \"(\", \"X_1\", \"*\", \"X_2\", \")\", \")\", \"+\", \"exp\", \"(\", \"u-\", \"X_3\", \"*\", \"X_4\", \"/\", \"(\", \"X_1\", \"*\", \"X_2\", \")\", \")\", \")\"], # noqa: F401\n            original_equation=\"n = n_0/(exp(mom*B/(kb*T))+exp(-mom*B/(kb*T)))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"II.34.11\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"X_3\", \")\"], # noqa: F401\n            original_equation=\"omega = g_*q*B/(2*m)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.34.29a\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"E_n = q*h/(4*pi*m)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_6v,\n            dataset_name=\"I.32.17\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"0.5\", \"*\", \"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"^2\", \")\", \"*\", \"(\", \"8\", \"*\", \"pi\", \"*\", \"X_3\", \"^2\", \"/\", \"3\", \")\", \"*\", \"(\", \"(\", \"X_4\", \"^2\", \"*\", \"X_4\", \"^2\", \")\", \"/\", \"(\", \"X_4\", \"^2\", \"-\", \"X_5\", \"^2\", \")\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"Pwr = (1/2*epsilon*c*Ef**2)*(8*pi*r**2/3)*(omega**4/(omega**2-omega_0**2)**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.35.21\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"tanh\", \"(\", \"X_1\", \"*\", \"X_2\", \"/\", \"(\", \"X_3\", \"*\", \"X_4\", \")\", \")\"], # noqa: F401\n            original_equation=\"M = n_rho*mom*tanh(mom*B/(kb*T))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"I.44.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"*\", \"ln\", \"(\", \"X_4\", \"/\", \"X_3\", \")\"], # noqa: F401\n            original_equation=\"E_n = n*kb*T*ln(V2/V1)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"III.4.32\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"1\", \"/\", \"(\", \"exp\", \"(\", \"(\", \"X_0\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"*\", \"X_1\", \"/\", \"(\", \"X_2\", \"*\", \"X_3\", \")\", \")\", \"-\", \"1\", \")\"], # noqa: F401\n            original_equation=\"n = 1/(exp((h/(2*pi))*omega/(kb*T))-1)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.10.9\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"/\", \"X_1\", \")\", \"*\", \"1\", \"/\", \"(\", \"1\", \"+\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"Ef = sigma_den/epsilon*1/(1+chi)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"II.38.3\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_3\", \"/\", \"X_2\"], # noqa: F401\n            original_equation=\"F = Y*A*x/d\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.6.2b\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"exp\", \"(\", \"u-\", \"(\", \"(\", \"(\", \"X_1\", \"-\", \"X_2\", \")\", \"/\", \"X_0\", \")\", \"^2\", \")\", \"/\", \"2\", \")\", \"/\", \"(\", \"sqrt\", \"(\", \"2\", \"*\", \"pi\", \")\", \"*\", \"X_0\", \")\"], # noqa: F401\n            original_equation=\"f = exp(-((theta-theta1)/sigma)**2/2)/(sqrt(2*pi)*sigma)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"II.8.31\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"^2\", \"/\", \"2\"], # noqa: F401\n            original_equation=\"E_den = epsilon*Ef**2/2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_1v,\n            dataset_name=\"I.6.2a\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"exp\", \"(\", \"u-\", \"X_0\", \"^2\", \"/\", \"2\", \")\", \"/\", \"sqrt\", \"(\", \"2\", \"*\", \"pi\", \")\"], # noqa: F401\n            original_equation=\"f = exp(-theta**2/2)/sqrt(2*pi)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"III.12.43\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"X_1\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\"], # noqa: F401\n            original_equation=\"L = n*(h/(2*pi))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"III.17.37\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"1\", \"+\", \"X_1\", \"*\", \"cos\", \"(\", \"X_2\", \")\", \")\"], # noqa: F401\n            original_equation=\"f = beta*(1+alpha*cos(theta))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"III.10.19\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"sqrt\", \"(\", \"X_1\", \"^2\", \"+\", \"X_2\", \"^2\", \"+\", \"X_3\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"E_n = mom*sqrt(Bx**2+By**2+Bz**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_6v,\n            dataset_name=\"II.11.7\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"1\", \"+\", \"X_4\", \"*\", \"X_5\", \"*\", \"cos\", \"(\", \"X_3\", \")\", \"/\", \"(\", \"X_1\", \"*\", \"X_2\", \")\", \")\"], # noqa: F401\n            original_equation=\"n = n_0*(1+p_d*Ef*cos(theta)/(kb*T))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.39.1\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"1.5\", \"*\", \"X_0\", \"*\", \"X_1\"], # noqa: F401\n            original_equation=\"E_n = 3/2*pr*V\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.37.1\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"1\", \"+\", \"X_2\", \")\", \"*\", \"X_1\"], # noqa: F401\n            original_equation=\"E_n = mom*(1+chi)*B\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.12.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_2\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_1\", \"*\", \"X_2\", \"^3\", \")\"], # noqa: F401\n            original_equation=\"Ef = q1*r/(4*pi*epsilon*r**3)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"II.27.18\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"^2\"], # noqa: F401\n            original_equation=\"E_den = epsilon*Ef**2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.12.2\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_3\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_2\", \"*\", \"X_3\", \"^3\", \")\"], # noqa: F401\n            original_equation=\"F = q1*q2*r/(4*pi*epsilon*r**3)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"III.13.18\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"2\", \"*\", \"X_0\", \"*\", \"X_1\", \"^2\", \"*\", \"X_2\", \"/\", \"(\", \"X_3\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\"], # noqa: F401\n            original_equation=\"v = 2*E_n*d**2*k/(h/(2*pi))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.11.3\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"X_2\", \"*\", \"(\", \"X_3\", \"^2\", \"-\", \"X_4\", \"^2\", \")\", \")\"], # noqa: F401\n            original_equation=\"x = q*Ef/(m*(omega_0**2-omega**2))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_6v,\n            dataset_name=\"I.40.1\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"exp\", \"(\", \"u-\", \"X_1\", \"*\", \"X_4\", \"*\", \"X_2\", \"/\", \"(\", \"X_5\", \"*\", \"X_3\", \")\", \")\"], # noqa: F401\n            original_equation=\"n = n_0*exp(-m*g*x/(kb*T))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"III.21.20\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"u-\", \"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"/\", \"X_3\"], # noqa: F401\n            original_equation=\"j = -rho_c_0*q*A_vec/m\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.43.16\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"/\", \"X_3\"], # noqa: F401\n            original_equation=\"v = mu_drift*q*Volt/d\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.15.10\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"p = m_0*v/sqrt(1-v**2/c**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.30.5\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"arcsin\", \"(\", \"X_0\", \"/\", \"(\", \"X_2\", \"*\", \"X_1\", \")\", \")\"], # noqa: F401\n            original_equation=\"theta = arcsin(lambd/(n*d))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.50.26\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"cos\", \"(\", \"X_1\", \"*\", \"X_2\", \")\", \"+\", \"X_3\", \"*\", \"cos\", \"(\", \"X_1\", \"*\", \"X_2\", \")\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"x = x1*(cos(omega*t)+alpha*cos(omega*t)**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"I.12.11\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"X_1\", \"+\", \"X_2\", \"*\", \"X_3\", \"*\", \"sin\", \"(\", \"X_4\", \")\", \")\"], # noqa: F401\n            original_equation=\"F = q*(Ef+B*v*sin(theta))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.6.2\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"exp\", \"(\", \"u-\", \"(\", \"(\", \"X_1\", \"/\", \"X_0\", \")\", \"^2\", \")\", \"/\", \"2\", \")\", \"/\", \"(\", \"sqrt\", \"(\", \"2\", \"*\", \"pi\", \")\", \"*\", \"X_0\", \")\"], # noqa: F401\n            original_equation=\"f = exp(-(theta/sigma)**2/2)/(sqrt(2*pi)*sigma)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.14.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"0.5\", \"*\", \"X_0\", \"*\", \"X_1\", \"^2\"], # noqa: F401\n            original_equation=\"U = 1/2*k_spring*x**2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.47.23\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"sqrt\", \"(\", \"X_0\", \"*\", \"X_1\", \"/\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"c = sqrt(gamma*pr/rho)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.8.7\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"0.6\", \"*\", \"X_0\", \"^2\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_1\", \"*\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"E_n = 3/5*q**2/(4*pi*epsilon*d)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"III.15.14\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"^2\", \"/\", \"(\", \"2\", \"*\", \"X_1\", \"*\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"m = (h/(2*pi))**2/(2*E_n*d**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.34.14\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"(\", \"1\", \"+\", \"(\", \"X_1\", \"/\", \"X_0\", \")\", \")\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_0\", \"^2\", \")\", \")\", \"*\", \"X_2\"], # noqa: F401\n            original_equation=\"omega = ((1+v/c)/sqrt(1-v**2/c**2))*omega_0\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"III.8.54\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"sin\", \"(\", \"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \")\", \"^2\"], # noqa: F401\n            original_equation=\"prob = sin(E_n*t/(h/(2*pi)))**2\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.26.2\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"arcsin\", \"(\", \"X_0\", \"*\", \"sin\", \"(\", \"X_1\", \")\", \")\"], # noqa: F401\n            original_equation=\"theta1 = arcsin(n*sin(theta2))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"III.19.51\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"u-\", \"X_0\", \"*\", \"(\", \"X_1\", \"^2\", \"*\", \"X_1\", \"^2\", \")\", \"/\", \"(\", \"(\", \"2\", \"*\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_4\", \")\", \"^2\", \")\", \"*\", \"(\", \"X_2\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"^2\", \")\", \"*\", \"(\", \"1\", \"/\", \"X_3\", \"^2\", \")\", \")\"], # noqa: F401\n            original_equation=\"E_n = -m*q**4/(2*(4*pi*epsilon)**2*(h/(2*pi))**2)*(1/n**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"III.4.33\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"*\", \"X_1\", \"/\", \"(\", \"exp\", \"(\", \"(\", \"X_0\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\", \"*\", \"X_1\", \"/\", \"(\", \"X_2\", \"*\", \"X_3\", \")\", \")\", \"-\", \"1\", \")\"], # noqa: F401\n            original_equation=\"E_n = (h/(2*pi))*omega/(exp((h/(2*pi))*omega/(kb*T))-1)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.34.1\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_2\", \"/\", \"(\", \"1\", \"-\", \"X_1\", \"/\", \"X_0\", \")\"], # noqa: F401\n            original_equation=\"omega = omega_0/(1-v/c)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"II.11.27\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_0\", \"*\", \"X_1\", \"/\", \"(\", \"1\", \"-\", \"(\", \"X_0\", \"*\", \"X_1\", \"/\", \"3\", \")\", \")\", \")\", \"*\", \"X_2\", \"*\", \"X_3\"], # noqa: F401\n            original_equation=\"Pol = n*alpha/(1-(n*alpha/3))*epsilon*Ef\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.13.34\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"/\", \"sqrt\", \"(\", \"1\", \"-\", \"X_1\", \"^2\", \"/\", \"X_2\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"j = rho_c_0*v/sqrt(1-v**2/c**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"II.4.23\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_1\", \"*\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"Volt = q/(4*pi*epsilon*r)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.32.5\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"^2\", \"*\", \"X_1\", \"^2\", \"/\", \"(\", \"6\", \"*\", \"pi\", \"*\", \"X_2\", \"*\", \"X_3\", \"^3\", \")\"], # noqa: F401\n            original_equation=\"Pwr = q**2*a**2/(6*pi*epsilon*c**3)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"I.13.12\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_4\", \"*\", \"X_0\", \"*\", \"X_1\", \"*\", \"(\", \"1\", \"/\", \"X_3\", \"-\", \"1\", \"/\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"U = G*m1*m2*(1/r2-1/r1)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.2.42\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"X_2\", \"-\", \"X_1\", \")\", \"*\", \"X_3\", \"/\", \"X_4\"], # noqa: F401\n            original_equation=\"Pwr = kappa*(T2-T1)*A/d\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.27.6\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"1\", \"/\", \"(\", \"1\", \"/\", \"X_0\", \"+\", \"X_2\", \"/\", \"X_1\", \")\"], # noqa: F401\n            original_equation=\"foc = 1/(1/d1+n/d2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"III.14.14\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"(\", \"exp\", \"(\", \"X_1\", \"*\", \"X_2\", \"/\", \"(\", \"X_3\", \"*\", \"X_4\", \")\", \")\", \"-\", \"1\", \")\"], # noqa: F401\n            original_equation=\"I = I_0*(exp(q*Volt/(kb*T))-1)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.18.12\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"sin\", \"(\", \"X_2\", \")\"], # noqa: F401\n            original_equation=\"tau = r*F*sin(theta)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.18.14\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"*\", \"sin\", \"(\", \"X_3\", \")\"], # noqa: F401\n            original_equation=\"L = m*r*v*sin(theta)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.21.32\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_1\", \"*\", \"X_2\", \"*\", \"(\", \"1\", \"-\", \"X_3\", \"/\", \"X_4\", \")\", \")\"], # noqa: F401\n            original_equation=\"Volt = q/(4*pi*epsilon*r*(1-v/c))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"II.38.14\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"/\", \"(\", \"2\", \"*\", \"(\", \"1\", \"+\", \"X_1\", \")\", \")\"], # noqa: F401\n            original_equation=\"mu_S = Y/(2*(1+sigma))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.34.8\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\", \"/\", \"X_3\"], # noqa: F401\n            original_equation=\"omega = q*v*B/p\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.8.14\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"sqrt\", \"(\", \"(\", \"X_1\", \"-\", \"X_0\", \")\", \"^2\", \"+\", \"(\", \"X_3\", \"-\", \"X_2\", \")\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"d = sqrt((x2-x1)**2+(y2-y1)**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"II.6.15b\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"(\", \"X_1\", \"/\", \"(\", \"4\", \"*\", \"pi\", \"*\", \"X_0\", \")\", \")\", \"*\", \"3\", \"*\", \"cos\", \"(\", \"X_2\", \")\", \"*\", \"sin\", \"(\", \"X_2\", \")\", \"/\", \"X_3\", \"^3\"], # noqa: F401\n            original_equation=\"E_f = p_d/(4*pi*epsilon)*3*cos(theta)*sin(theta)/r**3\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_2v,\n            dataset_name=\"I.12.1\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\"], # noqa: F401\n            original_equation=\"F = mu*Nn\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_5v,\n            dataset_name=\"II.34.29b\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_3\", \"*\", \"X_4\", \"*\", \"X_2\", \"/\", \"(\", \"X_1\", \"/\", \"(\", \"2\", \"*\", \"pi\", \")\", \")\"], # noqa: F401\n            original_equation=\"E_n = g_*mom*B*Jz/(h/(2*pi))\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.13.4\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"0.5\", \"*\", \"X_0\", \"*\", \"(\", \"X_1\", \"^2\", \"+\", \"X_2\", \"^2\", \"+\", \"X_3\", \"^2\", \")\"], # noqa: F401\n            original_equation=\"K = 1/2*m*(v**2+u**2+w**2)\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_4v,\n            dataset_name=\"I.39.22\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_3\", \"*\", \"X_1\", \"/\", \"X_2\"], # noqa: F401\n            original_equation=\"pr = n*kb*T/V\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n        benchmark.add_dataset(\n            \"\",\n            sl_3v,\n            dataset_name=\"I.14.3\",\n            ranking_function=\"rmse\",\n            ground_truth = [\"X_0\", \"*\", \"X_1\", \"*\", \"X_2\"], # noqa: F401\n            original_equation=\"U = m*g*z\",\n            max_evaluations=100000,\n            max_expression_length=50,\n            success_threshold=1e-7,\n            dataset_metadata=benchmark.metadata,\n            constant_range=[-5.0, 5.0],\n            result_augmenters=[],\n            seed = seed\n        )\n\n        return benchmark\n</code></pre>"},{"location":"references/dataset/srbenchmark/#SRToolkit.dataset.sr_benchmark.SR_benchmark.nguyen","title":"nguyen  <code>staticmethod</code>","text":"<pre><code>nguyen(dataset_directory: str, seed: Optional[int] = None) -&gt; SR_benchmark\n</code></pre> <p>Downloads and initializes the Nguyen benchmark datasets for symbolic regression.</p> <p>This method downloads the Nguyen symbolic regression benchmark datasets from a specified URL and initializes a set of datasets using a provided dataset directory. It creates two symbol libraries for equations with one variable and two variables, respectively, and populates the benchmark with various Nguyen equations, each represented with its symbolic tokens and associated symbol library.</p> <p>For more information about the Nguyen benchmark, see the following paper: https://doi.org/10.1007/s10710-010-9121-2</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; benchmark = SR_benchmark.nguyen('data/nguyen/')\n&gt;&gt;&gt; for dataset in benchmark.list_datasets(verbose=False):\n...     ds = benchmark.create_dataset(dataset)\n...     rmse = ds.create_evaluator().evaluate_expr(ds.ground_truth)\n...     if rmse &gt; ds.success_threshold:\n...         print(f'Failed dataset: {dataset} with RMSE {rmse}')\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dataset_directory</code> <code>str</code> <p>The directory path where the benchmark dataset will be downloaded and stored or where it will be loaded from.</p> required <code>seed</code> <code>Optional[int]</code> <p>The seed to use for the random number generator. If None, the random number generation will not be seeded</p> <code>None</code> <p>Returns:</p> Name Type Description <code>SR_benchmark</code> <code>SR_benchmark</code> <p>An initialized SR_benchmark instance containing the Nguyen datasets.</p> Source code in <code>SRToolkit/dataset/sr_benchmark.py</code> <pre><code>    @staticmethod\n    def nguyen(dataset_directory: str, seed: Optional[int] = None) -&gt; \"SR_benchmark\":\n        \"\"\"\n        Downloads and initializes the Nguyen benchmark datasets for symbolic regression.\n\n        This method downloads the Nguyen symbolic regression benchmark datasets from a specified URL\n        and initializes a set of datasets using a provided dataset directory. It creates two symbol libraries\n        for equations with one variable and two variables, respectively, and populates the benchmark with various\n        Nguyen equations, each represented with its symbolic tokens and associated symbol library.\n\n        For more information about the Nguyen benchmark, see the following paper: &lt;https://doi.org/10.1007/s10710-010-9121-2&gt;\n\n        Examples:\n            &gt;&gt;&gt; benchmark = SR_benchmark.nguyen('data/nguyen/')\n            &gt;&gt;&gt; for dataset in benchmark.list_datasets(verbose=False):\n            ...     ds = benchmark.create_dataset(dataset)\n            ...     rmse = ds.create_evaluator().evaluate_expr(ds.ground_truth)\n            ...     if rmse &gt; ds.success_threshold:\n            ...         print(f'Failed dataset: {dataset} with RMSE {rmse}')\n\n        Args:\n            dataset_directory: The directory path where the benchmark dataset will be downloaded and stored or where\n                it will be loaded from.\n            seed: The seed to use for the random number generator. If None, the random number generation will not\n                be seeded\n\n        Returns:\n            SR_benchmark: An initialized SR_benchmark instance containing the Nguyen datasets.\n        \"\"\"\n        url = \"https://raw.githubusercontent.com/smeznar/SymbolicRegressionToolkit/master/data/nguyen.zip\"\n        SR_benchmark.download_benchmark_data(url, dataset_directory)\n        # we create a SymbolLibrary with 1 and with 2 variables\n        # Each library contains +, -, *, /, sin, cos, exp, log, sqrt, ^2, ^3\n        sl_1v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"sin\", \"cos\", \"exp\", \"log\", \"sqrt\", \"^2\", \"^3\"], 1)\n        sl_2v = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"/\", \"sin\", \"cos\", \"exp\", \"log\", \"sqrt\", \"^2\", \"^3\"], 2)\n\n        metadata = {\"description\": \"Symbolic regression benchmark with 10 expressions that don't contain constant \"\n                                   \"parameters. First 4 are polynomials of different degrees. First eight expressions \"\n                                   \"contain 1 variable, last two expressions contain two variables. This benchmark \"\n                                   \"doesn't contain the original data, only expressions\",\n                    \"citation\": \"\"\"@article{Uy2011,\n    author={Uy, Nguyen Quang and Hoai, Nguyen Xuan and O'Neill, Michael and McKay, R. I. and Galv{\\'a}n-L{\\'o}pez, Edgar},\n    title={Semantically-based crossover in genetic programming: application to real-valued symbolic regression},\n    journal={Genetic Programming and Evolvable Machines},\n    year={2011},\n    month={Jun},\n    day={01},\n    volume={12},\n    number={2},\n    pages={91-119},\n}\"\"\"}\n\n        # Add datasets to the benchmark\n        benchmark = SR_benchmark(\"Nguyen\", dataset_directory, metadata=metadata)\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-1\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"X_0\", \"+\", \"X_0\", \"^2\", \"+\", \"X_0\", \"^3\"], # noqa: F401\n\t\t\toriginal_equation=\"y = x+x^2+x^3\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-2\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"X_0\", \"+\", \"X_0\", \"^2\", \"+\", \"X_0\", \"^3\", \"+\", \"X_0\", \"*\", \"X_0\", \"^3\"], # noqa: F401\n\t\t\toriginal_equation=\"y = x+x^2+x^3+x^4\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-3\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"X_0\", \"+\", \"X_0\", \"^2\", \"+\", \"X_0\", \"^3\", \"+\", \"X_0\", \"*\", \"X_0\", \"^3\", \"+\", \"X_0\", \"^2\", \"*\", \"X_0\", \"^3\"], # noqa: F401\n\t\t\toriginal_equation=\"y = x+x^2+x^3+x^4+x^5\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-4\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"X_0\", \"+\", \"X_0\", \"^2\", \"+\", \"X_0\", \"^3\", \"+\", \"X_0\", \"*\", \"X_0\", \"^3\", \"+\", \"X_0\", \"^2\", \"*\", \"X_0\", \"^3\", \"+\", \"X_0\", \"^3\", \"*\", \"X_0\", \"^3\"], # noqa: F401\n\t\t\toriginal_equation=\"y = x+x^2+x^3+x^4+x^5+x^6\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-5\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"sin\", \"(\", \"X_0\", \"^2\", \")\", \"*\", \"cos\", \"(\", \"X_0\", \")\", \"-\", \"1\"], # noqa: F401\n\t\t\toriginal_equation=\"y = sin(x^2)*cos(x)-1\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-6\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"sin\", \"(\", \"X_0\", \")\", \"+\", \"sin\", \"(\", \"X_0\", \"+\", \"X_0\", \"^2\", \")\"], # noqa: F401\n\t\t\toriginal_equation=\"y = sin(x)+sin(x+x^2)\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-7\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"log\", \"(\", \"1\", \"+\", \"X_0\", \")\", \"+\", \"log\", \"(\", \"1\", \"+\", \"X_0\", \"^2\", \")\"], # noqa: F401\n\t\t\toriginal_equation=\"y = log(1+x)+log(1+x^2)\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_1v,\n\t\t\tdataset_name=\"NG-8\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"sqrt\", \"(\", \"X_0\", \")\"], # noqa: F401\n\t\t\toriginal_equation=\"y = sqrt(x)\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_2v,\n\t\t\tdataset_name=\"NG-9\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"sin\", \"(\", \"X_0\", \")\", \"+\", \"sin\", \"(\", \"X_1\", \"^2\", \")\"], # noqa: F401\n\t\t\toriginal_equation=\"y = sin(x)+sin(y^2)\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        benchmark.add_dataset(\n\t\t\t\"\",\n\t\t\tsl_2v,\n\t\t\tdataset_name=\"NG-10\",\n\t\t\tranking_function=\"rmse\",\n\t\t\tground_truth = [\"2\", \"*\", \"sin\", \"(\", \"X_0\", \")\", \"*\", \"cos\", \"(\", \"X_1\", \")\"], # noqa: F401\n\t\t\toriginal_equation=\"y = 2*sin(x)*cos(y)\",\n\t\t\tmax_evaluations=100000,\n\t\t\tmax_expression_length=50,\n\t\t\tsuccess_threshold=1e-7,\n\t\t\tdataset_metadata=benchmark.metadata,\n\t\t\tresult_augmenters=[],\n\t\t\tseed = seed\n\t\t)\n\n        return benchmark\n</code></pre>"},{"location":"references/dataset/srdataset/","title":"SR Dataset","text":""},{"location":"references/dataset/srdataset/#SRToolkit.dataset.sr_dataset","title":"SRToolkit.dataset.sr_dataset","text":""},{"location":"references/dataset/srdataset/#SRToolkit.dataset.sr_dataset.SR_dataset","title":"SR_dataset","text":"<pre><code>SR_dataset(X: ndarray, symbol_library: SymbolLibrary, ranking_function: str = 'rmse', y: Optional[ndarray] = None, max_evaluations: int = -1, ground_truth: Optional[Union[List[str], Node, ndarray]] = None, original_equation: Optional[str] = None, success_threshold: Optional[float] = None, result_augmenters: Optional[List[ResultAugmenter]] = None, seed: Optional[int] = None, dataset_metadata: Optional[dict] = None, **kwargs)\n</code></pre> <p>Initializes an instance of the SR_dataset class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n&gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n&gt;&gt;&gt; evaluator = dataset.create_evaluator()\n&gt;&gt;&gt; evaluator.evaluate_expr([\"sin\", \"(\", \"X_0\", \")\"]) &lt; dataset.success_threshold\nFalse\n&gt;&gt;&gt; evaluator.evaluate_expr([\"u-\", \"C\", \"*\", \"X_1\", \"+\", \"X_0\"]) &lt; dataset.success_threshold\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data to be used in calculation of the error/ranking function. We assume that X is a 2D array with the shape (n_samples, n_features).</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use.</p> required <code>ranking_function</code> <code>str</code> <p>The ranking function to use. Currently, \"rmse\" and \"bed\" are supported. RMSE is the standard ranking function in symbolic regression, calculating the error between the ground truth values and outputs of expressions with fitted free parameters. BED is a stochastic measure that calculates the behavioral distance between two expressions that can contain free parameters. Its advantage is that expressions with lots of parameters are less likely to overfit, and thus the measure focuses more on structure identification.</p> <code>'rmse'</code> <code>y</code> <code>Optional[ndarray]</code> <p>The target values to be used in parameter estimation if the ranking function is \"rmse\".</p> <code>None</code> <code>max_evaluations</code> <code>int</code> <p>The maximum number of expressions to evaluate. Less than 0 means no limit.</p> <code>-1</code> <code>ground_truth</code> <code>Optional[Union[List[str], Node, ndarray]]</code> <p>The ground truth expression, represented as a list of tokens (strings) in the infix notation, a SRToolkit.utils.Node object, or a numpy array representing behavior (see SRToolkit.utils.create_behavior_matrix for more details).</p> <code>None</code> <code>original_equation</code> <code>Optional[str]</code> <p>The original equation from which the ground truth expression was generated).</p> <code>None</code> <code>success_threshold</code> <code>Optional[float]</code> <p>The threshold for determining whether an expression is successful or not. If None,</p> <code>None</code> <code>result_augmenters</code> <code>Optional[List[ResultAugmenter]]</code> <p>Optional list of objects that augment the results returned by the \"get_results\" function.</p> <code>None</code> <code>seed</code> <code>Optional[int]</code> <p>The seed to use for random number generation/reproducibility. Default is None, which means no seed is used.</p> <code>None</code> <code>dataset_metadata</code> <code>Optional[dict]</code> <p>An optional dictionary containing metadata about this evaluation. This could include information such as the name of the dataset, a citation for the dataset, number of variables, etc.</p> <code>None</code> <p>Other Parameters:</p> Name Type Description <code>method</code> <code>str</code> <p>The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested. Default is \"L-BFGS-B\".</p> <code>tol</code> <code>float</code> <p>The tolerance for termination. Default is 1e-6.</p> <code>gtol</code> <code>float</code> <p>The tolerance for the gradient norm. Default is 1e-3.</p> <code>max_iter</code> <code>int</code> <p>The maximum number of iterations. Default is 100.</p> <code>constant_bounds</code> <code>Tuple[float, float]</code> <p>A tuple of two elements, specifying the lower and upper bounds for the constant values. Default is (-5, 5).</p> <code>initialization</code> <code>str</code> <p>The method to use for initializing the constant values. Currently, only \"random\" and \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\" creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".</p> <code>max_constants</code> <code>int</code> <p>The maximum number of constants allowed in the expression. Default is 8.</p> <code>max_expr_length</code> <code>int</code> <p>The maximum length of the expression. Default is -1 (no limit).</p> <code>num_points_sampled</code> <code>int</code> <p>The number of points to sample when estimating the behavior of an expression. Default is 64. If num_points_sampled==-1, then the number of points sampled is equal to the number of points in the dataset.</p> <code>bed_X</code> <code>Optional[ndarray]</code> <p>Points used for BED evaluation. If None and domain_bounds are given, points are sampled from the domain. If None and domain_bounds are not givem, points are randomly selected from X. Default is None.</p> <code>num_consts_sampled</code> <code>int</code> <p>Number of constants sampled for BED evaluation. Default is 32.</p> <code>domain_bounds</code> <code>Optional[List[Tuple[float, float]]]</code> <p>Bounds for the domain to be used if bed_X is None to sample random points. Default is None.</p> Source code in <code>SRToolkit/dataset/sr_dataset.py</code> <pre><code>def __init__(\n    self,\n    X: np.ndarray,\n    symbol_library: SymbolLibrary,\n    ranking_function: str = \"rmse\",\n    y: Optional[np.ndarray] = None,\n    max_evaluations: int = -1,\n    ground_truth: Optional[Union[List[str], Node, np.ndarray]] = None,\n    original_equation: Optional[str] = None,\n    success_threshold: Optional[float] = None,\n    result_augmenters: Optional[List[ResultAugmenter]] = None,\n    seed: Optional[int] = None,\n    dataset_metadata: Optional[dict] = None,\n    **kwargs,\n):\n    \"\"\"\n    Initializes an instance of the SR_dataset class.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n        &gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n        ...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n        &gt;&gt;&gt; evaluator = dataset.create_evaluator()\n        &gt;&gt;&gt; evaluator.evaluate_expr([\"sin\", \"(\", \"X_0\", \")\"]) &lt; dataset.success_threshold\n        False\n        &gt;&gt;&gt; evaluator.evaluate_expr([\"u-\", \"C\", \"*\", \"X_1\", \"+\", \"X_0\"]) &lt; dataset.success_threshold\n        True\n\n    Args:\n        X: The input data to be used in calculation of the error/ranking function. We assume that X is a 2D array\n            with the shape (n_samples, n_features).\n        symbol_library: The symbol library to use.\n        ranking_function: The ranking function to use. Currently, \"rmse\" and \"bed\" are supported. RMSE is the\n            standard ranking function in symbolic regression, calculating the error between the ground truth values\n            and outputs of expressions with fitted free parameters. BED is a stochastic measure that calculates\n            the behavioral distance between two expressions that can contain free parameters. Its advantage is that\n            expressions with lots of parameters are less likely to overfit, and thus the measure focuses more on\n            structure identification.\n        y: The target values to be used in parameter estimation if the ranking function is \"rmse\".\n        max_evaluations: The maximum number of expressions to evaluate. Less than 0 means no limit.\n        ground_truth: The ground truth expression, represented as a list of tokens (strings) in the infix notation,\n            a SRToolkit.utils.Node object, or a numpy array representing behavior\n            (see SRToolkit.utils.create_behavior_matrix for more details).\n        original_equation: The original equation from which the ground truth expression was generated).\n        success_threshold: The threshold for determining whether an expression is successful or not. If None,\n        result_augmenters: Optional list of objects that augment the results returned by the \"get_results\" function.\n        seed: The seed to use for random number generation/reproducibility. Default is None, which means no seed is used.\n        dataset_metadata: An optional dictionary containing metadata about this evaluation. This could include\n            information such as the name of the dataset, a citation for the dataset, number of variables, etc.\n\n    Keyword Arguments:\n        method (str): The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested.\n            Default is \"L-BFGS-B\".\n        tol (float): The tolerance for termination. Default is 1e-6.\n        gtol (float): The tolerance for the gradient norm. Default is 1e-3.\n        max_iter (int): The maximum number of iterations. Default is 100.\n        constant_bounds (Tuple[float, float]): A tuple of two elements, specifying the lower and upper bounds for\n            the constant values. Default is (-5, 5).\n        initialization (str): The method to use for initializing the constant values. Currently, only \"random\" and\n            \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\"\n            creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".\n        max_constants (int): The maximum number of constants allowed in the expression. Default is 8.\n        max_expr_length (int): The maximum length of the expression. Default is -1 (no limit).\n        num_points_sampled (int): The number of points to sample when estimating the behavior of an expression.\n            Default is 64. If num_points_sampled==-1, then the number of points sampled is equal to the number of\n            points in the dataset.\n        bed_X (Optional[np.ndarray]): Points used for BED evaluation. If None and domain_bounds are given, points\n            are sampled from the domain. If None and domain_bounds are not givem, points are randomly selected\n            from X. Default is None.\n        num_consts_sampled (int): Number of constants sampled for BED evaluation. Default is 32.\n        domain_bounds (Optional[List[Tuple[float, float]]]): Bounds for the domain to be used if bed_X is None to\n            sample random points. Default is None.\n    \"\"\"\n    self.X = X\n    self.symbol_library = symbol_library\n    self.y = y\n    self.max_evaluations = max_evaluations\n    self.success_threshold = success_threshold\n    self.ranking_function = ranking_function\n    self.ground_truth = ground_truth\n    self.original_equation = original_equation\n    self.result_augmenters = result_augmenters\n    self.kwargs = kwargs\n\n    # See if symbols contain a symbol for constants\n    symbols_metadata = self.symbol_library.symbols.values()\n    self.contains_constants = any(\n        [symbol[\"type\"] == \"const\" for symbol in symbols_metadata]\n    )\n\n    self.seed = seed\n    self.dataset_metadata = dataset_metadata\n</code></pre>"},{"location":"references/dataset/srdataset/#SRToolkit.dataset.sr_dataset.SR_dataset.evaluate_approach","title":"evaluate_approach","text":"<pre><code>evaluate_approach(sr_approach: SR_approach, num_experiments: int = 1, top_k: int = 20, initial_seed: int = None, results: Optional[SR_results] = None) -&gt; SR_results\n</code></pre> <p>Evaluates an SR_approach on this dataset.</p> <p>Parameters:</p> Name Type Description Default <code>sr_approach</code> <code>SR_approach</code> <p>An instance of SR_approach that will be evaluated on this dataset.</p> required <code>num_experiments</code> <code>int</code> <p>The number of times the approach should be evaluated on this dataset.</p> <code>1</code> <code>top_k</code> <code>int</code> <p>Number of the best expressions presented in the results</p> <code>20</code> <code>seed</code> <p>The seed used for random number generation. If None, the seed from the dataset is used.</p> required <code>results</code> <code>Optional[SR_results]</code> <p>An optional SR_results object to which the results of the evaluation will be added. If None, a new SR_results object will be created.</p> <code>None</code> <p>Returns:</p> Type Description <code>SR_results</code> <p>The results of the evaluation.</p> Source code in <code>SRToolkit/dataset/sr_dataset.py</code> <pre><code>def evaluate_approach(self, sr_approach: SR_approach, num_experiments: int = 1, top_k: int = 20,\n                      initial_seed: int = None, results: Optional[SR_results] = None) -&gt; SR_results:\n    \"\"\"\n    Evaluates an SR_approach on this dataset.\n\n    Args:\n        sr_approach: An instance of SR_approach that will be evaluated on this dataset.\n        num_experiments: The number of times the approach should be evaluated on this dataset.\n        top_k: Number of the best expressions presented in the results\n        seed: The seed used for random number generation. If None, the seed from the dataset is used.\n        results: An optional SR_results object to which the results of the evaluation will be added. If None,\n            a new SR_results object will be created.\n\n    Returns:\n        The results of the evaluation.\n    \"\"\"\n    if initial_seed is None:\n        seed = self.seed\n    else:\n        seed = initial_seed\n\n    if results is None:\n        results = SR_results()\n\n    for experiment in range(num_experiments):\n        print(f\"Running experiment {experiment+1}/{num_experiments}\")\n        if seed is not None:\n            seed += 1\n\n        evaluator = self.create_evaluator(seed)\n        approach = sr_approach.clone()\n        approach.search(evaluator, seed)\n        results += evaluator.get_results(approach.name, top_k)\n    return results\n</code></pre>"},{"location":"references/dataset/srdataset/#SRToolkit.dataset.sr_dataset.SR_dataset.create_evaluator","title":"create_evaluator","text":"<pre><code>create_evaluator(metadata: dict = None, seed: int = None) -&gt; SR_evaluator\n</code></pre> <p>Creates an instance of the SR_evaluator class from this dataset.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n&gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n&gt;&gt;&gt; evaluator = dataset.create_evaluator()\n&gt;&gt;&gt; evaluator.evaluate_expr([\"sin\", \"(\", \"X_0\", \")\"])\n8.056453977203414\n&gt;&gt;&gt; evaluator.evaluate_expr([\"X_1\", \"+\", \"X_0\"])\n0.0\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>dict</code> <p>An optional dictionary containing metadata about this evaluation. This could include information such as the dataset used, the model used, seed, etc.</p> <code>None</code> <code>seed</code> <code>int</code> <p>An optional seed to be used for the random number generator. If None, the seed from the dataset is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>SR_evaluator</code> <p>An instance of the SR_evaluator class.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>if an error occurs when creating the evaluator.</p> Source code in <code>SRToolkit/dataset/sr_dataset.py</code> <pre><code>def create_evaluator(self, metadata: dict = None, seed: int = None) -&gt; SR_evaluator:\n    \"\"\"\n    Creates an instance of the SR_evaluator class from this dataset.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n        &gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n        ...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n        &gt;&gt;&gt; evaluator = dataset.create_evaluator()\n        &gt;&gt;&gt; evaluator.evaluate_expr([\"sin\", \"(\", \"X_0\", \")\"])\n        8.056453977203414\n        &gt;&gt;&gt; evaluator.evaluate_expr([\"X_1\", \"+\", \"X_0\"])\n        0.0\n\n    Args:\n        metadata: An optional dictionary containing metadata about this evaluation. This could include\n            information such as the dataset used, the model used, seed, etc.\n        seed: An optional seed to be used for the random number generator. If None, the seed from the dataset is used.\n\n    Returns:\n        An instance of the SR_evaluator class.\n\n    Raises:\n        Exception: if an error occurs when creating the evaluator.\n    \"\"\"\n    if metadata is None:\n        metadata = dict()\n    metadata[\"dataset_metadata\"] = self.dataset_metadata\n\n    if seed is None:\n        seed = self.seed\n\n    try:\n        return SR_evaluator(\n            X=self.X,\n            y=self.y,\n            max_evaluations=self.max_evaluations,\n            success_threshold=self.success_threshold,\n            ranking_function=self.ranking_function,\n            ground_truth=self.ground_truth,\n            result_augmenters=self.result_augmenters,\n            symbol_library=self.symbol_library,\n            seed=seed,\n            metadata=metadata,\n            **self.kwargs,\n        )\n    except Exception as e:\n        print(f\"Error creating evaluator: {e}\")\n        raise e\n</code></pre>"},{"location":"references/dataset/srdataset/#SRToolkit.dataset.sr_dataset.SR_dataset.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Returns a string describing this dataset.</p> <p>The string describes the target expression, symbols that should be used, and the success threshold. It also includes any constraints that should be followed when evaluating a model on this dataset. These constraints include the maximum number of expressions to evaluate, the maximum length of the expression, and the maximum number of constants allowed in the expression. If the symbol library contains a symbol for constants, the string also includes the range of constants.</p> <p>For other metadata, please refer to the attribute self.dataset_metadata.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n&gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n&gt;&gt;&gt; str(dataset)\n'Dataset for target expression z = x + y. When evaluating your model on this dataset, you should limit your generative model to only produce expressions using the following symbols: +, -, *, /, ^, u-, sqrt, sin, cos, exp, tan, arcsin, arccos, arctan, sinh, cosh, tanh, floor, ceil, ln, log, ^-1, ^2, ^3, ^4, ^5, pi, e, C, X_0, X_1.\\nExpressions will be ranked based on the RMSE ranking function.\\nExpressions are deemed successful if the root mean squared error is less than 1e-06. However, we advise that you check the best performing expressions manually to ensure they are correct.\\nDataset uses the default limitations (extra arguments) from the SR_evaluator.The expressions in the dataset can contain constants/free parameters.\\nFor other metadata, please refer to the attribute self.dataset_metadata.'\n</code></pre> <p>Returns:</p> Type Description <code>str</code> <p>A string describing this dataset.</p> Source code in <code>SRToolkit/dataset/sr_dataset.py</code> <pre><code>def __str__(self) -&gt; str:\n    r\"\"\"\n    Returns a string describing this dataset.\n\n    The string describes the target expression, symbols that should be used,\n    and the success threshold. It also includes any constraints that should\n    be followed when evaluating a model on this dataset. These constraints include the maximum\n    number of expressions to evaluate, the maximum length of the expression,\n    and the maximum number of constants allowed in the expression. If the\n    symbol library contains a symbol for constants, the string also includes\n    the range of constants.\n\n    For other metadata, please refer to the attribute self.dataset_metadata.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n        &gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n        ...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n        &gt;&gt;&gt; str(dataset)\n        'Dataset for target expression z = x + y. When evaluating your model on this dataset, you should limit your generative model to only produce expressions using the following symbols: +, -, *, /, ^, u-, sqrt, sin, cos, exp, tan, arcsin, arccos, arctan, sinh, cosh, tanh, floor, ceil, ln, log, ^-1, ^2, ^3, ^4, ^5, pi, e, C, X_0, X_1.\\nExpressions will be ranked based on the RMSE ranking function.\\nExpressions are deemed successful if the root mean squared error is less than 1e-06. However, we advise that you check the best performing expressions manually to ensure they are correct.\\nDataset uses the default limitations (extra arguments) from the SR_evaluator.The expressions in the dataset can contain constants/free parameters.\\nFor other metadata, please refer to the attribute self.dataset_metadata.'\n\n    Returns:\n        A string describing this dataset.\n    \"\"\"\n    description = f\"Dataset for target expression {self.original_equation}.\"\n    description += (\n        f\" When evaluating your model on this dataset, you should limit your generative model to only \"\n        f\"produce expressions using the following symbols: {str(self.symbol_library)}.\\nExpressions will be \"\n        f\"ranked based on the {self.ranking_function.upper()} ranking function.\\n\"\n    )\n\n    if self.success_threshold is not None:\n        description += (\"Expressions are deemed successful if the root mean squared error is less than \"\n                        f\"{self.success_threshold}. However, we advise that you check the best performing \"\n                        f\"expressions manually to ensure they are correct.\\n\")\n\n    if len(self.kwargs) == 0:\n        description += \"Dataset uses the default limitations (extra arguments) from the SR_evaluator.\"\n    else:\n        limitations = \"Non default limitations (extra arguments) from the SR_evaluators are:\"\n        for key, value in self.kwargs.items():\n            limitations += f\" {key}={value}, \"\n        limitations = limitations[:-2] + \".\\n\"\n        description += limitations\n\n    if self.contains_constants:\n        description += f\"The expressions in the dataset can contain constants/free parameters.\\n\"\n\n    description += \"For other metadata, please refer to the attribute self.dataset_metadata.\"\n\n    return description\n</code></pre>"},{"location":"references/dataset/srdataset/#SRToolkit.dataset.sr_dataset.SR_dataset.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of this dataset. This is mainly used for saving the dataset to disk.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n&gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n&gt;&gt;&gt; dataset.to_dict(\"data/example_ds\", \"test_dataset\")\n{'symbol_library': {'type': 'SymbolLibrary', 'symbols': {'+': {'symbol': '+', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} + {}', 'latex_str': '{} + {}'}, '-': {'symbol': '-', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} - {}', 'latex_str': '{} - {}'}, '*': {'symbol': '*', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} * {}', 'latex_str': '{} \\\\cdot {}'}, '/': {'symbol': '/', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} / {}', 'latex_str': '\\\\frac{{{}}}{{{}}}'}, '^': {'symbol': '^', 'type': 'op', 'precedence': 2, 'np_fn': '{} = np.power({},{})', 'latex_str': '{}^{{{}}}'}, 'u-': {'symbol': 'u-', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = -{}', 'latex_str': '- {}'}, 'sqrt': {'symbol': 'sqrt', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sqrt({})', 'latex_str': '\\\\sqrt {{{}}}'}, 'sin': {'symbol': 'sin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sin({})', 'latex_str': '\\\\sin {}'}, 'cos': {'symbol': 'cos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cos({})', 'latex_str': '\\\\cos {}'}, 'exp': {'symbol': 'exp', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.exp({})', 'latex_str': 'e^{{{}}}'}, 'tan': {'symbol': 'tan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tan({})', 'latex_str': '\\\\tan {}'}, 'arcsin': {'symbol': 'arcsin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arcsin({})', 'latex_str': '\\\\arcsin {}'}, 'arccos': {'symbol': 'arccos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arccos({})', 'latex_str': '\\\\arccos {}'}, 'arctan': {'symbol': 'arctan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arctan({})', 'latex_str': '\\\\arctan {}'}, 'sinh': {'symbol': 'sinh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sinh({})', 'latex_str': '\\\\sinh {}'}, 'cosh': {'symbol': 'cosh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cosh({})', 'latex_str': '\\\\cosh {}'}, 'tanh': {'symbol': 'tanh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tanh({})', 'latex_str': '\\\\tanh {}'}, 'floor': {'symbol': 'floor', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.floor({})', 'latex_str': '\\\\lfloor {} \\\\rfloor'}, 'ceil': {'symbol': 'ceil', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.ceil({})', 'latex_str': '\\\\lceil {} \\\\rceil'}, 'ln': {'symbol': 'ln', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log({})', 'latex_str': '\\\\ln {}'}, 'log': {'symbol': 'log', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log10({})', 'latex_str': '\\\\log_{{10}} {}'}, '^-1': {'symbol': '^-1', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = 1/{}', 'latex_str': '{}^{{-1}}'}, '^2': {'symbol': '^2', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**2', 'latex_str': '{}^2'}, '^3': {'symbol': '^3', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**3', 'latex_str': '{}^3'}, '^4': {'symbol': '^4', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**4', 'latex_str': '{}^4'}, '^5': {'symbol': '^5', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**5', 'latex_str': '{}^5'}, 'pi': {'symbol': 'pi', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.pi)', 'latex_str': '\\\\pi'}, 'e': {'symbol': 'e', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.e)', 'latex_str': 'e'}, 'C': {'symbol': 'C', 'type': 'const', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], C[{}])', 'latex_str': 'C_{{{}}}'}, 'X_0': {'symbol': 'X_0', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 0]', 'latex_str': 'X_{0}'}, 'X_1': {'symbol': 'X_1', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 1]', 'latex_str': 'X_{1}'}}, 'preamble': ['import numpy as np'], 'num_variables': 2}, 'ranking_function': 'rmse', 'max_evaluations': 10000, 'success_threshold': 1e-06, 'original_equation': 'z = x + y', 'seed': None, 'dataset_metadata': None, 'kwargs': {}, 'result_augmenters': None, 'ground_truth': ['X_0', '+', 'X_1'], 'dataset_path': 'data/example_ds/test_dataset.npz'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>The path to the directory where the data in the dataset should be saved.</p> required <code>name</code> <code>str</code> <p>The name of the dataset. This will be used to name the files containing the dataset data.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary representation of this dataset.</p> Source code in <code>SRToolkit/dataset/sr_dataset.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    r\"\"\"\n    Creates a dictionary representation of this dataset. This is mainly used for saving the dataset to disk.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n        &gt;&gt;&gt; dataset = SR_dataset(X, SymbolLibrary.default_symbols(2), ground_truth=[\"X_0\", \"+\", \"X_1\"],\n        ...     y=np.array([3, 7, 11]), max_evaluations=10000, original_equation=\"z = x + y\", success_threshold=1e-6)\n        &gt;&gt;&gt; dataset.to_dict(\"data/example_ds\", \"test_dataset\")\n        {'symbol_library': {'type': 'SymbolLibrary', 'symbols': {'+': {'symbol': '+', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} + {}', 'latex_str': '{} + {}'}, '-': {'symbol': '-', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} - {}', 'latex_str': '{} - {}'}, '*': {'symbol': '*', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} * {}', 'latex_str': '{} \\\\cdot {}'}, '/': {'symbol': '/', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} / {}', 'latex_str': '\\\\frac{{{}}}{{{}}}'}, '^': {'symbol': '^', 'type': 'op', 'precedence': 2, 'np_fn': '{} = np.power({},{})', 'latex_str': '{}^{{{}}}'}, 'u-': {'symbol': 'u-', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = -{}', 'latex_str': '- {}'}, 'sqrt': {'symbol': 'sqrt', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sqrt({})', 'latex_str': '\\\\sqrt {{{}}}'}, 'sin': {'symbol': 'sin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sin({})', 'latex_str': '\\\\sin {}'}, 'cos': {'symbol': 'cos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cos({})', 'latex_str': '\\\\cos {}'}, 'exp': {'symbol': 'exp', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.exp({})', 'latex_str': 'e^{{{}}}'}, 'tan': {'symbol': 'tan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tan({})', 'latex_str': '\\\\tan {}'}, 'arcsin': {'symbol': 'arcsin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arcsin({})', 'latex_str': '\\\\arcsin {}'}, 'arccos': {'symbol': 'arccos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arccos({})', 'latex_str': '\\\\arccos {}'}, 'arctan': {'symbol': 'arctan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arctan({})', 'latex_str': '\\\\arctan {}'}, 'sinh': {'symbol': 'sinh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sinh({})', 'latex_str': '\\\\sinh {}'}, 'cosh': {'symbol': 'cosh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cosh({})', 'latex_str': '\\\\cosh {}'}, 'tanh': {'symbol': 'tanh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tanh({})', 'latex_str': '\\\\tanh {}'}, 'floor': {'symbol': 'floor', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.floor({})', 'latex_str': '\\\\lfloor {} \\\\rfloor'}, 'ceil': {'symbol': 'ceil', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.ceil({})', 'latex_str': '\\\\lceil {} \\\\rceil'}, 'ln': {'symbol': 'ln', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log({})', 'latex_str': '\\\\ln {}'}, 'log': {'symbol': 'log', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log10({})', 'latex_str': '\\\\log_{{10}} {}'}, '^-1': {'symbol': '^-1', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = 1/{}', 'latex_str': '{}^{{-1}}'}, '^2': {'symbol': '^2', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**2', 'latex_str': '{}^2'}, '^3': {'symbol': '^3', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**3', 'latex_str': '{}^3'}, '^4': {'symbol': '^4', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**4', 'latex_str': '{}^4'}, '^5': {'symbol': '^5', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**5', 'latex_str': '{}^5'}, 'pi': {'symbol': 'pi', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.pi)', 'latex_str': '\\\\pi'}, 'e': {'symbol': 'e', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.e)', 'latex_str': 'e'}, 'C': {'symbol': 'C', 'type': 'const', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], C[{}])', 'latex_str': 'C_{{{}}}'}, 'X_0': {'symbol': 'X_0', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 0]', 'latex_str': 'X_{0}'}, 'X_1': {'symbol': 'X_1', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 1]', 'latex_str': 'X_{1}'}}, 'preamble': ['import numpy as np'], 'num_variables': 2}, 'ranking_function': 'rmse', 'max_evaluations': 10000, 'success_threshold': 1e-06, 'original_equation': 'z = x + y', 'seed': None, 'dataset_metadata': None, 'kwargs': {}, 'result_augmenters': None, 'ground_truth': ['X_0', '+', 'X_1'], 'dataset_path': 'data/example_ds/test_dataset.npz'}\n\n    Args:\n        base_path: The path to the directory where the data in the dataset should be saved.\n        name: The name of the dataset. This will be used to name the files containing the dataset data.\n\n    Returns:\n        A dictionary representation of this dataset.\n    \"\"\"\n    output = {\n        \"symbol_library\": self.symbol_library.to_dict(),\n        \"ranking_function\": self.ranking_function,\n        \"max_evaluations\": self.max_evaluations,\n        \"success_threshold\": self.success_threshold,\n        \"original_equation\": self.original_equation,\n        \"seed\": self.seed,\n        \"dataset_metadata\": self.dataset_metadata,\n    }\n\n    if self.kwargs is not None and \"bed_X\" in self.kwargs and isinstance(self.kwargs[\"bed_X\"], np.ndarray):\n        self.kwargs[\"bed_X\"] = self.kwargs[\"bed_X\"].tolist()\n\n    output[\"kwargs\"] = self.kwargs\n\n    if self.result_augmenters is None:\n        output[\"result_augmenters\"] = None\n    else:\n        output[\"result_augmenters\"] = [ag.to_dict(base_path, name) for ag in self.result_augmenters]\n\n    if not os.path.isdir(base_path):\n        os.makedirs(base_path)\n\n    if self.ground_truth is None:\n        output[\"ground_truth\"] = None\n    else:\n        if isinstance(self.ground_truth, list):\n            output[\"ground_truth\"] = self.ground_truth\n        elif isinstance(self.ground_truth, Node):\n            output[\"ground_truth\"] = self.ground_truth.to_list()\n        elif isinstance(self.ground_truth, np.ndarray) and not os.path.exists(f\"{base_path}/{name}_gt.npy\"):\n            np.save(f\"{base_path}/{name}_gt.npy\", self.ground_truth)\n            output[\"ground_truth\"] = f\"{base_path}/{name}_gt.npy\"\n\n    if not os.path.exists(f\"{base_path}/{name}.npz\"):\n        if self.y is None:\n            np.savez(f\"{base_path}/{name}.npz\", X=self.X)\n        else:\n            np.savez(f\"{base_path}/{name}.npz\", X=self.X, y=self.y)\n    output[\"dataset_path\"] = f\"{base_path}/{name}.npz\"\n\n    return output\n</code></pre>"},{"location":"references/dataset/srdataset/#SRToolkit.dataset.sr_dataset.SR_dataset.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(d: dict, augmentation_map: Dict[str, Type[ResultAugmenter]] = None) -&gt; SR_dataset\n</code></pre> <p>Creates an instance of the SR_dataset class from its dictionary representation. This is mainly used for loading the dataset from disk.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from SRToolkit.evaluation.result_augmentation import RESULT_AUGMENTERS\n&gt;&gt;&gt; dataset_dict = {'symbol_library': {'type': 'SymbolLibrary', 'symbols': {'+': {'symbol': '+', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} + {}', 'latex_str': '{} + {}'}, '-': {'symbol': '-', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} - {}', 'latex_str': '{} - {}'}, '*': {'symbol': '*', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} * {}', 'latex_str': '{} \\cdot {}'}, '/': {'symbol': '/', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} / {}', 'latex_str': '\\frac{{{}}}{{{}}}'}, '^': {'symbol': '^', 'type': 'op', 'precedence': 2, 'np_fn': '{} = np.power({},{})', 'latex_str': '{}^{{{}}}'}, 'u-': {'symbol': 'u-', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = -{}', 'latex_str': '- {}'}, 'sqrt': {'symbol': 'sqrt', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sqrt({})', 'latex_str': '\\sqrt {{{}}}'}, 'sin': {'symbol': 'sin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sin({})', 'latex_str': '\\sin {}'}, 'cos': {'symbol': 'cos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cos({})', 'latex_str': '\\cos {}'}, 'exp': {'symbol': 'exp', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.exp({})', 'latex_str': 'e^{{{}}}'}, 'tan': {'symbol': 'tan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tan({})', 'latex_str': '\\tan {}'}, 'arcsin': {'symbol': 'arcsin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arcsin({})', 'latex_str': '\\arcsin {}'}, 'arccos': {'symbol': 'arccos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arccos({})', 'latex_str': '\\arccos {}'}, 'arctan': {'symbol': 'arctan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arctan({})', 'latex_str': '\\arctan {}'}, 'sinh': {'symbol': 'sinh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sinh({})', 'latex_str': '\\sinh {}'}, 'cosh': {'symbol': 'cosh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cosh({})', 'latex_str': '\\cosh {}'}, 'tanh': {'symbol': 'tanh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tanh({})', 'latex_str': '\\tanh {}'}, 'floor': {'symbol': 'floor', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.floor({})', 'latex_str': '\\lfloor {} \\rfloor'}, 'ceil': {'symbol': 'ceil', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.ceil({})', 'latex_str': '\\lceil {} \\rceil'}, 'ln': {'symbol': 'ln', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log({})', 'latex_str': '\\ln {}'}, 'log': {'symbol': 'log', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log10({})', 'latex_str': '\\log_{{10}} {}'}, '^-1': {'symbol': '^-1', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = 1/{}', 'latex_str': '{}^{{-1}}'}, '^2': {'symbol': '^2', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**2', 'latex_str': '{}^2'}, '^3': {'symbol': '^3', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**3', 'latex_str': '{}^3'}, '^4': {'symbol': '^4', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**4', 'latex_str': '{}^4'}, '^5': {'symbol': '^5', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**5', 'latex_str': '{}^5'}, 'pi': {'symbol': 'pi', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.pi)', 'latex_str': '\\pi'}, 'e': {'symbol': 'e', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.e)', 'latex_str': 'e'}, 'C': {'symbol': 'C', 'type': 'const', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], C[{}])', 'latex_str': 'C_{{{}}}'}, 'X_0': {'symbol': 'X_0', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 0]', 'latex_str': 'X_{0}'}, 'X_1': {'symbol': 'X_1', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 1]', 'latex_str': 'X_{1}'}}, 'preamble': ['import numpy as np'], 'num_variables': 2}, 'ranking_function': 'rmse', 'max_evaluations': 10000, 'success_threshold': 1e-06, 'original_equation': 'z = x + y', 'seed': None, 'dataset_metadata': None, 'kwargs': {}, 'result_augmenters': None, 'ground_truth': ['X_0', '+', 'X_1'], 'dataset_path': 'data/example_ds/test_dataset.npz'}\n&gt;&gt;&gt; dataset = SR_dataset.from_dict(dataset_dict)\n&gt;&gt;&gt; dataset.X.shape\n(3, 2)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>The dictionary representation of the dataset.</p> required <code>augmentation_map</code> <code>Dict[str, Type[ResultAugmenter]]</code> <p>A dictionary mapping the names of the result augmentation classes to their respective classes. When default value (None) is used, the SRToolit.evaluation.result_augmentation.RESULT_AUGMENTERS dictionary is used.</p> <code>None</code> Source code in <code>SRToolkit/dataset/sr_dataset.py</code> <pre><code>@staticmethod\ndef from_dict(d: dict, augmentation_map: Dict[str, Type[ResultAugmenter]]=None) -&gt; \"SR_dataset\":\n    \"\"\"\n    Creates an instance of the SR_dataset class from its dictionary representation. This is mainly used for\n    loading the dataset from disk.\n\n    Examples:\n        &gt;&gt;&gt; from SRToolkit.evaluation.result_augmentation import RESULT_AUGMENTERS\n        &gt;&gt;&gt; dataset_dict = {'symbol_library': {'type': 'SymbolLibrary', 'symbols': {'+': {'symbol': '+', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} + {}', 'latex_str': '{} + {}'}, '-': {'symbol': '-', 'type': 'op', 'precedence': 0, 'np_fn': '{} = {} - {}', 'latex_str': '{} - {}'}, '*': {'symbol': '*', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} * {}', 'latex_str': '{} \\\\cdot {}'}, '/': {'symbol': '/', 'type': 'op', 'precedence': 1, 'np_fn': '{} = {} / {}', 'latex_str': '\\\\frac{{{}}}{{{}}}'}, '^': {'symbol': '^', 'type': 'op', 'precedence': 2, 'np_fn': '{} = np.power({},{})', 'latex_str': '{}^{{{}}}'}, 'u-': {'symbol': 'u-', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = -{}', 'latex_str': '- {}'}, 'sqrt': {'symbol': 'sqrt', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sqrt({})', 'latex_str': '\\\\sqrt {{{}}}'}, 'sin': {'symbol': 'sin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sin({})', 'latex_str': '\\\\sin {}'}, 'cos': {'symbol': 'cos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cos({})', 'latex_str': '\\\\cos {}'}, 'exp': {'symbol': 'exp', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.exp({})', 'latex_str': 'e^{{{}}}'}, 'tan': {'symbol': 'tan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tan({})', 'latex_str': '\\\\tan {}'}, 'arcsin': {'symbol': 'arcsin', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arcsin({})', 'latex_str': '\\\\arcsin {}'}, 'arccos': {'symbol': 'arccos', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arccos({})', 'latex_str': '\\\\arccos {}'}, 'arctan': {'symbol': 'arctan', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.arctan({})', 'latex_str': '\\\\arctan {}'}, 'sinh': {'symbol': 'sinh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.sinh({})', 'latex_str': '\\\\sinh {}'}, 'cosh': {'symbol': 'cosh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.cosh({})', 'latex_str': '\\\\cosh {}'}, 'tanh': {'symbol': 'tanh', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.tanh({})', 'latex_str': '\\\\tanh {}'}, 'floor': {'symbol': 'floor', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.floor({})', 'latex_str': '\\\\lfloor {} \\\\rfloor'}, 'ceil': {'symbol': 'ceil', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.ceil({})', 'latex_str': '\\\\lceil {} \\\\rceil'}, 'ln': {'symbol': 'ln', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log({})', 'latex_str': '\\\\ln {}'}, 'log': {'symbol': 'log', 'type': 'fn', 'precedence': 5, 'np_fn': '{} = np.log10({})', 'latex_str': '\\\\log_{{10}} {}'}, '^-1': {'symbol': '^-1', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = 1/{}', 'latex_str': '{}^{{-1}}'}, '^2': {'symbol': '^2', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**2', 'latex_str': '{}^2'}, '^3': {'symbol': '^3', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**3', 'latex_str': '{}^3'}, '^4': {'symbol': '^4', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**4', 'latex_str': '{}^4'}, '^5': {'symbol': '^5', 'type': 'fn', 'precedence': -1, 'np_fn': '{} = {}**5', 'latex_str': '{}^5'}, 'pi': {'symbol': 'pi', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.pi)', 'latex_str': '\\\\pi'}, 'e': {'symbol': 'e', 'type': 'lit', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], np.e)', 'latex_str': 'e'}, 'C': {'symbol': 'C', 'type': 'const', 'precedence': 5, 'np_fn': 'np.full(X.shape[0], C[{}])', 'latex_str': 'C_{{{}}}'}, 'X_0': {'symbol': 'X_0', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 0]', 'latex_str': 'X_{0}'}, 'X_1': {'symbol': 'X_1', 'type': 'var', 'precedence': 5, 'np_fn': 'X[:, 1]', 'latex_str': 'X_{1}'}}, 'preamble': ['import numpy as np'], 'num_variables': 2}, 'ranking_function': 'rmse', 'max_evaluations': 10000, 'success_threshold': 1e-06, 'original_equation': 'z = x + y', 'seed': None, 'dataset_metadata': None, 'kwargs': {}, 'result_augmenters': None, 'ground_truth': ['X_0', '+', 'X_1'], 'dataset_path': 'data/example_ds/test_dataset.npz'}\n        &gt;&gt;&gt; dataset = SR_dataset.from_dict(dataset_dict)\n        &gt;&gt;&gt; dataset.X.shape\n        (3, 2)\n\n    Args:\n        d: The dictionary representation of the dataset.\n        augmentation_map: A dictionary mapping the names of the result augmentation classes to their respective\n            classes. When default value (None) is used, the SRToolit.evaluation.result_augmentation.RESULT_AUGMENTERS dictionary is used.\n    \"\"\"\n    if augmentation_map is None:\n        from SRToolkit.evaluation.result_augmentation import RESULT_AUGMENTERS\n        augmentation_map = RESULT_AUGMENTERS\n    try:\n        data = np.load(d[\"dataset_path\"])\n        X = data[\"X\"]\n        if \"y\" in data:\n            y = data[\"y\"]\n        else:\n            y = None\n    except:\n        raise Exception(f\"[SR_dataset.from_dict] Could not load dataset from {d['dataset_path']}\")\n\n    if \"ground_truth\" in d and isinstance(d[\"ground_truth\"], list) or d[\"ground_truth\"] is None:\n        ground_truth = d[\"ground_truth\"]\n    else:\n        try:\n            ground_truth = np.load(d[\"ground_truth\"])\n        except:\n            raise Exception(f\"[SR_dataset.from_dict] Could not load ground truth from {d['ground_truth']}\")\n\n    if not \"result_augmenters\" in d:\n        raise Exception(\"[SR_dataset.from_dict] Could not find result_augmenters keyword in the provided dictionary.\")\n\n    if d[\"result_augmenters\"] is None:\n        result_augmenters = None\n    else:\n        result_augmenters = [augmentation_map[ag_data[\"type\"]].from_dict(ag_data, augmentation_map)\n                             for ag_data in d[\"result_augmenters\"]]\n\n    if \"bed_X\" in d[\"kwargs\"] and d[\"kwargs\"][\"bed_X\"] is not None:\n        d[\"kwargs\"][\"bed_X\"] = np.array(d[\"kwargs\"][\"bed_X\"])\n\n    try:\n        return SR_dataset(X,\n                          SymbolLibrary.from_dict(d[\"symbol_library\"]),\n                          ranking_function=d[\"ranking_function\"],\n                          y=y,\n                          max_evaluations=d[\"max_evaluations\"],\n                          ground_truth=ground_truth,\n                          original_equation=d[\"original_equation\"],\n                          success_threshold=d[\"success_threshold\"],\n                          result_augmenters=result_augmenters,\n                          seed=d[\"seed\"],\n                          dataset_metadata=d[\"dataset_metadata\"],\n                          **d[\"kwargs\"])\n    except Exception as e:\n        raise Exception(f\"[SR_dataset.from_dict] Error creating dataset: {e}\")\n</code></pre>"},{"location":"references/evaluation/","title":"Evaluation Submodule","text":""},{"location":"references/evaluation/#SRToolkit.evaluation","title":"SRToolkit.evaluation","text":"<p>This module contains classes and functions for evaluating symbolic regression approaches. Mainly it contains classes that can be used for parameter estimation and evaluation of mathematical expressions on some dataset.</p> <p>Modules:</p> Name Description <code>parameter_estimator</code> <p>The module containing classes and functions for parameter estimation.</p> <code>sr_evaluator</code> <p>The module containing classes and functions for expressions on some dataset.</p> <code>result_augmentation</code> <p>The module containing classes and functions for result augmentation.</p>"},{"location":"references/evaluation/#SRToolkit.evaluation.RESULT_AUGMENTERS","title":"RESULT_AUGMENTERS  <code>module-attribute</code>","text":"<pre><code>RESULT_AUGMENTERS: Dict[str, Type[ResultAugmenter]] = {'ExpressionToLatex': ExpressionToLatex, 'RMSE': RMSE, 'BED': BED, 'R2': R2, 'ExpressionSimplifier': ExpressionSimplifier}\n</code></pre> <p>A mapping of augmentation names to their corresponding ResultAugmenter classes.</p> <p>This constant defines the library of available result augmentation classes used across the benchmarking framework.</p> <p>The dictionary keys are the unique string identifiers for the augmentor found under the 'type' value in the to_dict  function. The values are the uninstantiated class objects, all of which inherit from ResultAugmenter.</p>"},{"location":"references/evaluation/#SRToolkit.evaluation.ParameterEstimator","title":"ParameterEstimator","text":"<pre><code>ParameterEstimator(X: ndarray, y: ndarray, symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(), seed: Optional[int] = None, **kwargs)\n</code></pre> <p>Initializes an instance of the ParameterEstimator class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; pe = ParameterEstimator(X, y)\n&gt;&gt;&gt; rmse, constants = pe.estimate_parameters([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; print(rmse &lt; 1e-6)\nTrue\n&gt;&gt;&gt; print(1.99 &lt; constants[0] &lt; 2.01)\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data to be used in parameter estimation for variables. We assume that X is a 2D array with shape (n_samples, n_features).</p> required <code>y</code> <code>ndarray</code> <p>The target values to be used in parameter estimation.</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use. Defaults to SymbolLibrary.default_symbols().</p> <code>default_symbols()</code> <p>Other Parameters:</p> Name Type Description <code>method</code> <code>str</code> <p>The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested. Default is \"L-BFGS-B\".</p> <code>tol</code> <code>float</code> <p>The tolerance for termination. Default is 1e-6.</p> <code>gtol</code> <code>float</code> <p>The tolerance for the gradient norm. Default is 1e-3.</p> <code>max_iter</code> <code>int</code> <p>The maximum number of iterations. Default is 100.</p> <code>constant_bounds</code> <code>Tuple[float, float]</code> <p>A tuple of two elements, specifying the lower and upper bounds for the constant values. Default is (-5, 5).</p> <code>initialization</code> <code>str</code> <p>The method to use for initializing the constant values. Currently, only \"random\" and \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\" creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".</p> <code>max_constants</code> <code>int</code> <p>The maximum number of constants allowed in the expression. Default is 8.</p> <code>max_expr_length</code> <code>int</code> <p>The maximum length of the expression. Default is -1 (no limit).</p> <p>Functions:</p> Name Description <code>estimate_parameters</code> <p>List[str]): Estimates the parameters of an expression by minimizing the error between the predicted and actual values.</p> Source code in <code>SRToolkit/evaluation/parameter_estimator.py</code> <pre><code>def __init__(\n    self,\n    X: np.ndarray,\n    y: np.ndarray,\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n    seed: Optional[int] = None,\n    **kwargs,\n):\n    \"\"\"\n    Initializes an instance of the ParameterEstimator class.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; pe = ParameterEstimator(X, y)\n        &gt;&gt;&gt; rmse, constants = pe.estimate_parameters([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; print(rmse &lt; 1e-6)\n        True\n        &gt;&gt;&gt; print(1.99 &lt; constants[0] &lt; 2.01)\n        True\n\n    Args:\n        X: The input data to be used in parameter estimation for variables. We assume that X is a 2D array\n            with shape (n_samples, n_features).\n        y: The target values to be used in parameter estimation.\n        symbol_library: The symbol library to use. Defaults to SymbolLibrary.default_symbols().\n\n    Keyword Arguments:\n        method (str): The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested. Default is \"L-BFGS-B\".\n        tol (float): The tolerance for termination. Default is 1e-6.\n        gtol (float): The tolerance for the gradient norm. Default is 1e-3.\n        max_iter (int): The maximum number of iterations. Default is 100.\n        constant_bounds (Tuple[float, float]): A tuple of two elements, specifying the lower and upper bounds for the constant values. Default is (-5, 5).\n        initialization (str): The method to use for initializing the constant values. Currently, only \"random\" and \"mean\" are supported. \"random\" creates a vector with random values\n            sampled within the bounds. \"mean\" creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".\n        max_constants (int): The maximum number of constants allowed in the expression. Default is 8.\n        max_expr_length (int): The maximum length of the expression. Default is -1 (no limit).\n\n    Methods:\n        estimate_parameters(expr: List[str]): Estimates the parameters of an expression by minimizing the error between the predicted and actual values.\n    \"\"\"\n    self.symbol_library = symbol_library\n    self.X = X\n    self.y = y\n    self.seed = seed\n    # self.stats = {\"success\": 0, \"failure\": 0, \"steps\": dict(), \"num_constants\": dict(), \"failed_constants\": dict()}\n\n    self.estimation_settings = {\n        \"method\": \"L-BFGS-B\",\n        \"tol\": 1e-6,\n        \"gtol\": 1e-3,\n        \"max_iter\": 100,\n        \"constant_bounds\": (-5, 5),\n        \"initialization\": \"random\",  # random, mean\n        \"max_constants\": 8,\n        \"max_expr_length\": -1,\n    }\n\n    if kwargs:\n        for k in self.estimation_settings.keys():\n            if k in kwargs:\n                self.estimation_settings[k] = kwargs[k]\n\n    if self.seed is not None:\n        np.random.seed(self.seed)\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.ParameterEstimator.estimate_parameters","title":"estimate_parameters","text":"<pre><code>estimate_parameters(expr: Union[List[str], Node]) -&gt; Tuple[float, np.ndarray]\n</code></pre> <p>Estimates the parameters of an expression by minimizing the error between the predicted and actual values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; pe = ParameterEstimator(X, y)\n&gt;&gt;&gt; rmse, constants = pe.estimate_parameters([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; print(rmse &lt; 1e-6)\nTrue\n&gt;&gt;&gt; print(1.99 &lt; constants[0] &lt; 2.01)\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[List[str], Node]</code> <p>An expression. This should either be an instance of SRToolkit.utils.expression_tree.Node or a list of   tokens in the infix notation representing the expression to be evaluated.</p> required <p>Returns:</p> Type Description <code>float</code> <p>the root mean square error (RMSE) of the optimized expression.</p> <code>ndarray</code> <p>An array containing the optimized constant values.</p> Notes <p>if the length of the expression exceeds the maximum allowed, NaN and an empty array are returned. If the number of constants in the expression exceeds the maximum allowed, NaN and an empty array are returned. If there are no constants in the expression, the RMSE is calculated directly without optimization.</p> Source code in <code>SRToolkit/evaluation/parameter_estimator.py</code> <pre><code>def estimate_parameters(\n    self, expr: Union[List[str], Node]\n) -&gt; Tuple[float, np.ndarray]:\n    \"\"\"\n    Estimates the parameters of an expression by minimizing the error between the predicted and actual values.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; pe = ParameterEstimator(X, y)\n        &gt;&gt;&gt; rmse, constants = pe.estimate_parameters([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; print(rmse &lt; 1e-6)\n        True\n        &gt;&gt;&gt; print(1.99 &lt; constants[0] &lt; 2.01)\n        True\n\n    Args:\n        expr: An expression. This should either be an instance of SRToolkit.utils.expression_tree.Node or a list of\n              tokens in the infix notation representing the expression to be evaluated.\n\n    Returns:\n        the root mean square error (RMSE) of the optimized expression.\n        An array containing the optimized constant values.\n\n    Notes:\n        if the length of the expression exceeds the maximum allowed, NaN and an empty array are returned.\n        If the number of constants in the expression exceeds the maximum allowed, NaN and an empty array are returned.\n        If there are no constants in the expression, the RMSE is calculated directly without optimization.\n    \"\"\"\n    if isinstance(expr, Node):\n        expr_str = expr.to_list(notation=\"prefix\")\n        num_constants = sum(\n            [1 for t in expr_str if self.symbol_library.get_type(t) == \"const\"]\n        )\n    else:\n        num_constants = sum(\n            [1 for t in expr if self.symbol_library.get_type(t) == \"const\"]\n        )\n    if 0 &lt;= self.estimation_settings[\"max_constants\"] &lt; num_constants:\n        return np.nan, np.array([])\n\n    if 0 &lt;= self.estimation_settings[\"max_expr_length\"] &lt; len(expr):\n        return np.nan, np.array([])\n\n    executable_error_fn = expr_to_error_function(expr, self.symbol_library)\n\n    if num_constants == 0:\n        rmse = executable_error_fn(self.X, np.array([]), self.y)\n        return rmse, np.array([])\n    else:\n        return self._optimize_parameters(executable_error_fn, num_constants)\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.SR_evaluator","title":"SR_evaluator","text":"<pre><code>SR_evaluator(X: ndarray, y: Optional[ndarray] = None, symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(), max_evaluations: int = -1, success_threshold: Optional[float] = None, ranking_function: str = 'rmse', ground_truth: Optional[Union[List[str], Node, ndarray]] = None, result_augmenters: Optional[List[ResultAugmenter]] = None, seed: Optional[int] = None, metadata: Optional[dict] = None, **kwargs)\n</code></pre> <p>Initializes an instance of the SR_evaluator class. This class is used for evaluating symbolic regression approaches.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; print(rmse &lt; 1e-6)\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data to be used in parameter estimation for variables. We assume that X is a 2D array with shape (n_samples, n_features).</p> required <code>y</code> <code>Optional[ndarray]</code> <p>The target values to be used in parameter estimation.</p> <code>None</code> <code>max_evaluations</code> <code>int</code> <p>The maximum number of expressions to evaluate. Default is -1, which means no limit.</p> <code>-1</code> <code>success_threshold</code> <code>Optional[float]</code> <p>The threshold used for determining whether an expression is considered successful. If None, the threshold is set to 1e-7 for RMSE and calculated automatically for BED. For BED we calculate this value by evaluating the distance of ground truth to itself 100 times and setting the threshold to np.max(distances)*1.1. For this calculation to be helpful, ground_truth must be provided as a list of tokens or SRToolkit.utils.Node object.</p> <code>None</code> <code>metadata</code> <code>Optional[dict]</code> <p>An optional dictionary containing metadata about this evaluation. This could include information such as the dataset used, the model used, seed, etc.</p> <code>None</code> <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use.</p> <code>default_symbols()</code> <code>ranking_function</code> <code>str</code> <p>The function used for ranking the expressions and fitting parameters if needed. Currently, \"rmse\" and \"bed\" are supported. Default is \"rmse\".</p> <code>'rmse'</code> <code>ground_truth</code> <code>Optional[Union[List[str], Node, ndarray]]</code> <p>The ground truth for the BED evaluation. This should be a list of tokens, a Node object, or a numpy array representing behavior (see SRToolkit.utils.create_behavior_matrix for more details).</p> <code>None</code> <code>result_augmenters</code> <code>Optional[List[ResultAugmenter]]</code> <p>Optional list of objects that augment the results returned by the \"get_results\" function. For example, SRToolkit.evaluation.result_augmentation.ExpressionSimplifier simplifies the evaluated expressions. Possible augmenters can be found in SRToolkit.evaluation.result_augmentation.py or customly defined by inheriting from SRToolkit.evaluation.result_augmentation.ResultAugmenter class.</p> <code>None</code> <code>seed</code> <code>Optional[int]</code> <p>The seed to use for random number generation.</p> <code>None</code> <p>Other Parameters:</p> Name Type Description <code>method</code> <code>str</code> <p>The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested. Default is \"L-BFGS-B\".</p> <code>tol</code> <code>float</code> <p>The tolerance for termination. Default is 1e-6.</p> <code>gtol</code> <code>float</code> <p>The tolerance for the gradient norm. Default is 1e-3.</p> <code>max_iter</code> <code>int</code> <p>The maximum number of iterations. Default is 100.</p> <code>constant_bounds</code> <code>Tuple[float, float]</code> <p>A tuple of two elements, specifying the lower and upper bounds for the constant values. Default is (-5, 5).</p> <code>initialization</code> <code>str</code> <p>The method to use for initializing the constant values. Currently, only \"random\" and \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\" creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".</p> <code>max_constants</code> <code>int</code> <p>The maximum number of constants allowed in the expression. Default is 8.</p> <code>max_expr_length</code> <code>int</code> <p>The maximum length of the expression. Default is -1 (no limit).</p> <code>num_points_sampled</code> <code>int</code> <p>The number of points to sample when estimating the behavior of an expression. Default is 64. If num_points_sampled==-1, then the number of points sampled is equal to the number of points in the dataset.</p> <code>bed_X</code> <code>Optional[ndarray]</code> <p>Points used for BED evaluation. If None and domain_bounds are given, points are sampled from the domain. If None and domain_bounds are not givem, points are randomly selected from X. Default is None.</p> <code>num_consts_sampled</code> <code>int</code> <p>Number of constants sampled for BED evaluation. Default is 32.</p> <code>domain_bounds</code> <code>Optional[List[Tuple[float, float]]]</code> <p>Bounds for the domain to be used if bed_X is None to sample random points. Default is None.</p> <p>Attributes:</p> Name Type Description <code>models</code> <p>A dictionary containing the results of previously evaluated expressions.</p> <code>invalid</code> <p>A list containing the expressions that could not be evaluated.</p> <code>ground_truth</code> <p>The ground truth we are trying to find.</p> <code>gt_behavior</code> <p>The behavior matrix for the ground truth that is used when BED is chosen as the ranking function.</p> <code>max_evaluations</code> <p>The maximum number of expressions to evaluate.</p> <code>bed_evaluation_parameters</code> <p>A dictionary containing parameters used for BED evaluation.</p> <code>metadata</code> <p>An optional dictionary containing metadata about this evaluation. This could include information such as the dataset used, the model used, seed, etc.</p> <code>symbol_library</code> <p>The symbol library to use.</p> <code>total_evaluations</code> <p>The number of times the \"evaluate_expr\" function was called.</p> <code>seed</code> <p>The seed to use for random number generation.</p> <code>parameter_estimator</code> <p>An instance of the ParameterEstimator class used for parameter estimation.</p> <code>ranking_function</code> <p>The function used for ranking the expressions and fitting parameters if needed.</p> <code>success_threshold</code> <p>The threshold used for determining whether an expression is considered successful.</p> <code>result_augmenters</code> <p>A list of SRToolkit.evaluation.result_augmentation.ResultAugmenter objects that augment the results returned by the get_results.</p> <p>Functions:</p> Name Description <code>evaluate_expr</code> <p>Evaluates an expression in infix notation and stores the result in memory to prevent re-evaluation.</p> <code>get_results</code> <p>Returns the results of the evaluation.</p> Notes <p>Determining if two expressions are equivalent is undecidable. Furthermore, random sampling, parameter fitting, and numerical errors all make it hard to determine whether we found the correct expression. Because of this, the success threshold is only a proxy for determining the success of an expression. We recommend checking the best performing expression manually for a better indication of success.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def __init__(\n    self,\n    X: np.ndarray,\n    y: Optional[np.ndarray] = None,\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n    max_evaluations: int = -1,\n    success_threshold: Optional[float] = None,\n    ranking_function: str = \"rmse\",\n    ground_truth: Optional[Union[List[str], Node, np.ndarray]] = None,\n    result_augmenters: Optional[List[ResultAugmenter]] = None,\n    seed: Optional[int] = None,\n    metadata: Optional[dict] = None,\n    **kwargs,\n):\n    \"\"\"\n    Initializes an instance of the SR_evaluator class. This class is used for evaluating symbolic regression approaches.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; print(rmse &lt; 1e-6)\n        True\n\n    Args:\n        X: The input data to be used in parameter estimation for variables. We assume that X is a 2D array with\n            shape (n_samples, n_features).\n        y: The target values to be used in parameter estimation.\n        max_evaluations: The maximum number of expressions to evaluate. Default is -1, which means no limit.\n        success_threshold: The threshold used for determining whether an expression is considered successful. If\n            None, the threshold is set to 1e-7 for RMSE and calculated automatically for BED. For BED we calculate\n            this value by evaluating the distance of ground truth to itself 100 times and setting the threshold to\n            np.max(distances)*1.1. For this calculation to be helpful, ground_truth must be provided as a list of\n            tokens or SRToolkit.utils.Node object.\n        metadata: An optional dictionary containing metadata about this evaluation. This could include information\n            such as the dataset used, the model used, seed, etc.\n        symbol_library: The symbol library to use.\n        ranking_function: The function used for ranking the expressions and fitting parameters if needed.\n            Currently, \"rmse\" and \"bed\" are supported. Default is \"rmse\".\n        ground_truth: The ground truth for the BED evaluation. This should be a list of tokens, a Node object, or a\n            numpy array representing behavior (see SRToolkit.utils.create_behavior_matrix for more details).\n        result_augmenters: Optional list of objects that augment the results returned by the \"get_results\" function.\n            For example, SRToolkit.evaluation.result_augmentation.ExpressionSimplifier simplifies the evaluated\n            expressions. Possible augmenters can be found in SRToolkit.evaluation.result_augmentation.py or customly\n            defined by inheriting from SRToolkit.evaluation.result_augmentation.ResultAugmenter class.\n        seed: The seed to use for random number generation.\n\n    Keyword Arguments:\n        method (str): The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested.\n            Default is \"L-BFGS-B\".\n        tol (float): The tolerance for termination. Default is 1e-6.\n        gtol (float): The tolerance for the gradient norm. Default is 1e-3.\n        max_iter (int): The maximum number of iterations. Default is 100.\n        constant_bounds (Tuple[float, float]): A tuple of two elements, specifying the lower and upper bounds for\n            the constant values. Default is (-5, 5).\n        initialization (str): The method to use for initializing the constant values. Currently, only \"random\" and\n            \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\"\n            creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".\n        max_constants (int): The maximum number of constants allowed in the expression. Default is 8.\n        max_expr_length (int): The maximum length of the expression. Default is -1 (no limit).\n        num_points_sampled (int): The number of points to sample when estimating the behavior of an expression.\n            Default is 64. If num_points_sampled==-1, then the number of points sampled is equal to the number of\n            points in the dataset.\n        bed_X (Optional[np.ndarray]): Points used for BED evaluation. If None and domain_bounds are given, points\n            are sampled from the domain. If None and domain_bounds are not givem, points are randomly selected\n            from X. Default is None.\n        num_consts_sampled (int): Number of constants sampled for BED evaluation. Default is 32.\n        domain_bounds (Optional[List[Tuple[float, float]]]): Bounds for the domain to be used if bed_X is None to\n            sample random points. Default is None.\n\n    Attributes:\n        models: A dictionary containing the results of previously evaluated expressions.\n        invalid: A list containing the expressions that could not be evaluated.\n        ground_truth: The ground truth we are trying to find.\n        gt_behavior: The behavior matrix for the ground truth that is used when BED is chosen as the ranking function.\n        max_evaluations: The maximum number of expressions to evaluate.\n        bed_evaluation_parameters: A dictionary containing parameters used for BED evaluation.\n        metadata: An optional dictionary containing metadata about this evaluation. This could include information\n            such as the dataset used, the model used, seed, etc.\n        symbol_library: The symbol library to use.\n        total_evaluations: The number of times the \"evaluate_expr\" function was called.\n        seed: The seed to use for random number generation.\n        parameter_estimator: An instance of the ParameterEstimator class used for parameter estimation.\n        ranking_function: The function used for ranking the expressions and fitting parameters if needed.\n        success_threshold: The threshold used for determining whether an expression is considered successful.\n        result_augmenters: A list of SRToolkit.evaluation.result_augmentation.ResultAugmenter objects that augment\n            the results returned by the get_results.\n\n    Methods:\n        evaluate_expr(expr): Evaluates an expression in infix notation and stores the result in memory to prevent re-evaluation.\n        get_results(top_k): Returns the results of the evaluation.\n\n    Notes:\n        Determining if two expressions are equivalent is undecidable. Furthermore, random sampling, parameter\n        fitting, and numerical errors all make it hard to determine whether we found the correct expression.\n        Because of this, the success threshold is only a proxy for determining the success of an expression.\n        We recommend checking the best performing expression manually for a better indication of success.\n    \"\"\"\n    self.kwargs = kwargs\n    self.models = dict()\n    self.invalid = list()\n    self.success_threshold = success_threshold\n    self.metadata = metadata\n    self.ground_truth = ground_truth\n    self.gt_behavior = None\n    self.bed_evaluation_parameters = {\n        \"bed_X\": None,\n        \"num_consts_sampled\": 32,\n        \"num_points_sampled\": 64,\n        \"domain_bounds\": None,\n        \"constant_bounds\": (-5, 5),\n    }\n    if kwargs:\n        for k in self.bed_evaluation_parameters.keys():\n            if k in kwargs:\n                self.bed_evaluation_parameters[k] = kwargs[k]\n    if self.bed_evaluation_parameters[\"num_points_sampled\"] == -1:\n        self.bed_evaluation_parameters[\"num_points_sampled\"] = X.shape[0]\n\n    self.symbol_library = symbol_library\n    self.max_evaluations = max_evaluations\n    self.total_evaluations = 0\n    self.seed = seed\n    if seed is not None:\n        np.random.seed(seed)\n\n    if ranking_function not in [\"rmse\", \"bed\"]:\n        print(\n            f\"Warning: ranking_function {ranking_function} not supported. Using rmse instead.\"\n        )\n        ranking_function = \"rmse\"\n    self.ranking_function = ranking_function\n\n    self.result_augmenters = []\n    if result_augmenters is not None:\n        for ra in result_augmenters:\n            if not isinstance(ra, ResultAugmenter):\n                print(\n                    f\"Warning: result_augmenter {ra} is not an instance of ResultAugmenter. Skipping.\"\n                )\n            else:\n                self.result_augmenters.append(ra)\n\n    if ranking_function == \"rmse\":\n        if y is None:\n            raise ValueError(\n                \"Target values must be provided for RMSE ranking function.\"\n            )\n        self.parameter_estimator = ParameterEstimator(\n            X, y, symbol_library=symbol_library, seed=seed, **kwargs\n        )\n\n        if self.success_threshold is None:\n            self.success_threshold = 1e-7\n\n    elif ranking_function == \"bed\":\n        if ground_truth is None:\n            raise ValueError(\n                \"Ground truth must be provided for bed ranking function. The ground truth must be \"\n                \"provided as a list of tokens, a Node object, or a numpy array representing behavior. \"\n                \"The behavior matrix is a matrix representing the distribution of outputs of an \"\n                \"expression with free parameters at different points in the domain. This matrix \"\n                \"should be of size (num_points_sampled, num_consts_sampled). See \"\n                \"SRToolkit.utils.create_behavior_matrix for more details.\"\n            )\n        else:\n            if self.bed_evaluation_parameters[\"bed_X\"] is None:\n                if self.bed_evaluation_parameters[\"domain_bounds\"] is not None:\n                    db = self.bed_evaluation_parameters[\"domain_bounds\"]\n                    interval_length = np.array([ub - lb for (lb, ub) in db])\n                    lower_bound = np.array([lb for (lb, ub) in db])\n                    lho = LatinHypercube(\n                        len(db), optimization=\"random-cd\", seed=seed\n                    )\n                    self.bed_evaluation_parameters[\"bed_X\"] = (\n                        lho.random(\n                            self.bed_evaluation_parameters[\"num_points_sampled\"]\n                        )\n                        * interval_length\n                        + lower_bound\n                    )\n                else:\n                    indices = np.random.choice(\n                        X.shape[0],\n                        size=self.bed_evaluation_parameters[\"num_points_sampled\"],\n                    )\n                    self.bed_evaluation_parameters[\"bed_X\"] = X[indices, :]\n\n        if isinstance(ground_truth, (list, Node)):\n            self.gt_behavior = create_behavior_matrix(\n                ground_truth,\n                self.bed_evaluation_parameters[\"bed_X\"],\n                num_consts_sampled=self.bed_evaluation_parameters[\n                    \"num_consts_sampled\"\n                ],\n                consts_bounds=self.bed_evaluation_parameters[\"constant_bounds\"],\n                symbol_library=self.symbol_library,\n                seed=self.seed,\n            )\n        elif isinstance(ground_truth, np.ndarray):\n            self.gt_behavior = ground_truth\n        else:\n            raise ValueError(\n                \"Ground truth must be provided as a list of tokens, a Node object, or a numpy array representing behavior.\"\n            )\n\n        if self.success_threshold is None:\n            distances = [\n                bed(\n                    self.ground_truth,\n                    self.gt_behavior,\n                    self.bed_evaluation_parameters[\"bed_X\"],\n                    num_consts_sampled=self.bed_evaluation_parameters[\n                        \"num_consts_sampled\"\n                    ],\n                    num_points_sampled=self.bed_evaluation_parameters[\n                        \"num_points_sampled\"\n                    ],\n                    domain_bounds=self.bed_evaluation_parameters[\"domain_bounds\"],\n                    consts_bounds=self.bed_evaluation_parameters[\"constant_bounds\"],\n                    symbol_library=self.symbol_library,\n                )\n                for i in range(100)\n            ]\n            self.success_threshold = np.max(distances) * 1.1\n\n    self.X = X\n    self.y = y\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.SR_evaluator.evaluate_expr","title":"evaluate_expr","text":"<pre><code>evaluate_expr(expr: Union[List[str], Node], simplify_expr: bool = False, verbose: int = 0) -&gt; float\n</code></pre> <p>Evaluates an expression in infix notation and stores the result in memory to prevent re-evaluation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; print(rmse &lt; 1e-6)\nTrue\n&gt;&gt;&gt; X = np.array([[0, 1], [0, 2], [0, 3]])\n&gt;&gt;&gt; y = np.array([2, 3, 4])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"+\", \"C\" \"*\", \"C\", \"+\", \"X_0\", \"*\", \"X_1\", \"/\", \"X_0\"], simplify_expr=True)\n&gt;&gt;&gt; print(rmse &lt; 1e-6)\nTrue\n&gt;&gt;&gt; list(se.models.keys())[0]\n'C+X_1'\n&gt;&gt;&gt; print(0.99 &lt; se.models[\"C+X_1\"][\"parameters\"][0] &lt; 1.01)\nTrue\n&gt;&gt;&gt; # Evaluating invalid expression returns nan and adds it to invalid list\n&gt;&gt;&gt; se.evaluate_expr([\"C\", \"*\", \"X_1\", \"X_0\"])\nnan\n&gt;&gt;&gt; se.invalid\n['C*X_1X_0']\n&gt;&gt;&gt; X = np.random.rand(10, 2) - 0.5\n&gt;&gt;&gt; gt = [\"X_0\", \"+\", \"C\"]\n&gt;&gt;&gt; se = SR_evaluator(X, ground_truth=gt, ranking_function=\"bed\")\n&gt;&gt;&gt; se.evaluate_expr([\"C\", \"+\", \"X_1\"]) &lt; 1\nTrue\n&gt;&gt;&gt; # When evaluating using BED as the ranking function, the error depends on the scale of output of the\n&gt;&gt;&gt; # ground truth. Because of stochasticity of BED, error might be high even when expressions match exactly.\n&gt;&gt;&gt; se.evaluate_expr([\"C\", \"+\", \"X_0\"]) &lt; 0.2\nTrue\n&gt;&gt;&gt; # X can also be sampled from a domain by providing domain_bounds\n&gt;&gt;&gt; se = SR_evaluator(X, ground_truth=gt, ranking_function=\"bed\", domain_bounds=[(-1, 1), (-1, 1)])\n&gt;&gt;&gt; se.evaluate_expr([\"C\", \"+\", \"X_0\"]) &lt; 0.2\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[List[str], Node]</code> <p>An expression. This should be an istance of the SRToolkit.utils.expression_tree.Node class or a list   of tokens in the infix notation.</p> required <code>simplify_expr</code> <code>bool</code> <p>If True, simplifies the expression using SymPy before evaluating it. This typically slows down            evaluation. We recommend simplifying only the best expressions when getting results using            the get_results method.</p> <code>False</code> <code>verbose</code> <code>int</code> <p>When 0, no additional output is printed, when 1, prints the expression being evaluated, RMSE, and      estimated parameters, and when 2, also prints numpy errors produced during evaluation.</p> <code>0</code> <p>Returns:</p> Type Description <code>float</code> <p>The root-mean-square error of the expression.</p> <p>Warns:</p> Type Description <code>Maximum number of evaluations reached</code> <p>If the maximum number of evaluations has been reached, a warning is printed and np.nan is returned.</p> Notes <p>If the expression has already been evaluated, its stored value is returned instead of re-evaluating the expression. When the maximum number of evaluations has been reached, a warning is printed and np.nan is returned.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def evaluate_expr(\n    self,\n    expr: Union[List[str], Node],\n    simplify_expr: bool = False,\n    verbose: int = 0,\n) -&gt; float:\n    \"\"\"\n    Evaluates an expression in infix notation and stores the result in\n    memory to prevent re-evaluation.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; print(rmse &lt; 1e-6)\n        True\n        &gt;&gt;&gt; X = np.array([[0, 1], [0, 2], [0, 3]])\n        &gt;&gt;&gt; y = np.array([2, 3, 4])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"+\", \"C\" \"*\", \"C\", \"+\", \"X_0\", \"*\", \"X_1\", \"/\", \"X_0\"], simplify_expr=True)\n        &gt;&gt;&gt; print(rmse &lt; 1e-6)\n        True\n        &gt;&gt;&gt; list(se.models.keys())[0]\n        'C+X_1'\n        &gt;&gt;&gt; print(0.99 &lt; se.models[\"C+X_1\"][\"parameters\"][0] &lt; 1.01)\n        True\n        &gt;&gt;&gt; # Evaluating invalid expression returns nan and adds it to invalid list\n        &gt;&gt;&gt; se.evaluate_expr([\"C\", \"*\", \"X_1\", \"X_0\"])\n        nan\n        &gt;&gt;&gt; se.invalid\n        ['C*X_1X_0']\n        &gt;&gt;&gt; X = np.random.rand(10, 2) - 0.5\n        &gt;&gt;&gt; gt = [\"X_0\", \"+\", \"C\"]\n        &gt;&gt;&gt; se = SR_evaluator(X, ground_truth=gt, ranking_function=\"bed\")\n        &gt;&gt;&gt; se.evaluate_expr([\"C\", \"+\", \"X_1\"]) &lt; 1\n        True\n        &gt;&gt;&gt; # When evaluating using BED as the ranking function, the error depends on the scale of output of the\n        &gt;&gt;&gt; # ground truth. Because of stochasticity of BED, error might be high even when expressions match exactly.\n        &gt;&gt;&gt; se.evaluate_expr([\"C\", \"+\", \"X_0\"]) &lt; 0.2\n        True\n        &gt;&gt;&gt; # X can also be sampled from a domain by providing domain_bounds\n        &gt;&gt;&gt; se = SR_evaluator(X, ground_truth=gt, ranking_function=\"bed\", domain_bounds=[(-1, 1), (-1, 1)])\n        &gt;&gt;&gt; se.evaluate_expr([\"C\", \"+\", \"X_0\"]) &lt; 0.2\n        True\n\n    Args:\n        expr: An expression. This should be an istance of the SRToolkit.utils.expression_tree.Node class or a list\n              of tokens in the infix notation.\n        simplify_expr: If True, simplifies the expression using SymPy before evaluating it. This typically slows down\n                       evaluation. We recommend simplifying only the best expressions when getting results using\n                       the get_results method.\n        verbose: When 0, no additional output is printed, when 1, prints the expression being evaluated, RMSE, and\n                 estimated parameters, and when 2, also prints numpy errors produced during evaluation.\n\n    Returns:\n        The root-mean-square error of the expression.\n\n    Warnings:\n        Maximum number of evaluations reached: If the maximum number of evaluations has been reached, a warning is printed and np.nan is returned.\n\n    Notes:\n        If the expression has already been evaluated, its stored value is returned instead of re-evaluating the expression.\n        When the maximum number of evaluations has been reached, a warning is printed and np.nan is returned.\n    \"\"\"\n    self.total_evaluations += 1\n\n    if 0 &lt;= self.max_evaluations &lt; self.total_evaluations:\n        warnings.warn(\n            f\"Maximum number of evaluations ({self.max_evaluations}) reached. Stopping evaluation.\"\n        )\n        return np.nan\n    else:\n        if simplify_expr:\n            try:\n                expr = simplify(expr, self.symbol_library)\n            except Exception as e:\n                if isinstance(expr, Node):\n                    expr_list = expr.to_list(symbol_library=self.symbol_library)\n                else:\n                    expr_list = expr\n                print(\n                    f\"Unable to simplify: {''.join(expr_list)}, problems with subexpression {e}\"\n                )\n\n        if isinstance(expr, Node):\n            expr_list = expr.to_list(symbol_library=self.symbol_library)\n        else:\n            expr_list = expr\n\n        expr_str = \"\".join(expr_list)\n        if expr_str in self.models:\n            if verbose &gt; 0:\n                print(f\"Already evaluated {expr_str}\")\n            return self.models[expr_str][\"error\"]\n\n        else:\n            if self.ranking_function == \"rmse\":\n                try:\n                    with (\n                        np.errstate(\n                            divide=\"ignore\",\n                            invalid=\"ignore\",\n                            over=\"ignore\",\n                            under=\"ignore\",\n                        )\n                        if verbose &lt; 2\n                        else nullcontext()\n                    ):\n                        error, parameters = (\n                            self.parameter_estimator.estimate_parameters(expr)\n                        )\n\n                    if verbose &gt; 0:\n                        if parameters.size &gt; 0:\n                            parameter_string = f\" Best parameters found are [{', '.join([str(round(p, 3)) for p in parameters])}]\"\n                        else:\n                            parameter_string = \"\"\n                        print(\n                            f\"Evaluated expression {expr_str} with RMSE: {error}.\"\n                            + parameter_string\n                        )\n\n                except Exception as e:\n                    if verbose &gt; 0:\n                        print(f\"Error evaluating expression {expr_str}: {e}\")\n\n                    self.invalid.append(expr_str)\n                    error, parameters = np.nan, np.array([])\n\n                self.models[expr_str] = {\n                    \"error\": error,\n                    \"parameters\": parameters,\n                    \"expr\": expr_list,\n                }\n\n            elif self.ranking_function == \"bed\":\n                try:\n                    with (\n                        np.errstate(\n                            divide=\"ignore\",\n                            invalid=\"ignore\",\n                            over=\"ignore\",\n                            under=\"ignore\",\n                        )\n                        if verbose &lt; 2\n                        else nullcontext()\n                    ):\n                        error = bed(\n                            expr,\n                            self.gt_behavior,\n                            self.bed_evaluation_parameters[\"bed_X\"],\n                            num_consts_sampled=self.bed_evaluation_parameters[\n                                \"num_consts_sampled\"\n                            ],\n                            num_points_sampled=self.bed_evaluation_parameters[\n                                \"num_points_sampled\"\n                            ],\n                            domain_bounds=self.bed_evaluation_parameters[\n                                \"domain_bounds\"\n                            ],\n                            consts_bounds=self.bed_evaluation_parameters[\n                                \"constant_bounds\"\n                            ],\n                            symbol_library=self.symbol_library,\n                            seed=self.seed,\n                        )\n\n                        if verbose &gt; 0:\n                            print(\n                                f\"Evaluated expression {expr_str} with BED: {error}.\"\n                            )\n\n                except Exception as e:\n                    if verbose &gt; 0:\n                        print(f\"Error evaluating expression {expr_str}: {e}\")\n\n                    self.invalid.append(expr_str)\n                    error = np.nan\n\n                self.models[expr_str] = {\n                    \"error\": error,\n                    \"expr\": expr_list,\n                }\n\n            else:\n                raise ValueError(\n                    f\"Ranking function {self.ranking_function} not supported.\"\n                )\n\n            return error\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.SR_evaluator.get_results","title":"get_results","text":"<pre><code>get_results(approach_name: str = '', top_k: int = 20, results: SR_results = None) -&gt; SR_results\n</code></pre> <p>Returns the results of the equation discovery/symbolic regression process/evaluation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; results = se.get_results(top_k=1)\n&gt;&gt;&gt; print(results[0][\"num_evaluated\"])\n1\n&gt;&gt;&gt; print(results[0][\"evaluation_calls\"])\n1\n&gt;&gt;&gt; print(results[0][\"best_expr\"])\nC*X_1-X_0\n&gt;&gt;&gt; print(results[0][\"min_error\"] &lt; 1e-6)\nTrue\n&gt;&gt;&gt; print(1.99 &lt; results[0][\"top_models\"][0][\"parameters\"][0] &lt; 2.01)\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>approach_name</code> <code>str</code> <p>The name of the approach used to discover the equations.</p> <code>''</code> <code>top_k</code> <code>int</code> <p>The number of top results to include in the output. If <code>top_k</code> is greater than the number of evaluated expressions, all evaluated expressions are included. If <code>top_k</code> is less than 0, all evaluated expressions are included.</p> <code>20</code> <code>results</code> <code>SR_results</code> <p>An SR_results object containing the results of the previous evaluation. If provided, the results of the current evaluation are appended to the existing results. Otherwise, a new SR_results object is created.</p> <code>None</code> <p>Returns:</p> Type Description <code>SR_results</code> <p>An instance of the SR_results object with the results of the evaluation.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def get_results(self, approach_name: str = \"\", top_k: int = 20, results: \"SR_results\" = None) -&gt; \"SR_results\":\n    \"\"\"\n    Returns the results of the equation discovery/symbolic regression process/evaluation.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; results = se.get_results(top_k=1)\n        &gt;&gt;&gt; print(results[0][\"num_evaluated\"])\n        1\n        &gt;&gt;&gt; print(results[0][\"evaluation_calls\"])\n        1\n        &gt;&gt;&gt; print(results[0][\"best_expr\"])\n        C*X_1-X_0\n        &gt;&gt;&gt; print(results[0][\"min_error\"] &lt; 1e-6)\n        True\n        &gt;&gt;&gt; print(1.99 &lt; results[0][\"top_models\"][0][\"parameters\"][0] &lt; 2.01)\n        True\n\n    Args:\n        approach_name: The name of the approach used to discover the equations.\n        top_k: The number of top results to include in the output. If `top_k`\n            is greater than the number of evaluated expressions, all\n            evaluated expressions are included. If `top_k` is less than 0,\n            all evaluated expressions are included.\n        results: An SR_results object containing the results of the previous evaluation. If provided,\n            the results of the current evaluation are appended to the existing results. Otherwise, a new SR_results\n            object is created.\n\n    Returns:\n        An instance of the SR_results object with the results of the evaluation.\n    \"\"\"\n    if top_k &gt; len(self.models) or top_k &lt; 0:\n        top_k = len(self.models)\n\n    if results is None:\n        results = SR_results()\n    results.add_results(self.models, top_k, self.result_augmenters, self.total_evaluations, self.success_threshold,\n                        approach_name, self.metadata)\n\n    return results\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.SR_evaluator.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the SR_evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <code>name</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the evaluator from disk.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the SR_evaluator.\n\n    Args:\n        base_path: Used to save the data of the evaluator to disk.\n        name: Used to save the data of the evaluator to disk.\n\n    Returns:\n        A dictionary containing the necessary information to recreate the evaluator from disk.\n    \"\"\"\n    output = {\"type\": \"SR_evaluator\",\n              \"metadata\": self.metadata,\n              \"symbol_library\": self.symbol_library.to_dict(),\n              \"max_evaluations\": self.max_evaluations,\n              \"success_threshold\": self.success_threshold,\n              \"ranking_function\": self.ranking_function,\n              \"result_augmenters\": [ra.to_dict(base_path, name) for ra in self.result_augmenters],\n              \"seed\": self.seed,\n              \"kwargs\": self.kwargs}\n\n    if not os.path.isdir(base_path):\n        os.makedirs(base_path)\n\n    X_path = f\"{base_path}/{name}_X.npy\"\n    np.save(X_path, self.X)\n    output[\"X\"] = X_path\n\n    if self.y is not None:\n        y_path = f\"{base_path}/{name}_y.npy\"\n        np.save(y_path, self.y)\n        output[\"y\"] = y_path\n    else:\n        output[\"y\"] = None\n\n    if self.ground_truth is None:\n        output[\"ground_truth\"] = None\n    else:\n        if isinstance(self.ground_truth, list):\n            output[\"ground_truth\"] = self.ground_truth\n        elif isinstance(self.ground_truth, Node):\n            output[\"ground_truth\"] = self.ground_truth.to_list(self.symbol_library)\n        else:\n            gt_path = f\"{base_path}/{name}_gt.npy\"\n            np.save(gt_path, self.ground_truth)\n            output[\"ground_truth\"] = gt_path\n\n    return output\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.SR_evaluator.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; SR_evaluator\n</code></pre> <p>Creates an instance of the SR_evaluator from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>A dictionary containing the necessary information to recreate the evaluator.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>A dictionary mapping the names of the augmenters to the augmenter classes.</p> <code>None</code> <p>Returns:</p> Type Description <code>SR_evaluator</code> <p>An instance of the SR_evaluator.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>if unable to load data for X/y/ground truth data, if result augmenters provided but not the augmenter map or if the result augmentor does not occur in the augmenter map.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"SR_evaluator\":\n    \"\"\"\n    Creates an instance of the SR_evaluator from a dictionary.\n\n    Args:\n        data: A dictionary containing the necessary information to recreate the evaluator.\n        augmenter_map: A dictionary mapping the names of the augmenters to the augmenter classes.\n\n    Returns:\n        An instance of the SR_evaluator.\n\n    Raises:\n        Exception: if unable to load data for X/y/ground truth data, if result augmenters provided but not the\n            augmenter map or if the result augmentor does not occur in the augmenter map.\n    \"\"\"\n    try:\n        X = np.load(data[\"X\"])\n\n        if data[\"y\"] is not None:\n            y = np.load(data[\"y\"])\n        else:\n            y = None\n\n        if data[\"ground_truth\"] is None:\n            gt = None\n        else:\n            if isinstance(data[\"ground_truth\"], list):\n                gt = data[\"ground_truth\"]\n            else:\n                gt = np.load(data[\"ground_truth\"])\n    except Exception as e:\n        raise ValueError(f\"[SR_evaluator.from_dict] Unable to load data for X/y/ground truth due to {e}\")\n\n\n    result_augmenters = []\n    for ra_data in data[\"result_augmenters\"]:\n        if augmenter_map is None:\n            raise ValueError(\"[SR_evaluator.from_dict] Argument augmenter_map must be provided when loading \"\n                             \"the dictionary contains result augmenters.\")\n        if ra_data[\"type\"] not in augmenter_map:\n            raise ValueError(f\"[SR_evaluator.from_dict] Result augmenter {ra_data['type']} not found in the \"\n                             f\"augmenter map.\")\n        result_augmenters.append(augmenter_map[ra_data[\"type\"]].from_dict(ra_data, augmenter_map))\n\n    symbol_library = SymbolLibrary.from_dict(data[\"symbol_library\"])\n    return SR_evaluator(X, y=y, ground_truth=gt, symbol_library=symbol_library,\n                        max_evaluations=data[\"max_evaluations\"], success_threshold=data[\"success_threshold\"],\n                        ranking_function=data[\"ranking_function\"], result_augmenters=result_augmenters,\n                        seed=data[\"seed\"], metadata=data[\"metadata\"], **data[\"kwargs\"])\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.ResultAugmenter","title":"ResultAugmenter","text":"<pre><code>ResultAugmenter()\n</code></pre> <p>Generic class that defines the interface for result augmentation. For examples, see the implementations of this class at SRToolkit.evaluation.result_augmentation.py.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Generic class that defines the interface for result augmentation. For examples, see the implementations of\n    this class at SRToolkit.evaluation.result_augmentation.py.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.ResultAugmenter.augment_results","title":"augment_results","text":"<pre><code>augment_results(results: dict, models: List[dict]) -&gt; dict\n</code></pre> <p>Augments the results dictionary with additional information. The model variable contains all models, for only top models, results[\"top_models\"] should be used.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict</code> <p>The dictionary containing the results to augment.</p> required <code>models</code> <code>List[dict]</code> <p>A list of dictionaries describing the performance of expressions using the base ranking function. Keyword expr contains the expression, error contains the error of the expression. The list is sorted by error.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The augmented results dictionary.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def augment_results(\n    self,\n    results: dict,\n    models: List[dict],\n) -&gt; dict:\n    \"\"\"\n    Augments the results dictionary with additional information. The model variable contains all models, for only\n    top models, results[\"top_models\"] should be used.\n\n    Args:\n        results: The dictionary containing the results to augment.\n        models: A list of dictionaries describing the performance of expressions using the base ranking function.\n            Keyword expr contains the expression, error contains the error of the expression. The list is sorted\n            by error.\n\n    Returns:\n        The augmented results dictionary.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.ResultAugmenter.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Transforms the augmenter into a dictionary. This is used for saving the augmenter to disk.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>The base path used for saving the data inside the augmenter, if needed.</p> required <code>name</code> <code>str</code> <p>The name/identifier used by the augmenter for saving.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Transforms the augmenter into a dictionary. This is used for saving the augmenter to disk.\n\n    Args:\n        base_path: The base path used for saving the data inside the augmenter, if needed.\n        name: The name/identifier used by the augmenter for saving.\n\n    Returns:\n        A dictionary containing the necessary information to recreate the augmenter.\n    \"\"\"\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.ResultAugmenter.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; ResultAugmenter\n</code></pre> <p>Creates an instance of the ResultAugmenter class from the dictionary with the relevant data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>the dictionary containing the data needed to recreate the augmenter.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>A dictionary mapping augmenter names to their classes.</p> <code>None</code> <p>Returns:</p> Type Description <code>ResultAugmenter</code> <p>An instance of the ResultAugmenter class with the same configuration as in the data dictionary.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"ResultAugmenter\":\n    \"\"\"\n    Creates an instance of the ResultAugmenter class from the dictionary with the relevant data.\n\n    Args:\n        data: the dictionary containing the data needed to recreate the augmenter.\n        augmenter_map: A dictionary mapping augmenter names to their classes.\n\n    Returns:\n        An instance of the ResultAugmenter class with the same configuration as in the data dictionary.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.SR_results","title":"SR_results","text":"<pre><code>SR_results()\n</code></pre> <p>Initializes an SR_results object. This object stores the results of an equation discovery/symbolic regression experiments.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; results = se.get_results(top_k=1) # Obtain an instance of SR_results\n&gt;&gt;&gt; print(results[0][\"num_evaluated\"])\n1\n&gt;&gt;&gt; print(results[0][\"evaluation_calls\"])\n1\n&gt;&gt;&gt; print(results[0][\"best_expr\"])\nC*X_1-X_0\n&gt;&gt;&gt; print(results[0][\"min_error\"] &lt; 1e-6)\nTrue\n&gt;&gt;&gt; print(1.99 &lt; results[0][\"top_models\"][0][\"parameters\"][0] &lt; 2.01)\nTrue\n</code></pre> <p>Attributes:</p> Name Type Description <code>results</code> <p>A list of dictionaries containing the results of each evaluation.</p> <p>Functions:</p> Name Description <code>add_results</code> <p>Adds the results of an evaluation to the results object. If needed, the results are additionally augmented using the provided result augmenters.</p> <code>print_results</code> <p>Prints the results of the evaluation.</p> <code>__len__</code> <p>Returns the number of results stored in the results object.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes an SR_results object. This object stores the results of an equation discovery/symbolic regression experiments.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; results = se.get_results(top_k=1) # Obtain an instance of SR_results\n        &gt;&gt;&gt; print(results[0][\"num_evaluated\"])\n        1\n        &gt;&gt;&gt; print(results[0][\"evaluation_calls\"])\n        1\n        &gt;&gt;&gt; print(results[0][\"best_expr\"])\n        C*X_1-X_0\n        &gt;&gt;&gt; print(results[0][\"min_error\"] &lt; 1e-6)\n        True\n        &gt;&gt;&gt; print(1.99 &lt; results[0][\"top_models\"][0][\"parameters\"][0] &lt; 2.01)\n        True\n\n    Attributes:\n        results: A list of dictionaries containing the results of each evaluation.\n\n    Methods:\n        add_results: Adds the results of an evaluation to the results object. If needed, the results are\n            additionally augmented using the provided result augmenters.\n        print_results: Prints the results of the evaluation.\n        __len__: Returns the number of results stored in the results object.\n    \"\"\"\n    self.results = list()\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.SR_results.add_results","title":"add_results","text":"<pre><code>add_results(models: Dict[str, dict], top_k: int, result_augmenters: List[ResultAugmenter], total_evaluations: int, success_threshold: Optional[float], approach_name: str, metadata: Optional[dict] = None)\n</code></pre> <p>Adds the results of an evaluation to the results object. If needed, the results are additionally augmented using the provided result augmenters. For an example of how to use this function, look at the SR_evaluator.get_results method.</p> <p>Parameters:</p> Name Type Description Default <code>models</code> <code>Dict[str, dict]</code> <p>A dictionary mapping expressions to their evaluation results.</p> required <code>top_k</code> <code>int</code> <p>The number of top results to include in the output.</p> required <code>result_augmenters</code> <code>List[ResultAugmenter]</code> <p>A list of result augmenters to use for augmenting the results.</p> required <code>total_evaluations</code> <code>int</code> <p>The total number of evaluations performed during the evaluation.</p> required <code>success_threshold</code> <code>Optional[float]</code> <p>The success threshold used to determine whether the evaluation was successful.</p> required <code>approach_name</code> <code>str</code> <p>The name of the approach used to discover the equations.</p> required <code>metadata</code> <code>Optional[dict]</code> <p>A dictionary containing additional metadata about the evaluation.</p> <code>None</code> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def add_results(self, models: Dict[str, dict], top_k: int, result_augmenters: List[ResultAugmenter],\n                total_evaluations: int, success_threshold: Optional[float], approach_name: str,\n                metadata: Optional[dict] = None):\n    \"\"\"\n    Adds the results of an evaluation to the results object. If needed, the results are additionally augmented\n    using the provided result augmenters. For an example of how to use this function, look at the SR_evaluator.get_results method.\n\n    Args:\n        models: A dictionary mapping expressions to their evaluation results.\n        top_k: The number of top results to include in the output.\n        result_augmenters: A list of result augmenters to use for augmenting the results.\n        total_evaluations: The total number of evaluations performed during the evaluation.\n        success_threshold: The success threshold used to determine whether the evaluation was successful.\n        approach_name: The name of the approach used to discover the equations.\n        metadata: A dictionary containing additional metadata about the evaluation.\n    \"\"\"\n    models = list(models.values())\n    best_indices = np.argsort([v[\"error\"] for v in models])\n    models = [models[i] for i in best_indices]\n\n    results_dict = {\n        \"min_error\": models[0][\"error\"],\n        \"best_expr\": \"\".join(models[0][\"expr\"]),\n        \"num_evaluated\": len(models),\n        \"evaluation_calls\": total_evaluations,\n        \"top_models\": list(),\n        \"metadata\": metadata,\n        \"all_models\": models,\n        \"approach_name\": approach_name\n    }\n\n    # Determine success based on the predefined success threshold\n    if (\n            success_threshold is not None\n            and results_dict[\"min_error\"] &lt; success_threshold\n    ):\n        results_dict[\"success\"] = True\n    else:\n        results_dict[\"success\"] = False\n\n    for model in models[:top_k]:\n        m = {\"expr\": model[\"expr\"], \"error\": model[\"error\"]}\n        if \"parameters\" in model:\n            m[\"parameters\"] = model[\"parameters\"]\n\n        results_dict[\"top_models\"].append(m)\n\n    for augmenter in result_augmenters:\n        try:\n            results_dict = augmenter.augment_results(results_dict, models)\n        except Exception as e:\n            print(\n                f\"Error augmenting results, skipping current augmentor because of the following error: {e}\"\n            )\n\n    self.results.append(results_dict)\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.SR_results.print_results","title":"print_results","text":"<pre><code>print_results(experiment_number: Optional[int] = None, detailed: bool = False)\n</code></pre> <p>Prints the results of the SR_evaluator. Specifically, prints the minimum error, the best expression, the number of evaluated expressions, the number of times the \"evaluate_expr\" function was called, whether the evaluation was successful, and the metadata and the approach name, if present. If detailed is True, prints all the information about the top models.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; results = se.get_results(top_k=1)\n&gt;&gt;&gt; results.print_results()\nExperiment 0:\nBest expression found: C*X_1-X_0\nError: 6.8864915460553005e-09\nNumber of evaluated expressions: 1\nNumber of times evaluate_expr was called: 1\nSuccess: True\n\n-----------------------------------------\n&gt;&gt;&gt; results.print_results(detailed=True, experiment_number=0)\nBest expression found: C*X_1-X_0\nError: 6.8864915460553005e-09\nNumber of evaluated expressions: 1\nNumber of times evaluate_expr was called: 1\nSuccess: True\n\nTop models:\nModel 1 - expr: ['C', '*', 'X_1', '-', 'X_0'], error: 6.8864915460553005e-09, parameters: [2.]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>experiment_number</code> <code>Optional[int]</code> <p>Number of the experiment you want to print the results for. If None, prints the results for all experiments.</p> <code>None</code> <code>detailed</code> <code>bool</code> <p>If True, prints all the information about the top models.</p> <code>False</code> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def print_results(self, experiment_number: Optional[int] = None, detailed: bool = False):\n    r\"\"\"\n    Prints the results of the SR_evaluator. Specifically, prints the minimum error, the best expression,\n    the number of evaluated expressions, the number of times the \"evaluate_expr\" function was called, whether\n    the evaluation was successful, and the metadata and the approach name, if present. If detailed is True, prints\n    all the information about the top models.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; results = se.get_results(top_k=1)\n        &gt;&gt;&gt; results.print_results()\n        Experiment 0:\n        Best expression found: C*X_1-X_0\n        Error: 6.8864915460553005e-09\n        Number of evaluated expressions: 1\n        Number of times evaluate_expr was called: 1\n        Success: True\n        &lt;BLANKLINE&gt;\n        -----------------------------------------\n        &gt;&gt;&gt; results.print_results(detailed=True, experiment_number=0)\n        Best expression found: C*X_1-X_0\n        Error: 6.8864915460553005e-09\n        Number of evaluated expressions: 1\n        Number of times evaluate_expr was called: 1\n        Success: True\n        &lt;BLANKLINE&gt;\n        Top models:\n        Model 1 - expr: ['C', '*', 'X_1', '-', 'X_0'], error: 6.8864915460553005e-09, parameters: [2.]\n        &lt;BLANKLINE&gt;\n\n    Args:\n        experiment_number: Number of the experiment you want to print the results for. If None, prints the results for all experiments.\n        detailed: If True, prints all the information about the top models.\n\n    \"\"\"\n    if experiment_number is None:\n        for i, result in enumerate(self.results):\n            print(f\"Experiment {i+1}/{len(self.results)}:\")\n            SR_results._print_result_(result, detailed)\n            print(\"-----------------------------------------\")\n\n    else:\n        assert experiment_number &lt; len(self.results), \"[SR_Results.print_results] experiment number out of bounds\"\n        SR_results._print_result_(self.results[experiment_number], detailed)\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.SR_results.__add__","title":"__add__","text":"<pre><code>__add__(other)\n</code></pre> <p>Returns a new SR_results object that is the concatenation of the current SR_results object with the other SR_results object.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>SR_results object to concatenate with the current SR_results object.</p> required <p>Returns:</p> Type Description <p>The concatenated SR_results objects.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def __add__(self, other):\n    \"\"\"\n    Returns a new SR_results object that is the concatenation of the current SR_results object with the other SR_results object.\n\n    Args:\n        other: SR_results object to concatenate with the current SR_results object.\n\n    Returns:\n        The concatenated SR_results objects.\n    \"\"\"\n    self.results += other.results\n    return self\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.SR_results.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(item)\n</code></pre> <p>Returns the results of the experiment with the given index.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; results = se.get_results(top_k=1)\n&gt;&gt;&gt; result_of_first_experiment = results[0]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>item</code> <p>the index of the experiment.</p> required <p>Returns:</p> Type Description <p>The results of the experiment with the given index.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def __getitem__(self, item):\n    \"\"\"\n    Returns the results of the experiment with the given index.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; results = se.get_results(top_k=1)\n        &gt;&gt;&gt; result_of_first_experiment = results[0]\n\n    Args:\n        item: the index of the experiment.\n\n    Returns:\n        The results of the experiment with the given index.\n\n    \"\"\"\n    assert isinstance(item, int), \"[SR_Results.__getitem__] Item must be an integer.\"\n    assert 0 &lt;= item &lt; len(self.results), \"[SR_Results.__getitem__] Item out of bounds.\"\n    return self.results[item]\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.SR_results.__len__","title":"__len__","text":"<pre><code>__len__()\n</code></pre> <p>Returns the number of results stored in the results object. Usually, each result corresponds to a single experiment.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; results = se.get_results(top_k=1)\n&gt;&gt;&gt; len(results)\n1\n</code></pre> <p>Returns:</p> Type Description <p>The number of results stored in the results object.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def __len__(self):\n    \"\"\"\n    Returns the number of results stored in the results object. Usually, each result corresponds to a single experiment.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; results = se.get_results(top_k=1)\n        &gt;&gt;&gt; len(results)\n        1\n\n    Returns:\n        The number of results stored in the results object.\n    \"\"\"\n    return len(self.results)\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.ExpressionSimplifier","title":"ExpressionSimplifier","text":"<pre><code>ExpressionSimplifier(symbol_library: SymbolLibrary, only_best_expression: bool = False, verbose: bool = False)\n</code></pre> <p>               Bases: <code>ResultAugmenter</code></p> <p>Simplifies the expressions inside the results dictionary if possible.</p> <p>Parameters:</p> Name Type Description Default <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library used to simplify the expressions.</p> required <code>only_best_expression</code> <code>bool</code> <p>If True, only the best expression is simplified. If False, all top expressions are simplified.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>If True, warns the user if simplification fails for a given expression.</p> <code>False</code> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def __init__(self, symbol_library: SymbolLibrary, only_best_expression: bool = False, verbose: bool = False):\n    \"\"\"\n    Simplifies the expressions inside the results dictionary if possible.\n\n    Args:\n        symbol_library: The symbol library used to simplify the expressions.\n        only_best_expression: If True, only the best expression is simplified. If False, all top expressions are\n            simplified.\n        verbose: If True, warns the user if simplification fails for a given expression.\n    \"\"\"\n    super().__init__()\n    self.symbol_library = symbol_library\n    self.only_best_expression = only_best_expression\n    self.verbose = verbose\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.ExpressionSimplifier.augment_results","title":"augment_results","text":"<pre><code>augment_results(results: dict, models: List[dict]) -&gt; dict\n</code></pre> <p>Simplifies the expressions inside the results dictionary if possible.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict</code> <p>The dictionary containing the results to augment.</p> required <code>models</code> <code>List[dict]</code> <p>A list of dictionaries describing the performance of expressions using the base ranking function. Keyword expr contains the expression, error contains the error of the expression. The list is sorted by error.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The augmented results dictionary. The results dictionary contains an additional key \"simplified_best_expr\"</p> <code>dict</code> <p>if simplification was successful for the best expression, and similarly keys \"simplified_expr\" inside the</p> <code>dict</code> <p>top_models list if only_best_expression is False.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def augment_results(\n    self,\n    results: dict,\n    models: List[dict],\n) -&gt; dict:\n    \"\"\"\n    Simplifies the expressions inside the results dictionary if possible.\n\n    Args:\n        results: The dictionary containing the results to augment.\n        models: A list of dictionaries describing the performance of expressions using the base ranking function.\n            Keyword expr contains the expression, error contains the error of the expression. The list is sorted\n            by error.\n\n    Returns:\n        The augmented results dictionary. The results dictionary contains an additional key \"simplified_best_expr\"\n        if simplification was successful for the best expression, and similarly keys \"simplified_expr\" inside the\n        top_models list if only_best_expression is False.\n    \"\"\"\n    try:\n        simplified_expr = simplify(models[0][\"expr\"], self.symbol_library)\n        results[\"simplified_best_expr\"] = \"\".join(simplified_expr)\n    except Exception as e:\n        if self.verbose:\n            print(f\"Unable to simplify {results['best_expr']}: {e}\")\n\n    for model in results[\"top_models\"]:\n        try:\n            simplified_expr = simplify(model[\"expr\"], self.symbol_library)\n            model[\"simplified_expr\"] = \"\".join(simplified_expr)\n        except Exception as e:\n            if self.verbose:\n                print(f\"Unable to simplify {model['expr']}: {e}\")\n\n    return results\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.ExpressionSimplifier.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the ExpressionSimplifier augmenter.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Unused and ignored</p> required <code>name</code> <code>str</code> <p>Unused and ignored</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the ExpressionSimplifier augmenter.\n\n    Args:\n        base_path: Unused and ignored\n        name: Unused and ignored\n\n    Returns:\n        A dictionary containing the necessary information to recreate the augmenter.\n    \"\"\"\n    return {\"type\": \"ExpressionSimplifier\", \"symbol_library\": self.symbol_library,\n            \"only_best_expression\": self.only_best_expression, \"verbose\": self.verbose}\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.ExpressionSimplifier.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; ExpressionSimplifier\n</code></pre> <p>Creates an instance of the ExpressionSimplifier augmenter from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>Unused and ignored</p> <code>None</code> <p>Returns:     An instance of the ExpressionSimplifier augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"ExpressionSimplifier\":\n    \"\"\"\n    Creates an instance of the ExpressionSimplifier augmenter from a dictionary.\n\n    Args:\n        data: A dictionary containing the necessary information to recreate the augmenter.\n        augmenter_map: Unused and ignored\n    Returns:\n        An instance of the ExpressionSimplifier augmenter.\n    \"\"\"\n    return ExpressionSimplifier(symbol_library=data[\"symbol_library\"],\n                                only_best_expression=data[\"only_best_expression\"], verbose=data[\"verbose\"])\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.RMSE","title":"RMSE","text":"<pre><code>RMSE(evaluator: SR_evaluator)\n</code></pre> <p>               Bases: <code>ResultAugmenter</code></p> <p>Computes the RMSE for the top models in the results dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>SR_evaluator</code> <p>The evaluator used to evaluate the models (e.g., evaluator defined with test set data). This evaluator must be initialized with ranking_function = \"rmse\"</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If the evaluator is not initialized with ranking_function = \"rmse\" or if y in the evaluator is None.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def __init__(self, evaluator: SR_evaluator):  # noqa: F821\n    \"\"\"\n    Computes the RMSE for the top models in the results dictionary.\n\n    Args:\n        evaluator: The evaluator used to evaluate the models (e.g., evaluator defined with test set data). This\n            evaluator must be initialized with ranking_function = \"rmse\"\n\n    Raises:\n        Exception: If the evaluator is not initialized with ranking_function = \"rmse\" or if y in the evaluator is None.\n    \"\"\"\n    super().__init__()\n    self.evaluator = evaluator\n    if self.evaluator.ranking_function != \"rmse\":\n        raise Exception(\n            \"[RMSE augmenter] Ranking function of the evaluator must be set to 'rmse' to compute RMSE.\"\n        )\n    if self.evaluator.y is None:\n        raise Exception(\n            \"[RMSE augmenter] y in the evaluator must not be None to compute RMSE.\"\n        )\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.RMSE.augment_results","title":"augment_results","text":"<pre><code>augment_results(results: dict, models: List[dict]) -&gt; dict\n</code></pre> <p>Computes the RMSE for the top models in the results dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict</code> <p>The dictionary containing the results to augment.</p> required <code>models</code> <code>List[dict]</code> <p>A list of dictionaries describing the performance of expressions using the base ranking function. Keyword expr contains the expression, error contains the error of the expression. The list is sorted by error.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The augmented results dictionary. The results dictionary contains an additional key \"best_expr_rmse\" with the</p> <code>dict</code> <p>RMSE of the best expression, and keys \"rmse\" and \"parameters_rmse\" for each of the top_models inside the</p> <code>dict</code> <p>results[\"top_models\"] list.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def augment_results(\n    self,\n    results: dict,\n    models: List[dict],\n) -&gt; dict:\n    \"\"\"\n    Computes the RMSE for the top models in the results dictionary.\n\n    Args:\n        results: The dictionary containing the results to augment.\n        models: A list of dictionaries describing the performance of expressions using the base ranking function.\n            Keyword expr contains the expression, error contains the error of the expression. The list is sorted\n            by error.\n\n    Returns:\n        The augmented results dictionary. The results dictionary contains an additional key \"best_expr_rmse\" with the\n        RMSE of the best expression, and keys \"rmse\" and \"parameters_rmse\" for each of the top_models inside the\n        results[\"top_models\"] list.\n    \"\"\"\n    expr = models[0][\"expr\"]\n    error = self.evaluator.evaluate_expr(expr)\n    results[\"best_expr_rmse\"] = error\n    for model in results[\"top_models\"]:\n        error = self.evaluator.evaluate_expr(model[\"expr\"])\n        model[\"rmse\"] = error\n        model[\"parameters_rmse\"] = self.evaluator.models[\"\".join(model[\"expr\"])][\n            \"parameters\"\n        ]\n    return results\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.RMSE.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the RMSE augmenter.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <code>name</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the RMSE augmenter.\n\n    Args:\n        base_path: Used to save the data of the evaluator to disk.\n        name: Used to save the data of the evaluator to disk.\n\n    Returns:\n        A dictionary containing the necessary information to recreate the augmenter.\n    \"\"\"\n    return {\"type\": \"RMSE\", \"evaluator\": self.evaluator.to_dict(base_path, name+\"_RMSE_augmenter\")}\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.RMSE.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; RMSE\n</code></pre> <p>Creates an instance of the RMSE augmenter from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>A dictionary mapping augmenter names to their classes.</p> <code>None</code> <p>Returns:</p> Type Description <code>RMSE</code> <p>An instance of the RMSE augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"RMSE\":\n    \"\"\"\n    Creates an instance of the RMSE augmenter from a dictionary.\n\n    Args:\n        data: A dictionary containing the necessary information to recreate the augmenter.\n        augmenter_map: A dictionary mapping augmenter names to their classes.\n\n    Returns:\n        An instance of the RMSE augmenter.\n    \"\"\"\n    evaluator = SR_evaluator.from_dict(data[\"evaluator\"], augmenter_map=augmenter_map)\n    return RMSE(evaluator)\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.R2","title":"R2","text":"<pre><code>R2(evaluator: SR_evaluator)\n</code></pre> <p>               Bases: <code>ResultAugmenter</code></p> <p>Computes the R^2 for the top models in the results dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>SR_evaluator</code> <p>The evaluator used to evaluate the models (e.g., evaluator defined with test set data). This evaluator must be initialized with ranking_function = \"rmse\". If you're also using the RMSE augmenter, they the same one can be used for both.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If the evaluator is not initialized with ranking_function = \"rmse\" or if y in the evaluator is None.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def __init__(self, evaluator: SR_evaluator):  # noqa: F821\n    \"\"\"\n    Computes the R^2 for the top models in the results dictionary.\n\n    Args:\n        evaluator: The evaluator used to evaluate the models (e.g., evaluator defined with test set data). This\n            evaluator must be initialized with ranking_function = \"rmse\". If you're also using the RMSE augmenter,\n            they the same one can be used for both.\n\n    Raises:\n        Exception: If the evaluator is not initialized with ranking_function = \"rmse\" or if y in the evaluator is None.\n    \"\"\"\n    super().__init__()\n    self.evaluator = evaluator\n    if self.evaluator.ranking_function != \"rmse\":\n        raise Exception(\n            \"[R2 augmenter] Ranking function of the evaluator must be set to 'rmse' to compute R^2.\"\n        )\n    if self.evaluator.y is None:\n        raise Exception(\n            \"[R2 augmenter] y in the evaluator must not be None to compute R^2.\"\n        )\n    self.ss_tot = np.sum((self.evaluator.y - np.mean(self.evaluator.y)) ** 2)\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.R2.augment_results","title":"augment_results","text":"<pre><code>augment_results(results: dict, models: List[dict]) -&gt; dict\n</code></pre> <p>Computes the R^2 for the top models in the results dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict</code> <p>The dictionary containing the results to augment.</p> required <code>models</code> <code>List[dict]</code> <p>A list of dictionaries describing the performance of expressions using the base ranking function. Keyword expr contains the expression, error contains the error of the expression. The list is sorted by error.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The augmented results dictionary. The results dictionary contains an additional key \"best_expr_r^2\" with the</p> <code>dict</code> <p>R^2 of the best expression, and keys \"r^2\" and \"parameters_r^2\" for each of the top_models inside the</p> <code>dict</code> <p>results[\"top_models\"] list.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def augment_results(\n    self,\n    results: dict,\n    models: List[dict],\n) -&gt; dict:\n    \"\"\"\n    Computes the R^2 for the top models in the results dictionary.\n\n    Args:\n        results: The dictionary containing the results to augment.\n        models: A list of dictionaries describing the performance of expressions using the base ranking function.\n            Keyword expr contains the expression, error contains the error of the expression. The list is sorted\n            by error.\n\n    Returns:\n        The augmented results dictionary. The results dictionary contains an additional key \"best_expr_r^2\" with the\n        R^2 of the best expression, and keys \"r^2\" and \"parameters_r^2\" for each of the top_models inside the\n        results[\"top_models\"] list.\n    \"\"\"\n    results[\"best_expr_r^2\"] = self._compute_r2(models[0])\n    for model in results[\"top_models\"]:\n        r2 = self._compute_r2(model)\n        model[\"r^2\"] = r2\n        model[\"parameters_r^2\"] = (\n            self.evaluator.models[\"\".join(model[\"expr\"])][\"parameters\"]\n            if \"parameters\" in self.evaluator.models[\"\".join(model[\"expr\"])]\n            else \"\"\n        )\n    return results\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.R2.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the R2 augmenter.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <code>name</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the R2 augmenter.\n\n    Args:\n        base_path: Used to save the data of the evaluator to disk.\n        name: Used to save the data of the evaluator to disk.\n\n    Returns:\n        A dictionary containing the necessary information to recreate the augmenter.\n    \"\"\"\n    return {\"type\": \"R2\", \"evaluator\": self.evaluator.to_dict(base_path, name+\"_R2_augmenter\")}\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.R2.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; R2\n</code></pre> <p>Creates an instance of the R2 augmenter from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>A dictionary mapping augmenter names to their classes.</p> <code>None</code> <p>Returns:</p> Type Description <code>R2</code> <p>An instance of the R2 augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"R2\":\n    \"\"\"\n    Creates an instance of the R2 augmenter from a dictionary.\n\n    Args:\n        data: A dictionary containing the necessary information to recreate the augmenter.\n        augmenter_map: A dictionary mapping augmenter names to their classes.\n\n    Returns:\n        An instance of the R2 augmenter.\n    \"\"\"\n    evaluator = SR_evaluator.from_dict(data[\"evaluator\"], augmenter_map=augmenter_map)\n    return R2(evaluator)\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.BED","title":"BED","text":"<pre><code>BED(evaluator: SR_evaluator)\n</code></pre> <p>               Bases: <code>ResultAugmenter</code></p> <p>Computes BED for the top models in the results dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>SR_evaluator</code> <p>The evaluator used to evaluate the models. This evaluator must be initialized with ranking_function = \"bed\"</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If the evaluator is not initialized with ranking_function = \"bed\".</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def __init__(self, evaluator: SR_evaluator):  # noqa: F821\n    \"\"\"\n    Computes BED for the top models in the results dictionary.\n\n    Args:\n        evaluator: The evaluator used to evaluate the models. This evaluator must be initialized with\n            ranking_function = \"bed\"\n\n    Raises:\n        Exception: If the evaluator is not initialized with ranking_function = \"bed\".\n    \"\"\"\n    super().__init__()\n    self.evaluator = evaluator\n    if self.evaluator.ranking_function != \"bed\":\n        raise Exception(\n            \"[BED augmenter] Ranking function of the evaluator must be set to 'bed' to compute BED.\"\n        )\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.BED.augment_results","title":"augment_results","text":"<pre><code>augment_results(results: dict, models: List[dict]) -&gt; dict\n</code></pre> <p>Computes BED for the top models in the results dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict</code> <p>The dictionary containing the results to augment.</p> required <code>models</code> <code>List[dict]</code> <p>A list of dictionaries describing the performance of expressions using the base ranking function. Keyword expr contains the expression, error contains the error of the expression. The list is sorted by error.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The augmented results dictionary. The results dictionary contains an additional key \"best_expr_bed\" with</p> <code>dict</code> <p>BED of the best expression, and key \"bed\" for each of the top_models inside the results[\"top_models\"] list.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def augment_results(\n    self,\n    results: dict,\n    models: List[dict],\n) -&gt; dict:\n    \"\"\"\n    Computes BED for the top models in the results dictionary.\n\n    Args:\n        results: The dictionary containing the results to augment.\n        models: A list of dictionaries describing the performance of expressions using the base ranking function.\n            Keyword expr contains the expression, error contains the error of the expression. The list is sorted\n            by error.\n\n    Returns:\n        The augmented results dictionary. The results dictionary contains an additional key \"best_expr_bed\" with\n        BED of the best expression, and key \"bed\" for each of the top_models inside the results[\"top_models\"] list.\n    \"\"\"\n    expr = models[0][\"expr\"]\n    error = self.evaluator.evaluate_expr(expr)\n    results[\"best_expr_bed\"] = error\n    for model in results[\"top_models\"]:\n        model[\"bed\"] = self.evaluator.evaluate_expr(model[\"expr\"])\n    return results\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.BED.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the BED augmenter.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <code>name</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the BED augmenter.\n\n    Args:\n        base_path: Used to save the data of the evaluator to disk.\n        name: Used to save the data of the evaluator to disk.\n\n    Returns:\n        A dictionary containing the necessary information to recreate the augmenter.\n    \"\"\"\n    return {\"type\": \"BED\", \"evaluator\": self.evaluator.to_dict(base_path, name+\"_BED_augmenter\")}\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.BED.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; BED\n</code></pre> <p>Creates an instance of the BED augmenter from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>A dictionary mapping augmenter names to their classes.</p> <code>None</code> <p>Returns:</p> Type Description <code>BED</code> <p>An instance of the BED augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"BED\":\n    \"\"\"\n    Creates an instance of the BED augmenter from a dictionary.\n\n    Args:\n        data: A dictionary containing the necessary information to recreate the augmenter.\n        augmenter_map: A dictionary mapping augmenter names to their classes.\n\n    Returns:\n        An instance of the BED augmenter.\n    \"\"\"\n    evaluator = SR_evaluator.from_dict(data[\"evaluator\"], augmenter_map=augmenter_map)\n    return BED(evaluator)\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.ExpressionToLatex","title":"ExpressionToLatex","text":"<pre><code>ExpressionToLatex(symbol_library: SymbolLibrary, only_best_expression: bool = False, verbose: bool = False)\n</code></pre> <p>               Bases: <code>ResultAugmenter</code></p> <p>Transforms the expressions inside the results dictionary into LaTeX strings.</p> <p>Parameters:</p> Name Type Description Default <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library used to convert tokens into LaTeX symbols.</p> required <code>only_best_expression</code> <code>bool</code> <p>If True, only the best expression is transformed. If False, all top expressions are transformed.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>If True, warns the user if LaTeX conversion fails for a given expression.</p> <code>False</code> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def __init__(self, symbol_library: SymbolLibrary, only_best_expression: bool = False, verbose: bool = False):\n    \"\"\"\n    Transforms the expressions inside the results dictionary into LaTeX strings.\n\n    Args:\n        symbol_library: The symbol library used to convert tokens into LaTeX symbols.\n        only_best_expression: If True, only the best expression is transformed. If False, all top expressions are\n            transformed.\n        verbose: If True, warns the user if LaTeX conversion fails for a given expression.\n    \"\"\"\n    super().__init__()\n    self.symbol_library = symbol_library\n    self.only_best_expression = only_best_expression\n    self.verbose = verbose\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.ExpressionToLatex.augment_results","title":"augment_results","text":"<pre><code>augment_results(results: dict, models: List[dict]) -&gt; dict\n</code></pre> <p>Transforms the expressions inside the results dictionary into LaTeX strings.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict</code> <p>The dictionary containing the results to augment.</p> required <code>models</code> <code>List[dict]</code> <p>A list of dictionaries describing the performance of expressions using the base ranking function. Keyword expr contains the expression, error contains the error of the expression. The list is sorted by error.</p> required <p>Returns:     The augmented results dictionary. The results dictionary contains an additional key \"best_expr_latex\" with         the LaTeX representation of the best expression, and similarly keys \"expr_latex\" for expressions inside         the top_models list if only_best_expression is False.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def augment_results(\n    self,\n    results: dict,\n    models: List[dict]\n    ) -&gt; dict:\n    \"\"\"\n    Transforms the expressions inside the results dictionary into LaTeX strings.\n\n    Args:\n        results: The dictionary containing the results to augment.\n        models: A list of dictionaries describing the performance of expressions using the base ranking function.\n            Keyword expr contains the expression, error contains the error of the expression. The list is sorted\n            by error.\n    Returns:\n        The augmented results dictionary. The results dictionary contains an additional key \"best_expr_latex\" with\n            the LaTeX representation of the best expression, and similarly keys \"expr_latex\" for expressions inside\n            the top_models list if only_best_expression is False.\n    \"\"\"\n    try:\n        results[\"best_expr_latex\"] = tokens_to_tree(\n            models[0][\"expr\"], self.symbol_library\n        ).to_latex(self.symbol_library)\n    except Exception as e:\n        if self.verbose:\n            print(f\"Unable to convert best expression to LaTeX: {e}\")\n    if not self.only_best_expression:\n        for model in results[\"top_models\"]:\n            try:\n                model[\"expr_latex\"] = tokens_to_tree(\n                    model[\"expr\"], self.symbol_library\n                ).to_latex(self.symbol_library)\n            except Exception as e:\n                if self.verbose:\n                    print(\n                        f\"Unable to convert expression {''.join(model['expr'])} to LaTeX: {e}\"\n                    )\n\n    return results\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.ExpressionToLatex.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the ExpressionToLatex augmenter.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Unused and ignored</p> required <code>name</code> <code>str</code> <p>Unused and ignored</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the ExpressionToLatex augmenter.\n\n    Args:\n        base_path: Unused and ignored\n        name: Unused and ignored\n\n    Returns:\n        A dictionary containing the necessary information to recreate the augmenter.\n    \"\"\"\n    return {\"type\": \"ExpressionToLatex\", \"symbol_library\": self.symbol_library.to_dict(),\n            \"only_best_expression\": self.only_best_expression, \"verbose\": self.verbose}\n</code></pre>"},{"location":"references/evaluation/#SRToolkit.evaluation.ExpressionToLatex.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; ExpressionToLatex\n</code></pre> <p>Creates an instance of the ExpressionToLatex augmenter from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>Unused and ignored</p> <code>None</code> <p>Returns:</p> Type Description <code>ExpressionToLatex</code> <p>An instance of the ExpressionToLatex augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"ExpressionToLatex\":\n    \"\"\"\n    Creates an instance of the ExpressionToLatex augmenter from a dictionary.\n\n    Args:\n        data: A dictionary containing the necessary information to recreate the augmenter.\n        augmenter_map: Unused and ignored\n\n    Returns:\n        An instance of the ExpressionToLatex augmenter.\n    \"\"\"\n    return ExpressionToLatex(symbol_library=data[\"symbol_library\"],\n                             only_best_expression=data[\"only_best_expression\"], verbose=data[\"verbose\"])\n</code></pre>"},{"location":"references/evaluation/parameter_estimator/","title":"Parameter Estimator","text":""},{"location":"references/evaluation/parameter_estimator/#SRToolkit.evaluation.parameter_estimator","title":"SRToolkit.evaluation.parameter_estimator","text":"<p>This module contains the ParameterEstimator class, which is used to estimate the parameters of an expression.</p>"},{"location":"references/evaluation/parameter_estimator/#SRToolkit.evaluation.parameter_estimator.ParameterEstimator","title":"ParameterEstimator","text":"<pre><code>ParameterEstimator(X: ndarray, y: ndarray, symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(), seed: Optional[int] = None, **kwargs)\n</code></pre> <p>Initializes an instance of the ParameterEstimator class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; pe = ParameterEstimator(X, y)\n&gt;&gt;&gt; rmse, constants = pe.estimate_parameters([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; print(rmse &lt; 1e-6)\nTrue\n&gt;&gt;&gt; print(1.99 &lt; constants[0] &lt; 2.01)\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data to be used in parameter estimation for variables. We assume that X is a 2D array with shape (n_samples, n_features).</p> required <code>y</code> <code>ndarray</code> <p>The target values to be used in parameter estimation.</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use. Defaults to SymbolLibrary.default_symbols().</p> <code>default_symbols()</code> <p>Other Parameters:</p> Name Type Description <code>method</code> <code>str</code> <p>The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested. Default is \"L-BFGS-B\".</p> <code>tol</code> <code>float</code> <p>The tolerance for termination. Default is 1e-6.</p> <code>gtol</code> <code>float</code> <p>The tolerance for the gradient norm. Default is 1e-3.</p> <code>max_iter</code> <code>int</code> <p>The maximum number of iterations. Default is 100.</p> <code>constant_bounds</code> <code>Tuple[float, float]</code> <p>A tuple of two elements, specifying the lower and upper bounds for the constant values. Default is (-5, 5).</p> <code>initialization</code> <code>str</code> <p>The method to use for initializing the constant values. Currently, only \"random\" and \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\" creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".</p> <code>max_constants</code> <code>int</code> <p>The maximum number of constants allowed in the expression. Default is 8.</p> <code>max_expr_length</code> <code>int</code> <p>The maximum length of the expression. Default is -1 (no limit).</p> <p>Functions:</p> Name Description <code>estimate_parameters</code> <p>List[str]): Estimates the parameters of an expression by minimizing the error between the predicted and actual values.</p> Source code in <code>SRToolkit/evaluation/parameter_estimator.py</code> <pre><code>def __init__(\n    self,\n    X: np.ndarray,\n    y: np.ndarray,\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n    seed: Optional[int] = None,\n    **kwargs,\n):\n    \"\"\"\n    Initializes an instance of the ParameterEstimator class.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; pe = ParameterEstimator(X, y)\n        &gt;&gt;&gt; rmse, constants = pe.estimate_parameters([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; print(rmse &lt; 1e-6)\n        True\n        &gt;&gt;&gt; print(1.99 &lt; constants[0] &lt; 2.01)\n        True\n\n    Args:\n        X: The input data to be used in parameter estimation for variables. We assume that X is a 2D array\n            with shape (n_samples, n_features).\n        y: The target values to be used in parameter estimation.\n        symbol_library: The symbol library to use. Defaults to SymbolLibrary.default_symbols().\n\n    Keyword Arguments:\n        method (str): The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested. Default is \"L-BFGS-B\".\n        tol (float): The tolerance for termination. Default is 1e-6.\n        gtol (float): The tolerance for the gradient norm. Default is 1e-3.\n        max_iter (int): The maximum number of iterations. Default is 100.\n        constant_bounds (Tuple[float, float]): A tuple of two elements, specifying the lower and upper bounds for the constant values. Default is (-5, 5).\n        initialization (str): The method to use for initializing the constant values. Currently, only \"random\" and \"mean\" are supported. \"random\" creates a vector with random values\n            sampled within the bounds. \"mean\" creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".\n        max_constants (int): The maximum number of constants allowed in the expression. Default is 8.\n        max_expr_length (int): The maximum length of the expression. Default is -1 (no limit).\n\n    Methods:\n        estimate_parameters(expr: List[str]): Estimates the parameters of an expression by minimizing the error between the predicted and actual values.\n    \"\"\"\n    self.symbol_library = symbol_library\n    self.X = X\n    self.y = y\n    self.seed = seed\n    # self.stats = {\"success\": 0, \"failure\": 0, \"steps\": dict(), \"num_constants\": dict(), \"failed_constants\": dict()}\n\n    self.estimation_settings = {\n        \"method\": \"L-BFGS-B\",\n        \"tol\": 1e-6,\n        \"gtol\": 1e-3,\n        \"max_iter\": 100,\n        \"constant_bounds\": (-5, 5),\n        \"initialization\": \"random\",  # random, mean\n        \"max_constants\": 8,\n        \"max_expr_length\": -1,\n    }\n\n    if kwargs:\n        for k in self.estimation_settings.keys():\n            if k in kwargs:\n                self.estimation_settings[k] = kwargs[k]\n\n    if self.seed is not None:\n        np.random.seed(self.seed)\n</code></pre>"},{"location":"references/evaluation/parameter_estimator/#SRToolkit.evaluation.parameter_estimator.ParameterEstimator.estimate_parameters","title":"estimate_parameters","text":"<pre><code>estimate_parameters(expr: Union[List[str], Node]) -&gt; Tuple[float, np.ndarray]\n</code></pre> <p>Estimates the parameters of an expression by minimizing the error between the predicted and actual values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; pe = ParameterEstimator(X, y)\n&gt;&gt;&gt; rmse, constants = pe.estimate_parameters([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; print(rmse &lt; 1e-6)\nTrue\n&gt;&gt;&gt; print(1.99 &lt; constants[0] &lt; 2.01)\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[List[str], Node]</code> <p>An expression. This should either be an instance of SRToolkit.utils.expression_tree.Node or a list of   tokens in the infix notation representing the expression to be evaluated.</p> required <p>Returns:</p> Type Description <code>float</code> <p>the root mean square error (RMSE) of the optimized expression.</p> <code>ndarray</code> <p>An array containing the optimized constant values.</p> Notes <p>if the length of the expression exceeds the maximum allowed, NaN and an empty array are returned. If the number of constants in the expression exceeds the maximum allowed, NaN and an empty array are returned. If there are no constants in the expression, the RMSE is calculated directly without optimization.</p> Source code in <code>SRToolkit/evaluation/parameter_estimator.py</code> <pre><code>def estimate_parameters(\n    self, expr: Union[List[str], Node]\n) -&gt; Tuple[float, np.ndarray]:\n    \"\"\"\n    Estimates the parameters of an expression by minimizing the error between the predicted and actual values.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; pe = ParameterEstimator(X, y)\n        &gt;&gt;&gt; rmse, constants = pe.estimate_parameters([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; print(rmse &lt; 1e-6)\n        True\n        &gt;&gt;&gt; print(1.99 &lt; constants[0] &lt; 2.01)\n        True\n\n    Args:\n        expr: An expression. This should either be an instance of SRToolkit.utils.expression_tree.Node or a list of\n              tokens in the infix notation representing the expression to be evaluated.\n\n    Returns:\n        the root mean square error (RMSE) of the optimized expression.\n        An array containing the optimized constant values.\n\n    Notes:\n        if the length of the expression exceeds the maximum allowed, NaN and an empty array are returned.\n        If the number of constants in the expression exceeds the maximum allowed, NaN and an empty array are returned.\n        If there are no constants in the expression, the RMSE is calculated directly without optimization.\n    \"\"\"\n    if isinstance(expr, Node):\n        expr_str = expr.to_list(notation=\"prefix\")\n        num_constants = sum(\n            [1 for t in expr_str if self.symbol_library.get_type(t) == \"const\"]\n        )\n    else:\n        num_constants = sum(\n            [1 for t in expr if self.symbol_library.get_type(t) == \"const\"]\n        )\n    if 0 &lt;= self.estimation_settings[\"max_constants\"] &lt; num_constants:\n        return np.nan, np.array([])\n\n    if 0 &lt;= self.estimation_settings[\"max_expr_length\"] &lt; len(expr):\n        return np.nan, np.array([])\n\n    executable_error_fn = expr_to_error_function(expr, self.symbol_library)\n\n    if num_constants == 0:\n        rmse = executable_error_fn(self.X, np.array([]), self.y)\n        return rmse, np.array([])\n    else:\n        return self._optimize_parameters(executable_error_fn, num_constants)\n</code></pre>"},{"location":"references/evaluation/result_augmentation/","title":"Result Augmentation","text":""},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation","title":"SRToolkit.evaluation.result_augmentation","text":"<p>This module contains the implementations of the ResultAugmenter class. These implementations augment the results dictionary returned by the SRToolkit.evaluate function with additional information, such as the LaTeX representation of the best expression, or RMSE on the test set, ...</p>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.RESULT_AUGMENTERS","title":"RESULT_AUGMENTERS  <code>module-attribute</code>","text":"<pre><code>RESULT_AUGMENTERS: Dict[str, Type[ResultAugmenter]] = {'ExpressionToLatex': ExpressionToLatex, 'RMSE': RMSE, 'BED': BED, 'R2': R2, 'ExpressionSimplifier': ExpressionSimplifier}\n</code></pre> <p>A mapping of augmentation names to their corresponding ResultAugmenter classes.</p> <p>This constant defines the library of available result augmentation classes used across the benchmarking framework.</p> <p>The dictionary keys are the unique string identifiers for the augmentor found under the 'type' value in the to_dict  function. The values are the uninstantiated class objects, all of which inherit from ResultAugmenter.</p>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.ExpressionToLatex","title":"ExpressionToLatex","text":"<pre><code>ExpressionToLatex(symbol_library: SymbolLibrary, only_best_expression: bool = False, verbose: bool = False)\n</code></pre> <p>               Bases: <code>ResultAugmenter</code></p> <p>Transforms the expressions inside the results dictionary into LaTeX strings.</p> <p>Parameters:</p> Name Type Description Default <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library used to convert tokens into LaTeX symbols.</p> required <code>only_best_expression</code> <code>bool</code> <p>If True, only the best expression is transformed. If False, all top expressions are transformed.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>If True, warns the user if LaTeX conversion fails for a given expression.</p> <code>False</code> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def __init__(self, symbol_library: SymbolLibrary, only_best_expression: bool = False, verbose: bool = False):\n    \"\"\"\n    Transforms the expressions inside the results dictionary into LaTeX strings.\n\n    Args:\n        symbol_library: The symbol library used to convert tokens into LaTeX symbols.\n        only_best_expression: If True, only the best expression is transformed. If False, all top expressions are\n            transformed.\n        verbose: If True, warns the user if LaTeX conversion fails for a given expression.\n    \"\"\"\n    super().__init__()\n    self.symbol_library = symbol_library\n    self.only_best_expression = only_best_expression\n    self.verbose = verbose\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.ExpressionToLatex.augment_results","title":"augment_results","text":"<pre><code>augment_results(results: dict, models: List[dict]) -&gt; dict\n</code></pre> <p>Transforms the expressions inside the results dictionary into LaTeX strings.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict</code> <p>The dictionary containing the results to augment.</p> required <code>models</code> <code>List[dict]</code> <p>A list of dictionaries describing the performance of expressions using the base ranking function. Keyword expr contains the expression, error contains the error of the expression. The list is sorted by error.</p> required <p>Returns:     The augmented results dictionary. The results dictionary contains an additional key \"best_expr_latex\" with         the LaTeX representation of the best expression, and similarly keys \"expr_latex\" for expressions inside         the top_models list if only_best_expression is False.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def augment_results(\n    self,\n    results: dict,\n    models: List[dict]\n    ) -&gt; dict:\n    \"\"\"\n    Transforms the expressions inside the results dictionary into LaTeX strings.\n\n    Args:\n        results: The dictionary containing the results to augment.\n        models: A list of dictionaries describing the performance of expressions using the base ranking function.\n            Keyword expr contains the expression, error contains the error of the expression. The list is sorted\n            by error.\n    Returns:\n        The augmented results dictionary. The results dictionary contains an additional key \"best_expr_latex\" with\n            the LaTeX representation of the best expression, and similarly keys \"expr_latex\" for expressions inside\n            the top_models list if only_best_expression is False.\n    \"\"\"\n    try:\n        results[\"best_expr_latex\"] = tokens_to_tree(\n            models[0][\"expr\"], self.symbol_library\n        ).to_latex(self.symbol_library)\n    except Exception as e:\n        if self.verbose:\n            print(f\"Unable to convert best expression to LaTeX: {e}\")\n    if not self.only_best_expression:\n        for model in results[\"top_models\"]:\n            try:\n                model[\"expr_latex\"] = tokens_to_tree(\n                    model[\"expr\"], self.symbol_library\n                ).to_latex(self.symbol_library)\n            except Exception as e:\n                if self.verbose:\n                    print(\n                        f\"Unable to convert expression {''.join(model['expr'])} to LaTeX: {e}\"\n                    )\n\n    return results\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.ExpressionToLatex.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the ExpressionToLatex augmenter.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Unused and ignored</p> required <code>name</code> <code>str</code> <p>Unused and ignored</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the ExpressionToLatex augmenter.\n\n    Args:\n        base_path: Unused and ignored\n        name: Unused and ignored\n\n    Returns:\n        A dictionary containing the necessary information to recreate the augmenter.\n    \"\"\"\n    return {\"type\": \"ExpressionToLatex\", \"symbol_library\": self.symbol_library.to_dict(),\n            \"only_best_expression\": self.only_best_expression, \"verbose\": self.verbose}\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.ExpressionToLatex.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; ExpressionToLatex\n</code></pre> <p>Creates an instance of the ExpressionToLatex augmenter from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>Unused and ignored</p> <code>None</code> <p>Returns:</p> Type Description <code>ExpressionToLatex</code> <p>An instance of the ExpressionToLatex augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"ExpressionToLatex\":\n    \"\"\"\n    Creates an instance of the ExpressionToLatex augmenter from a dictionary.\n\n    Args:\n        data: A dictionary containing the necessary information to recreate the augmenter.\n        augmenter_map: Unused and ignored\n\n    Returns:\n        An instance of the ExpressionToLatex augmenter.\n    \"\"\"\n    return ExpressionToLatex(symbol_library=data[\"symbol_library\"],\n                             only_best_expression=data[\"only_best_expression\"], verbose=data[\"verbose\"])\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.ExpressionSimplifier","title":"ExpressionSimplifier","text":"<pre><code>ExpressionSimplifier(symbol_library: SymbolLibrary, only_best_expression: bool = False, verbose: bool = False)\n</code></pre> <p>               Bases: <code>ResultAugmenter</code></p> <p>Simplifies the expressions inside the results dictionary if possible.</p> <p>Parameters:</p> Name Type Description Default <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library used to simplify the expressions.</p> required <code>only_best_expression</code> <code>bool</code> <p>If True, only the best expression is simplified. If False, all top expressions are simplified.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>If True, warns the user if simplification fails for a given expression.</p> <code>False</code> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def __init__(self, symbol_library: SymbolLibrary, only_best_expression: bool = False, verbose: bool = False):\n    \"\"\"\n    Simplifies the expressions inside the results dictionary if possible.\n\n    Args:\n        symbol_library: The symbol library used to simplify the expressions.\n        only_best_expression: If True, only the best expression is simplified. If False, all top expressions are\n            simplified.\n        verbose: If True, warns the user if simplification fails for a given expression.\n    \"\"\"\n    super().__init__()\n    self.symbol_library = symbol_library\n    self.only_best_expression = only_best_expression\n    self.verbose = verbose\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.ExpressionSimplifier.augment_results","title":"augment_results","text":"<pre><code>augment_results(results: dict, models: List[dict]) -&gt; dict\n</code></pre> <p>Simplifies the expressions inside the results dictionary if possible.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict</code> <p>The dictionary containing the results to augment.</p> required <code>models</code> <code>List[dict]</code> <p>A list of dictionaries describing the performance of expressions using the base ranking function. Keyword expr contains the expression, error contains the error of the expression. The list is sorted by error.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The augmented results dictionary. The results dictionary contains an additional key \"simplified_best_expr\"</p> <code>dict</code> <p>if simplification was successful for the best expression, and similarly keys \"simplified_expr\" inside the</p> <code>dict</code> <p>top_models list if only_best_expression is False.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def augment_results(\n    self,\n    results: dict,\n    models: List[dict],\n) -&gt; dict:\n    \"\"\"\n    Simplifies the expressions inside the results dictionary if possible.\n\n    Args:\n        results: The dictionary containing the results to augment.\n        models: A list of dictionaries describing the performance of expressions using the base ranking function.\n            Keyword expr contains the expression, error contains the error of the expression. The list is sorted\n            by error.\n\n    Returns:\n        The augmented results dictionary. The results dictionary contains an additional key \"simplified_best_expr\"\n        if simplification was successful for the best expression, and similarly keys \"simplified_expr\" inside the\n        top_models list if only_best_expression is False.\n    \"\"\"\n    try:\n        simplified_expr = simplify(models[0][\"expr\"], self.symbol_library)\n        results[\"simplified_best_expr\"] = \"\".join(simplified_expr)\n    except Exception as e:\n        if self.verbose:\n            print(f\"Unable to simplify {results['best_expr']}: {e}\")\n\n    for model in results[\"top_models\"]:\n        try:\n            simplified_expr = simplify(model[\"expr\"], self.symbol_library)\n            model[\"simplified_expr\"] = \"\".join(simplified_expr)\n        except Exception as e:\n            if self.verbose:\n                print(f\"Unable to simplify {model['expr']}: {e}\")\n\n    return results\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.ExpressionSimplifier.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the ExpressionSimplifier augmenter.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Unused and ignored</p> required <code>name</code> <code>str</code> <p>Unused and ignored</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the ExpressionSimplifier augmenter.\n\n    Args:\n        base_path: Unused and ignored\n        name: Unused and ignored\n\n    Returns:\n        A dictionary containing the necessary information to recreate the augmenter.\n    \"\"\"\n    return {\"type\": \"ExpressionSimplifier\", \"symbol_library\": self.symbol_library,\n            \"only_best_expression\": self.only_best_expression, \"verbose\": self.verbose}\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.ExpressionSimplifier.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; ExpressionSimplifier\n</code></pre> <p>Creates an instance of the ExpressionSimplifier augmenter from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>Unused and ignored</p> <code>None</code> <p>Returns:     An instance of the ExpressionSimplifier augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"ExpressionSimplifier\":\n    \"\"\"\n    Creates an instance of the ExpressionSimplifier augmenter from a dictionary.\n\n    Args:\n        data: A dictionary containing the necessary information to recreate the augmenter.\n        augmenter_map: Unused and ignored\n    Returns:\n        An instance of the ExpressionSimplifier augmenter.\n    \"\"\"\n    return ExpressionSimplifier(symbol_library=data[\"symbol_library\"],\n                                only_best_expression=data[\"only_best_expression\"], verbose=data[\"verbose\"])\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.RMSE","title":"RMSE","text":"<pre><code>RMSE(evaluator: SR_evaluator)\n</code></pre> <p>               Bases: <code>ResultAugmenter</code></p> <p>Computes the RMSE for the top models in the results dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>SR_evaluator</code> <p>The evaluator used to evaluate the models (e.g., evaluator defined with test set data). This evaluator must be initialized with ranking_function = \"rmse\"</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If the evaluator is not initialized with ranking_function = \"rmse\" or if y in the evaluator is None.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def __init__(self, evaluator: SR_evaluator):  # noqa: F821\n    \"\"\"\n    Computes the RMSE for the top models in the results dictionary.\n\n    Args:\n        evaluator: The evaluator used to evaluate the models (e.g., evaluator defined with test set data). This\n            evaluator must be initialized with ranking_function = \"rmse\"\n\n    Raises:\n        Exception: If the evaluator is not initialized with ranking_function = \"rmse\" or if y in the evaluator is None.\n    \"\"\"\n    super().__init__()\n    self.evaluator = evaluator\n    if self.evaluator.ranking_function != \"rmse\":\n        raise Exception(\n            \"[RMSE augmenter] Ranking function of the evaluator must be set to 'rmse' to compute RMSE.\"\n        )\n    if self.evaluator.y is None:\n        raise Exception(\n            \"[RMSE augmenter] y in the evaluator must not be None to compute RMSE.\"\n        )\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.RMSE.augment_results","title":"augment_results","text":"<pre><code>augment_results(results: dict, models: List[dict]) -&gt; dict\n</code></pre> <p>Computes the RMSE for the top models in the results dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict</code> <p>The dictionary containing the results to augment.</p> required <code>models</code> <code>List[dict]</code> <p>A list of dictionaries describing the performance of expressions using the base ranking function. Keyword expr contains the expression, error contains the error of the expression. The list is sorted by error.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The augmented results dictionary. The results dictionary contains an additional key \"best_expr_rmse\" with the</p> <code>dict</code> <p>RMSE of the best expression, and keys \"rmse\" and \"parameters_rmse\" for each of the top_models inside the</p> <code>dict</code> <p>results[\"top_models\"] list.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def augment_results(\n    self,\n    results: dict,\n    models: List[dict],\n) -&gt; dict:\n    \"\"\"\n    Computes the RMSE for the top models in the results dictionary.\n\n    Args:\n        results: The dictionary containing the results to augment.\n        models: A list of dictionaries describing the performance of expressions using the base ranking function.\n            Keyword expr contains the expression, error contains the error of the expression. The list is sorted\n            by error.\n\n    Returns:\n        The augmented results dictionary. The results dictionary contains an additional key \"best_expr_rmse\" with the\n        RMSE of the best expression, and keys \"rmse\" and \"parameters_rmse\" for each of the top_models inside the\n        results[\"top_models\"] list.\n    \"\"\"\n    expr = models[0][\"expr\"]\n    error = self.evaluator.evaluate_expr(expr)\n    results[\"best_expr_rmse\"] = error\n    for model in results[\"top_models\"]:\n        error = self.evaluator.evaluate_expr(model[\"expr\"])\n        model[\"rmse\"] = error\n        model[\"parameters_rmse\"] = self.evaluator.models[\"\".join(model[\"expr\"])][\n            \"parameters\"\n        ]\n    return results\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.RMSE.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the RMSE augmenter.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <code>name</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the RMSE augmenter.\n\n    Args:\n        base_path: Used to save the data of the evaluator to disk.\n        name: Used to save the data of the evaluator to disk.\n\n    Returns:\n        A dictionary containing the necessary information to recreate the augmenter.\n    \"\"\"\n    return {\"type\": \"RMSE\", \"evaluator\": self.evaluator.to_dict(base_path, name+\"_RMSE_augmenter\")}\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.RMSE.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; RMSE\n</code></pre> <p>Creates an instance of the RMSE augmenter from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>A dictionary mapping augmenter names to their classes.</p> <code>None</code> <p>Returns:</p> Type Description <code>RMSE</code> <p>An instance of the RMSE augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"RMSE\":\n    \"\"\"\n    Creates an instance of the RMSE augmenter from a dictionary.\n\n    Args:\n        data: A dictionary containing the necessary information to recreate the augmenter.\n        augmenter_map: A dictionary mapping augmenter names to their classes.\n\n    Returns:\n        An instance of the RMSE augmenter.\n    \"\"\"\n    evaluator = SR_evaluator.from_dict(data[\"evaluator\"], augmenter_map=augmenter_map)\n    return RMSE(evaluator)\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.BED","title":"BED","text":"<pre><code>BED(evaluator: SR_evaluator)\n</code></pre> <p>               Bases: <code>ResultAugmenter</code></p> <p>Computes BED for the top models in the results dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>SR_evaluator</code> <p>The evaluator used to evaluate the models. This evaluator must be initialized with ranking_function = \"bed\"</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If the evaluator is not initialized with ranking_function = \"bed\".</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def __init__(self, evaluator: SR_evaluator):  # noqa: F821\n    \"\"\"\n    Computes BED for the top models in the results dictionary.\n\n    Args:\n        evaluator: The evaluator used to evaluate the models. This evaluator must be initialized with\n            ranking_function = \"bed\"\n\n    Raises:\n        Exception: If the evaluator is not initialized with ranking_function = \"bed\".\n    \"\"\"\n    super().__init__()\n    self.evaluator = evaluator\n    if self.evaluator.ranking_function != \"bed\":\n        raise Exception(\n            \"[BED augmenter] Ranking function of the evaluator must be set to 'bed' to compute BED.\"\n        )\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.BED.augment_results","title":"augment_results","text":"<pre><code>augment_results(results: dict, models: List[dict]) -&gt; dict\n</code></pre> <p>Computes BED for the top models in the results dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict</code> <p>The dictionary containing the results to augment.</p> required <code>models</code> <code>List[dict]</code> <p>A list of dictionaries describing the performance of expressions using the base ranking function. Keyword expr contains the expression, error contains the error of the expression. The list is sorted by error.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The augmented results dictionary. The results dictionary contains an additional key \"best_expr_bed\" with</p> <code>dict</code> <p>BED of the best expression, and key \"bed\" for each of the top_models inside the results[\"top_models\"] list.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def augment_results(\n    self,\n    results: dict,\n    models: List[dict],\n) -&gt; dict:\n    \"\"\"\n    Computes BED for the top models in the results dictionary.\n\n    Args:\n        results: The dictionary containing the results to augment.\n        models: A list of dictionaries describing the performance of expressions using the base ranking function.\n            Keyword expr contains the expression, error contains the error of the expression. The list is sorted\n            by error.\n\n    Returns:\n        The augmented results dictionary. The results dictionary contains an additional key \"best_expr_bed\" with\n        BED of the best expression, and key \"bed\" for each of the top_models inside the results[\"top_models\"] list.\n    \"\"\"\n    expr = models[0][\"expr\"]\n    error = self.evaluator.evaluate_expr(expr)\n    results[\"best_expr_bed\"] = error\n    for model in results[\"top_models\"]:\n        model[\"bed\"] = self.evaluator.evaluate_expr(model[\"expr\"])\n    return results\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.BED.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the BED augmenter.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <code>name</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the BED augmenter.\n\n    Args:\n        base_path: Used to save the data of the evaluator to disk.\n        name: Used to save the data of the evaluator to disk.\n\n    Returns:\n        A dictionary containing the necessary information to recreate the augmenter.\n    \"\"\"\n    return {\"type\": \"BED\", \"evaluator\": self.evaluator.to_dict(base_path, name+\"_BED_augmenter\")}\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.BED.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; BED\n</code></pre> <p>Creates an instance of the BED augmenter from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>A dictionary mapping augmenter names to their classes.</p> <code>None</code> <p>Returns:</p> Type Description <code>BED</code> <p>An instance of the BED augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"BED\":\n    \"\"\"\n    Creates an instance of the BED augmenter from a dictionary.\n\n    Args:\n        data: A dictionary containing the necessary information to recreate the augmenter.\n        augmenter_map: A dictionary mapping augmenter names to their classes.\n\n    Returns:\n        An instance of the BED augmenter.\n    \"\"\"\n    evaluator = SR_evaluator.from_dict(data[\"evaluator\"], augmenter_map=augmenter_map)\n    return BED(evaluator)\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.R2","title":"R2","text":"<pre><code>R2(evaluator: SR_evaluator)\n</code></pre> <p>               Bases: <code>ResultAugmenter</code></p> <p>Computes the R^2 for the top models in the results dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>SR_evaluator</code> <p>The evaluator used to evaluate the models (e.g., evaluator defined with test set data). This evaluator must be initialized with ranking_function = \"rmse\". If you're also using the RMSE augmenter, they the same one can be used for both.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If the evaluator is not initialized with ranking_function = \"rmse\" or if y in the evaluator is None.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def __init__(self, evaluator: SR_evaluator):  # noqa: F821\n    \"\"\"\n    Computes the R^2 for the top models in the results dictionary.\n\n    Args:\n        evaluator: The evaluator used to evaluate the models (e.g., evaluator defined with test set data). This\n            evaluator must be initialized with ranking_function = \"rmse\". If you're also using the RMSE augmenter,\n            they the same one can be used for both.\n\n    Raises:\n        Exception: If the evaluator is not initialized with ranking_function = \"rmse\" or if y in the evaluator is None.\n    \"\"\"\n    super().__init__()\n    self.evaluator = evaluator\n    if self.evaluator.ranking_function != \"rmse\":\n        raise Exception(\n            \"[R2 augmenter] Ranking function of the evaluator must be set to 'rmse' to compute R^2.\"\n        )\n    if self.evaluator.y is None:\n        raise Exception(\n            \"[R2 augmenter] y in the evaluator must not be None to compute R^2.\"\n        )\n    self.ss_tot = np.sum((self.evaluator.y - np.mean(self.evaluator.y)) ** 2)\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.R2.augment_results","title":"augment_results","text":"<pre><code>augment_results(results: dict, models: List[dict]) -&gt; dict\n</code></pre> <p>Computes the R^2 for the top models in the results dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict</code> <p>The dictionary containing the results to augment.</p> required <code>models</code> <code>List[dict]</code> <p>A list of dictionaries describing the performance of expressions using the base ranking function. Keyword expr contains the expression, error contains the error of the expression. The list is sorted by error.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The augmented results dictionary. The results dictionary contains an additional key \"best_expr_r^2\" with the</p> <code>dict</code> <p>R^2 of the best expression, and keys \"r^2\" and \"parameters_r^2\" for each of the top_models inside the</p> <code>dict</code> <p>results[\"top_models\"] list.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def augment_results(\n    self,\n    results: dict,\n    models: List[dict],\n) -&gt; dict:\n    \"\"\"\n    Computes the R^2 for the top models in the results dictionary.\n\n    Args:\n        results: The dictionary containing the results to augment.\n        models: A list of dictionaries describing the performance of expressions using the base ranking function.\n            Keyword expr contains the expression, error contains the error of the expression. The list is sorted\n            by error.\n\n    Returns:\n        The augmented results dictionary. The results dictionary contains an additional key \"best_expr_r^2\" with the\n        R^2 of the best expression, and keys \"r^2\" and \"parameters_r^2\" for each of the top_models inside the\n        results[\"top_models\"] list.\n    \"\"\"\n    results[\"best_expr_r^2\"] = self._compute_r2(models[0])\n    for model in results[\"top_models\"]:\n        r2 = self._compute_r2(model)\n        model[\"r^2\"] = r2\n        model[\"parameters_r^2\"] = (\n            self.evaluator.models[\"\".join(model[\"expr\"])][\"parameters\"]\n            if \"parameters\" in self.evaluator.models[\"\".join(model[\"expr\"])]\n            else \"\"\n        )\n    return results\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.R2.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the R2 augmenter.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <code>name</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the R2 augmenter.\n\n    Args:\n        base_path: Used to save the data of the evaluator to disk.\n        name: Used to save the data of the evaluator to disk.\n\n    Returns:\n        A dictionary containing the necessary information to recreate the augmenter.\n    \"\"\"\n    return {\"type\": \"R2\", \"evaluator\": self.evaluator.to_dict(base_path, name+\"_R2_augmenter\")}\n</code></pre>"},{"location":"references/evaluation/result_augmentation/#SRToolkit.evaluation.result_augmentation.R2.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; R2\n</code></pre> <p>Creates an instance of the R2 augmenter from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>A dictionary mapping augmenter names to their classes.</p> <code>None</code> <p>Returns:</p> Type Description <code>R2</code> <p>An instance of the R2 augmenter.</p> Source code in <code>SRToolkit/evaluation/result_augmentation.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"R2\":\n    \"\"\"\n    Creates an instance of the R2 augmenter from a dictionary.\n\n    Args:\n        data: A dictionary containing the necessary information to recreate the augmenter.\n        augmenter_map: A dictionary mapping augmenter names to their classes.\n\n    Returns:\n        An instance of the R2 augmenter.\n    \"\"\"\n    evaluator = SR_evaluator.from_dict(data[\"evaluator\"], augmenter_map=augmenter_map)\n    return R2(evaluator)\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/","title":"SR Evaluator","text":""},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator","title":"SRToolkit.evaluation.sr_evaluator","text":"<p>This module contains the SR_evaluator class, which is used for evaluating symbolic regression approaches. Additionally, the generic ResultAugmenter class is defined here to avoid circular imports.</p>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.ResultAugmenter","title":"ResultAugmenter","text":"<pre><code>ResultAugmenter()\n</code></pre> <p>Generic class that defines the interface for result augmentation. For examples, see the implementations of this class at SRToolkit.evaluation.result_augmentation.py.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Generic class that defines the interface for result augmentation. For examples, see the implementations of\n    this class at SRToolkit.evaluation.result_augmentation.py.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.ResultAugmenter.augment_results","title":"augment_results","text":"<pre><code>augment_results(results: dict, models: List[dict]) -&gt; dict\n</code></pre> <p>Augments the results dictionary with additional information. The model variable contains all models, for only top models, results[\"top_models\"] should be used.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>dict</code> <p>The dictionary containing the results to augment.</p> required <code>models</code> <code>List[dict]</code> <p>A list of dictionaries describing the performance of expressions using the base ranking function. Keyword expr contains the expression, error contains the error of the expression. The list is sorted by error.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The augmented results dictionary.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def augment_results(\n    self,\n    results: dict,\n    models: List[dict],\n) -&gt; dict:\n    \"\"\"\n    Augments the results dictionary with additional information. The model variable contains all models, for only\n    top models, results[\"top_models\"] should be used.\n\n    Args:\n        results: The dictionary containing the results to augment.\n        models: A list of dictionaries describing the performance of expressions using the base ranking function.\n            Keyword expr contains the expression, error contains the error of the expression. The list is sorted\n            by error.\n\n    Returns:\n        The augmented results dictionary.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.ResultAugmenter.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Transforms the augmenter into a dictionary. This is used for saving the augmenter to disk.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>The base path used for saving the data inside the augmenter, if needed.</p> required <code>name</code> <code>str</code> <p>The name/identifier used by the augmenter for saving.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the augmenter.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Transforms the augmenter into a dictionary. This is used for saving the augmenter to disk.\n\n    Args:\n        base_path: The base path used for saving the data inside the augmenter, if needed.\n        name: The name/identifier used by the augmenter for saving.\n\n    Returns:\n        A dictionary containing the necessary information to recreate the augmenter.\n    \"\"\"\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.ResultAugmenter.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; ResultAugmenter\n</code></pre> <p>Creates an instance of the ResultAugmenter class from the dictionary with the relevant data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>the dictionary containing the data needed to recreate the augmenter.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>A dictionary mapping augmenter names to their classes.</p> <code>None</code> <p>Returns:</p> Type Description <code>ResultAugmenter</code> <p>An instance of the ResultAugmenter class with the same configuration as in the data dictionary.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"ResultAugmenter\":\n    \"\"\"\n    Creates an instance of the ResultAugmenter class from the dictionary with the relevant data.\n\n    Args:\n        data: the dictionary containing the data needed to recreate the augmenter.\n        augmenter_map: A dictionary mapping augmenter names to their classes.\n\n    Returns:\n        An instance of the ResultAugmenter class with the same configuration as in the data dictionary.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.SR_evaluator","title":"SR_evaluator","text":"<pre><code>SR_evaluator(X: ndarray, y: Optional[ndarray] = None, symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(), max_evaluations: int = -1, success_threshold: Optional[float] = None, ranking_function: str = 'rmse', ground_truth: Optional[Union[List[str], Node, ndarray]] = None, result_augmenters: Optional[List[ResultAugmenter]] = None, seed: Optional[int] = None, metadata: Optional[dict] = None, **kwargs)\n</code></pre> <p>Initializes an instance of the SR_evaluator class. This class is used for evaluating symbolic regression approaches.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; print(rmse &lt; 1e-6)\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data to be used in parameter estimation for variables. We assume that X is a 2D array with shape (n_samples, n_features).</p> required <code>y</code> <code>Optional[ndarray]</code> <p>The target values to be used in parameter estimation.</p> <code>None</code> <code>max_evaluations</code> <code>int</code> <p>The maximum number of expressions to evaluate. Default is -1, which means no limit.</p> <code>-1</code> <code>success_threshold</code> <code>Optional[float]</code> <p>The threshold used for determining whether an expression is considered successful. If None, the threshold is set to 1e-7 for RMSE and calculated automatically for BED. For BED we calculate this value by evaluating the distance of ground truth to itself 100 times and setting the threshold to np.max(distances)*1.1. For this calculation to be helpful, ground_truth must be provided as a list of tokens or SRToolkit.utils.Node object.</p> <code>None</code> <code>metadata</code> <code>Optional[dict]</code> <p>An optional dictionary containing metadata about this evaluation. This could include information such as the dataset used, the model used, seed, etc.</p> <code>None</code> <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use.</p> <code>default_symbols()</code> <code>ranking_function</code> <code>str</code> <p>The function used for ranking the expressions and fitting parameters if needed. Currently, \"rmse\" and \"bed\" are supported. Default is \"rmse\".</p> <code>'rmse'</code> <code>ground_truth</code> <code>Optional[Union[List[str], Node, ndarray]]</code> <p>The ground truth for the BED evaluation. This should be a list of tokens, a Node object, or a numpy array representing behavior (see SRToolkit.utils.create_behavior_matrix for more details).</p> <code>None</code> <code>result_augmenters</code> <code>Optional[List[ResultAugmenter]]</code> <p>Optional list of objects that augment the results returned by the \"get_results\" function. For example, SRToolkit.evaluation.result_augmentation.ExpressionSimplifier simplifies the evaluated expressions. Possible augmenters can be found in SRToolkit.evaluation.result_augmentation.py or customly defined by inheriting from SRToolkit.evaluation.result_augmentation.ResultAugmenter class.</p> <code>None</code> <code>seed</code> <code>Optional[int]</code> <p>The seed to use for random number generation.</p> <code>None</code> <p>Other Parameters:</p> Name Type Description <code>method</code> <code>str</code> <p>The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested. Default is \"L-BFGS-B\".</p> <code>tol</code> <code>float</code> <p>The tolerance for termination. Default is 1e-6.</p> <code>gtol</code> <code>float</code> <p>The tolerance for the gradient norm. Default is 1e-3.</p> <code>max_iter</code> <code>int</code> <p>The maximum number of iterations. Default is 100.</p> <code>constant_bounds</code> <code>Tuple[float, float]</code> <p>A tuple of two elements, specifying the lower and upper bounds for the constant values. Default is (-5, 5).</p> <code>initialization</code> <code>str</code> <p>The method to use for initializing the constant values. Currently, only \"random\" and \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\" creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".</p> <code>max_constants</code> <code>int</code> <p>The maximum number of constants allowed in the expression. Default is 8.</p> <code>max_expr_length</code> <code>int</code> <p>The maximum length of the expression. Default is -1 (no limit).</p> <code>num_points_sampled</code> <code>int</code> <p>The number of points to sample when estimating the behavior of an expression. Default is 64. If num_points_sampled==-1, then the number of points sampled is equal to the number of points in the dataset.</p> <code>bed_X</code> <code>Optional[ndarray]</code> <p>Points used for BED evaluation. If None and domain_bounds are given, points are sampled from the domain. If None and domain_bounds are not givem, points are randomly selected from X. Default is None.</p> <code>num_consts_sampled</code> <code>int</code> <p>Number of constants sampled for BED evaluation. Default is 32.</p> <code>domain_bounds</code> <code>Optional[List[Tuple[float, float]]]</code> <p>Bounds for the domain to be used if bed_X is None to sample random points. Default is None.</p> <p>Attributes:</p> Name Type Description <code>models</code> <p>A dictionary containing the results of previously evaluated expressions.</p> <code>invalid</code> <p>A list containing the expressions that could not be evaluated.</p> <code>ground_truth</code> <p>The ground truth we are trying to find.</p> <code>gt_behavior</code> <p>The behavior matrix for the ground truth that is used when BED is chosen as the ranking function.</p> <code>max_evaluations</code> <p>The maximum number of expressions to evaluate.</p> <code>bed_evaluation_parameters</code> <p>A dictionary containing parameters used for BED evaluation.</p> <code>metadata</code> <p>An optional dictionary containing metadata about this evaluation. This could include information such as the dataset used, the model used, seed, etc.</p> <code>symbol_library</code> <p>The symbol library to use.</p> <code>total_evaluations</code> <p>The number of times the \"evaluate_expr\" function was called.</p> <code>seed</code> <p>The seed to use for random number generation.</p> <code>parameter_estimator</code> <p>An instance of the ParameterEstimator class used for parameter estimation.</p> <code>ranking_function</code> <p>The function used for ranking the expressions and fitting parameters if needed.</p> <code>success_threshold</code> <p>The threshold used for determining whether an expression is considered successful.</p> <code>result_augmenters</code> <p>A list of SRToolkit.evaluation.result_augmentation.ResultAugmenter objects that augment the results returned by the get_results.</p> <p>Functions:</p> Name Description <code>evaluate_expr</code> <p>Evaluates an expression in infix notation and stores the result in memory to prevent re-evaluation.</p> <code>get_results</code> <p>Returns the results of the evaluation.</p> Notes <p>Determining if two expressions are equivalent is undecidable. Furthermore, random sampling, parameter fitting, and numerical errors all make it hard to determine whether we found the correct expression. Because of this, the success threshold is only a proxy for determining the success of an expression. We recommend checking the best performing expression manually for a better indication of success.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def __init__(\n    self,\n    X: np.ndarray,\n    y: Optional[np.ndarray] = None,\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n    max_evaluations: int = -1,\n    success_threshold: Optional[float] = None,\n    ranking_function: str = \"rmse\",\n    ground_truth: Optional[Union[List[str], Node, np.ndarray]] = None,\n    result_augmenters: Optional[List[ResultAugmenter]] = None,\n    seed: Optional[int] = None,\n    metadata: Optional[dict] = None,\n    **kwargs,\n):\n    \"\"\"\n    Initializes an instance of the SR_evaluator class. This class is used for evaluating symbolic regression approaches.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; print(rmse &lt; 1e-6)\n        True\n\n    Args:\n        X: The input data to be used in parameter estimation for variables. We assume that X is a 2D array with\n            shape (n_samples, n_features).\n        y: The target values to be used in parameter estimation.\n        max_evaluations: The maximum number of expressions to evaluate. Default is -1, which means no limit.\n        success_threshold: The threshold used for determining whether an expression is considered successful. If\n            None, the threshold is set to 1e-7 for RMSE and calculated automatically for BED. For BED we calculate\n            this value by evaluating the distance of ground truth to itself 100 times and setting the threshold to\n            np.max(distances)*1.1. For this calculation to be helpful, ground_truth must be provided as a list of\n            tokens or SRToolkit.utils.Node object.\n        metadata: An optional dictionary containing metadata about this evaluation. This could include information\n            such as the dataset used, the model used, seed, etc.\n        symbol_library: The symbol library to use.\n        ranking_function: The function used for ranking the expressions and fitting parameters if needed.\n            Currently, \"rmse\" and \"bed\" are supported. Default is \"rmse\".\n        ground_truth: The ground truth for the BED evaluation. This should be a list of tokens, a Node object, or a\n            numpy array representing behavior (see SRToolkit.utils.create_behavior_matrix for more details).\n        result_augmenters: Optional list of objects that augment the results returned by the \"get_results\" function.\n            For example, SRToolkit.evaluation.result_augmentation.ExpressionSimplifier simplifies the evaluated\n            expressions. Possible augmenters can be found in SRToolkit.evaluation.result_augmentation.py or customly\n            defined by inheriting from SRToolkit.evaluation.result_augmentation.ResultAugmenter class.\n        seed: The seed to use for random number generation.\n\n    Keyword Arguments:\n        method (str): The method to be used for minimization. Currently, only \"L-BFGS-B\" is supported/tested.\n            Default is \"L-BFGS-B\".\n        tol (float): The tolerance for termination. Default is 1e-6.\n        gtol (float): The tolerance for the gradient norm. Default is 1e-3.\n        max_iter (int): The maximum number of iterations. Default is 100.\n        constant_bounds (Tuple[float, float]): A tuple of two elements, specifying the lower and upper bounds for\n            the constant values. Default is (-5, 5).\n        initialization (str): The method to use for initializing the constant values. Currently, only \"random\" and\n            \"mean\" are supported. \"random\" creates a vector with random values sampled within the bounds. \"mean\"\n            creates a vector where all values are calculated as (lower_bound + upper_bound)/2. Default is \"random\".\n        max_constants (int): The maximum number of constants allowed in the expression. Default is 8.\n        max_expr_length (int): The maximum length of the expression. Default is -1 (no limit).\n        num_points_sampled (int): The number of points to sample when estimating the behavior of an expression.\n            Default is 64. If num_points_sampled==-1, then the number of points sampled is equal to the number of\n            points in the dataset.\n        bed_X (Optional[np.ndarray]): Points used for BED evaluation. If None and domain_bounds are given, points\n            are sampled from the domain. If None and domain_bounds are not givem, points are randomly selected\n            from X. Default is None.\n        num_consts_sampled (int): Number of constants sampled for BED evaluation. Default is 32.\n        domain_bounds (Optional[List[Tuple[float, float]]]): Bounds for the domain to be used if bed_X is None to\n            sample random points. Default is None.\n\n    Attributes:\n        models: A dictionary containing the results of previously evaluated expressions.\n        invalid: A list containing the expressions that could not be evaluated.\n        ground_truth: The ground truth we are trying to find.\n        gt_behavior: The behavior matrix for the ground truth that is used when BED is chosen as the ranking function.\n        max_evaluations: The maximum number of expressions to evaluate.\n        bed_evaluation_parameters: A dictionary containing parameters used for BED evaluation.\n        metadata: An optional dictionary containing metadata about this evaluation. This could include information\n            such as the dataset used, the model used, seed, etc.\n        symbol_library: The symbol library to use.\n        total_evaluations: The number of times the \"evaluate_expr\" function was called.\n        seed: The seed to use for random number generation.\n        parameter_estimator: An instance of the ParameterEstimator class used for parameter estimation.\n        ranking_function: The function used for ranking the expressions and fitting parameters if needed.\n        success_threshold: The threshold used for determining whether an expression is considered successful.\n        result_augmenters: A list of SRToolkit.evaluation.result_augmentation.ResultAugmenter objects that augment\n            the results returned by the get_results.\n\n    Methods:\n        evaluate_expr(expr): Evaluates an expression in infix notation and stores the result in memory to prevent re-evaluation.\n        get_results(top_k): Returns the results of the evaluation.\n\n    Notes:\n        Determining if two expressions are equivalent is undecidable. Furthermore, random sampling, parameter\n        fitting, and numerical errors all make it hard to determine whether we found the correct expression.\n        Because of this, the success threshold is only a proxy for determining the success of an expression.\n        We recommend checking the best performing expression manually for a better indication of success.\n    \"\"\"\n    self.kwargs = kwargs\n    self.models = dict()\n    self.invalid = list()\n    self.success_threshold = success_threshold\n    self.metadata = metadata\n    self.ground_truth = ground_truth\n    self.gt_behavior = None\n    self.bed_evaluation_parameters = {\n        \"bed_X\": None,\n        \"num_consts_sampled\": 32,\n        \"num_points_sampled\": 64,\n        \"domain_bounds\": None,\n        \"constant_bounds\": (-5, 5),\n    }\n    if kwargs:\n        for k in self.bed_evaluation_parameters.keys():\n            if k in kwargs:\n                self.bed_evaluation_parameters[k] = kwargs[k]\n    if self.bed_evaluation_parameters[\"num_points_sampled\"] == -1:\n        self.bed_evaluation_parameters[\"num_points_sampled\"] = X.shape[0]\n\n    self.symbol_library = symbol_library\n    self.max_evaluations = max_evaluations\n    self.total_evaluations = 0\n    self.seed = seed\n    if seed is not None:\n        np.random.seed(seed)\n\n    if ranking_function not in [\"rmse\", \"bed\"]:\n        print(\n            f\"Warning: ranking_function {ranking_function} not supported. Using rmse instead.\"\n        )\n        ranking_function = \"rmse\"\n    self.ranking_function = ranking_function\n\n    self.result_augmenters = []\n    if result_augmenters is not None:\n        for ra in result_augmenters:\n            if not isinstance(ra, ResultAugmenter):\n                print(\n                    f\"Warning: result_augmenter {ra} is not an instance of ResultAugmenter. Skipping.\"\n                )\n            else:\n                self.result_augmenters.append(ra)\n\n    if ranking_function == \"rmse\":\n        if y is None:\n            raise ValueError(\n                \"Target values must be provided for RMSE ranking function.\"\n            )\n        self.parameter_estimator = ParameterEstimator(\n            X, y, symbol_library=symbol_library, seed=seed, **kwargs\n        )\n\n        if self.success_threshold is None:\n            self.success_threshold = 1e-7\n\n    elif ranking_function == \"bed\":\n        if ground_truth is None:\n            raise ValueError(\n                \"Ground truth must be provided for bed ranking function. The ground truth must be \"\n                \"provided as a list of tokens, a Node object, or a numpy array representing behavior. \"\n                \"The behavior matrix is a matrix representing the distribution of outputs of an \"\n                \"expression with free parameters at different points in the domain. This matrix \"\n                \"should be of size (num_points_sampled, num_consts_sampled). See \"\n                \"SRToolkit.utils.create_behavior_matrix for more details.\"\n            )\n        else:\n            if self.bed_evaluation_parameters[\"bed_X\"] is None:\n                if self.bed_evaluation_parameters[\"domain_bounds\"] is not None:\n                    db = self.bed_evaluation_parameters[\"domain_bounds\"]\n                    interval_length = np.array([ub - lb for (lb, ub) in db])\n                    lower_bound = np.array([lb for (lb, ub) in db])\n                    lho = LatinHypercube(\n                        len(db), optimization=\"random-cd\", seed=seed\n                    )\n                    self.bed_evaluation_parameters[\"bed_X\"] = (\n                        lho.random(\n                            self.bed_evaluation_parameters[\"num_points_sampled\"]\n                        )\n                        * interval_length\n                        + lower_bound\n                    )\n                else:\n                    indices = np.random.choice(\n                        X.shape[0],\n                        size=self.bed_evaluation_parameters[\"num_points_sampled\"],\n                    )\n                    self.bed_evaluation_parameters[\"bed_X\"] = X[indices, :]\n\n        if isinstance(ground_truth, (list, Node)):\n            self.gt_behavior = create_behavior_matrix(\n                ground_truth,\n                self.bed_evaluation_parameters[\"bed_X\"],\n                num_consts_sampled=self.bed_evaluation_parameters[\n                    \"num_consts_sampled\"\n                ],\n                consts_bounds=self.bed_evaluation_parameters[\"constant_bounds\"],\n                symbol_library=self.symbol_library,\n                seed=self.seed,\n            )\n        elif isinstance(ground_truth, np.ndarray):\n            self.gt_behavior = ground_truth\n        else:\n            raise ValueError(\n                \"Ground truth must be provided as a list of tokens, a Node object, or a numpy array representing behavior.\"\n            )\n\n        if self.success_threshold is None:\n            distances = [\n                bed(\n                    self.ground_truth,\n                    self.gt_behavior,\n                    self.bed_evaluation_parameters[\"bed_X\"],\n                    num_consts_sampled=self.bed_evaluation_parameters[\n                        \"num_consts_sampled\"\n                    ],\n                    num_points_sampled=self.bed_evaluation_parameters[\n                        \"num_points_sampled\"\n                    ],\n                    domain_bounds=self.bed_evaluation_parameters[\"domain_bounds\"],\n                    consts_bounds=self.bed_evaluation_parameters[\"constant_bounds\"],\n                    symbol_library=self.symbol_library,\n                )\n                for i in range(100)\n            ]\n            self.success_threshold = np.max(distances) * 1.1\n\n    self.X = X\n    self.y = y\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.SR_evaluator.evaluate_expr","title":"evaluate_expr","text":"<pre><code>evaluate_expr(expr: Union[List[str], Node], simplify_expr: bool = False, verbose: int = 0) -&gt; float\n</code></pre> <p>Evaluates an expression in infix notation and stores the result in memory to prevent re-evaluation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; print(rmse &lt; 1e-6)\nTrue\n&gt;&gt;&gt; X = np.array([[0, 1], [0, 2], [0, 3]])\n&gt;&gt;&gt; y = np.array([2, 3, 4])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"+\", \"C\" \"*\", \"C\", \"+\", \"X_0\", \"*\", \"X_1\", \"/\", \"X_0\"], simplify_expr=True)\n&gt;&gt;&gt; print(rmse &lt; 1e-6)\nTrue\n&gt;&gt;&gt; list(se.models.keys())[0]\n'C+X_1'\n&gt;&gt;&gt; print(0.99 &lt; se.models[\"C+X_1\"][\"parameters\"][0] &lt; 1.01)\nTrue\n&gt;&gt;&gt; # Evaluating invalid expression returns nan and adds it to invalid list\n&gt;&gt;&gt; se.evaluate_expr([\"C\", \"*\", \"X_1\", \"X_0\"])\nnan\n&gt;&gt;&gt; se.invalid\n['C*X_1X_0']\n&gt;&gt;&gt; X = np.random.rand(10, 2) - 0.5\n&gt;&gt;&gt; gt = [\"X_0\", \"+\", \"C\"]\n&gt;&gt;&gt; se = SR_evaluator(X, ground_truth=gt, ranking_function=\"bed\")\n&gt;&gt;&gt; se.evaluate_expr([\"C\", \"+\", \"X_1\"]) &lt; 1\nTrue\n&gt;&gt;&gt; # When evaluating using BED as the ranking function, the error depends on the scale of output of the\n&gt;&gt;&gt; # ground truth. Because of stochasticity of BED, error might be high even when expressions match exactly.\n&gt;&gt;&gt; se.evaluate_expr([\"C\", \"+\", \"X_0\"]) &lt; 0.2\nTrue\n&gt;&gt;&gt; # X can also be sampled from a domain by providing domain_bounds\n&gt;&gt;&gt; se = SR_evaluator(X, ground_truth=gt, ranking_function=\"bed\", domain_bounds=[(-1, 1), (-1, 1)])\n&gt;&gt;&gt; se.evaluate_expr([\"C\", \"+\", \"X_0\"]) &lt; 0.2\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[List[str], Node]</code> <p>An expression. This should be an istance of the SRToolkit.utils.expression_tree.Node class or a list   of tokens in the infix notation.</p> required <code>simplify_expr</code> <code>bool</code> <p>If True, simplifies the expression using SymPy before evaluating it. This typically slows down            evaluation. We recommend simplifying only the best expressions when getting results using            the get_results method.</p> <code>False</code> <code>verbose</code> <code>int</code> <p>When 0, no additional output is printed, when 1, prints the expression being evaluated, RMSE, and      estimated parameters, and when 2, also prints numpy errors produced during evaluation.</p> <code>0</code> <p>Returns:</p> Type Description <code>float</code> <p>The root-mean-square error of the expression.</p> <p>Warns:</p> Type Description <code>Maximum number of evaluations reached</code> <p>If the maximum number of evaluations has been reached, a warning is printed and np.nan is returned.</p> Notes <p>If the expression has already been evaluated, its stored value is returned instead of re-evaluating the expression. When the maximum number of evaluations has been reached, a warning is printed and np.nan is returned.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def evaluate_expr(\n    self,\n    expr: Union[List[str], Node],\n    simplify_expr: bool = False,\n    verbose: int = 0,\n) -&gt; float:\n    \"\"\"\n    Evaluates an expression in infix notation and stores the result in\n    memory to prevent re-evaluation.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; print(rmse &lt; 1e-6)\n        True\n        &gt;&gt;&gt; X = np.array([[0, 1], [0, 2], [0, 3]])\n        &gt;&gt;&gt; y = np.array([2, 3, 4])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"+\", \"C\" \"*\", \"C\", \"+\", \"X_0\", \"*\", \"X_1\", \"/\", \"X_0\"], simplify_expr=True)\n        &gt;&gt;&gt; print(rmse &lt; 1e-6)\n        True\n        &gt;&gt;&gt; list(se.models.keys())[0]\n        'C+X_1'\n        &gt;&gt;&gt; print(0.99 &lt; se.models[\"C+X_1\"][\"parameters\"][0] &lt; 1.01)\n        True\n        &gt;&gt;&gt; # Evaluating invalid expression returns nan and adds it to invalid list\n        &gt;&gt;&gt; se.evaluate_expr([\"C\", \"*\", \"X_1\", \"X_0\"])\n        nan\n        &gt;&gt;&gt; se.invalid\n        ['C*X_1X_0']\n        &gt;&gt;&gt; X = np.random.rand(10, 2) - 0.5\n        &gt;&gt;&gt; gt = [\"X_0\", \"+\", \"C\"]\n        &gt;&gt;&gt; se = SR_evaluator(X, ground_truth=gt, ranking_function=\"bed\")\n        &gt;&gt;&gt; se.evaluate_expr([\"C\", \"+\", \"X_1\"]) &lt; 1\n        True\n        &gt;&gt;&gt; # When evaluating using BED as the ranking function, the error depends on the scale of output of the\n        &gt;&gt;&gt; # ground truth. Because of stochasticity of BED, error might be high even when expressions match exactly.\n        &gt;&gt;&gt; se.evaluate_expr([\"C\", \"+\", \"X_0\"]) &lt; 0.2\n        True\n        &gt;&gt;&gt; # X can also be sampled from a domain by providing domain_bounds\n        &gt;&gt;&gt; se = SR_evaluator(X, ground_truth=gt, ranking_function=\"bed\", domain_bounds=[(-1, 1), (-1, 1)])\n        &gt;&gt;&gt; se.evaluate_expr([\"C\", \"+\", \"X_0\"]) &lt; 0.2\n        True\n\n    Args:\n        expr: An expression. This should be an istance of the SRToolkit.utils.expression_tree.Node class or a list\n              of tokens in the infix notation.\n        simplify_expr: If True, simplifies the expression using SymPy before evaluating it. This typically slows down\n                       evaluation. We recommend simplifying only the best expressions when getting results using\n                       the get_results method.\n        verbose: When 0, no additional output is printed, when 1, prints the expression being evaluated, RMSE, and\n                 estimated parameters, and when 2, also prints numpy errors produced during evaluation.\n\n    Returns:\n        The root-mean-square error of the expression.\n\n    Warnings:\n        Maximum number of evaluations reached: If the maximum number of evaluations has been reached, a warning is printed and np.nan is returned.\n\n    Notes:\n        If the expression has already been evaluated, its stored value is returned instead of re-evaluating the expression.\n        When the maximum number of evaluations has been reached, a warning is printed and np.nan is returned.\n    \"\"\"\n    self.total_evaluations += 1\n\n    if 0 &lt;= self.max_evaluations &lt; self.total_evaluations:\n        warnings.warn(\n            f\"Maximum number of evaluations ({self.max_evaluations}) reached. Stopping evaluation.\"\n        )\n        return np.nan\n    else:\n        if simplify_expr:\n            try:\n                expr = simplify(expr, self.symbol_library)\n            except Exception as e:\n                if isinstance(expr, Node):\n                    expr_list = expr.to_list(symbol_library=self.symbol_library)\n                else:\n                    expr_list = expr\n                print(\n                    f\"Unable to simplify: {''.join(expr_list)}, problems with subexpression {e}\"\n                )\n\n        if isinstance(expr, Node):\n            expr_list = expr.to_list(symbol_library=self.symbol_library)\n        else:\n            expr_list = expr\n\n        expr_str = \"\".join(expr_list)\n        if expr_str in self.models:\n            if verbose &gt; 0:\n                print(f\"Already evaluated {expr_str}\")\n            return self.models[expr_str][\"error\"]\n\n        else:\n            if self.ranking_function == \"rmse\":\n                try:\n                    with (\n                        np.errstate(\n                            divide=\"ignore\",\n                            invalid=\"ignore\",\n                            over=\"ignore\",\n                            under=\"ignore\",\n                        )\n                        if verbose &lt; 2\n                        else nullcontext()\n                    ):\n                        error, parameters = (\n                            self.parameter_estimator.estimate_parameters(expr)\n                        )\n\n                    if verbose &gt; 0:\n                        if parameters.size &gt; 0:\n                            parameter_string = f\" Best parameters found are [{', '.join([str(round(p, 3)) for p in parameters])}]\"\n                        else:\n                            parameter_string = \"\"\n                        print(\n                            f\"Evaluated expression {expr_str} with RMSE: {error}.\"\n                            + parameter_string\n                        )\n\n                except Exception as e:\n                    if verbose &gt; 0:\n                        print(f\"Error evaluating expression {expr_str}: {e}\")\n\n                    self.invalid.append(expr_str)\n                    error, parameters = np.nan, np.array([])\n\n                self.models[expr_str] = {\n                    \"error\": error,\n                    \"parameters\": parameters,\n                    \"expr\": expr_list,\n                }\n\n            elif self.ranking_function == \"bed\":\n                try:\n                    with (\n                        np.errstate(\n                            divide=\"ignore\",\n                            invalid=\"ignore\",\n                            over=\"ignore\",\n                            under=\"ignore\",\n                        )\n                        if verbose &lt; 2\n                        else nullcontext()\n                    ):\n                        error = bed(\n                            expr,\n                            self.gt_behavior,\n                            self.bed_evaluation_parameters[\"bed_X\"],\n                            num_consts_sampled=self.bed_evaluation_parameters[\n                                \"num_consts_sampled\"\n                            ],\n                            num_points_sampled=self.bed_evaluation_parameters[\n                                \"num_points_sampled\"\n                            ],\n                            domain_bounds=self.bed_evaluation_parameters[\n                                \"domain_bounds\"\n                            ],\n                            consts_bounds=self.bed_evaluation_parameters[\n                                \"constant_bounds\"\n                            ],\n                            symbol_library=self.symbol_library,\n                            seed=self.seed,\n                        )\n\n                        if verbose &gt; 0:\n                            print(\n                                f\"Evaluated expression {expr_str} with BED: {error}.\"\n                            )\n\n                except Exception as e:\n                    if verbose &gt; 0:\n                        print(f\"Error evaluating expression {expr_str}: {e}\")\n\n                    self.invalid.append(expr_str)\n                    error = np.nan\n\n                self.models[expr_str] = {\n                    \"error\": error,\n                    \"expr\": expr_list,\n                }\n\n            else:\n                raise ValueError(\n                    f\"Ranking function {self.ranking_function} not supported.\"\n                )\n\n            return error\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.SR_evaluator.get_results","title":"get_results","text":"<pre><code>get_results(approach_name: str = '', top_k: int = 20, results: SR_results = None) -&gt; SR_results\n</code></pre> <p>Returns the results of the equation discovery/symbolic regression process/evaluation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; results = se.get_results(top_k=1)\n&gt;&gt;&gt; print(results[0][\"num_evaluated\"])\n1\n&gt;&gt;&gt; print(results[0][\"evaluation_calls\"])\n1\n&gt;&gt;&gt; print(results[0][\"best_expr\"])\nC*X_1-X_0\n&gt;&gt;&gt; print(results[0][\"min_error\"] &lt; 1e-6)\nTrue\n&gt;&gt;&gt; print(1.99 &lt; results[0][\"top_models\"][0][\"parameters\"][0] &lt; 2.01)\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>approach_name</code> <code>str</code> <p>The name of the approach used to discover the equations.</p> <code>''</code> <code>top_k</code> <code>int</code> <p>The number of top results to include in the output. If <code>top_k</code> is greater than the number of evaluated expressions, all evaluated expressions are included. If <code>top_k</code> is less than 0, all evaluated expressions are included.</p> <code>20</code> <code>results</code> <code>SR_results</code> <p>An SR_results object containing the results of the previous evaluation. If provided, the results of the current evaluation are appended to the existing results. Otherwise, a new SR_results object is created.</p> <code>None</code> <p>Returns:</p> Type Description <code>SR_results</code> <p>An instance of the SR_results object with the results of the evaluation.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def get_results(self, approach_name: str = \"\", top_k: int = 20, results: \"SR_results\" = None) -&gt; \"SR_results\":\n    \"\"\"\n    Returns the results of the equation discovery/symbolic regression process/evaluation.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; results = se.get_results(top_k=1)\n        &gt;&gt;&gt; print(results[0][\"num_evaluated\"])\n        1\n        &gt;&gt;&gt; print(results[0][\"evaluation_calls\"])\n        1\n        &gt;&gt;&gt; print(results[0][\"best_expr\"])\n        C*X_1-X_0\n        &gt;&gt;&gt; print(results[0][\"min_error\"] &lt; 1e-6)\n        True\n        &gt;&gt;&gt; print(1.99 &lt; results[0][\"top_models\"][0][\"parameters\"][0] &lt; 2.01)\n        True\n\n    Args:\n        approach_name: The name of the approach used to discover the equations.\n        top_k: The number of top results to include in the output. If `top_k`\n            is greater than the number of evaluated expressions, all\n            evaluated expressions are included. If `top_k` is less than 0,\n            all evaluated expressions are included.\n        results: An SR_results object containing the results of the previous evaluation. If provided,\n            the results of the current evaluation are appended to the existing results. Otherwise, a new SR_results\n            object is created.\n\n    Returns:\n        An instance of the SR_results object with the results of the evaluation.\n    \"\"\"\n    if top_k &gt; len(self.models) or top_k &lt; 0:\n        top_k = len(self.models)\n\n    if results is None:\n        results = SR_results()\n    results.add_results(self.models, top_k, self.result_augmenters, self.total_evaluations, self.success_threshold,\n                        approach_name, self.metadata)\n\n    return results\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.SR_evaluator.to_dict","title":"to_dict","text":"<pre><code>to_dict(base_path: str, name: str) -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the SR_evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <code>name</code> <code>str</code> <p>Used to save the data of the evaluator to disk.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the necessary information to recreate the evaluator from disk.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def to_dict(self, base_path: str, name: str) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the SR_evaluator.\n\n    Args:\n        base_path: Used to save the data of the evaluator to disk.\n        name: Used to save the data of the evaluator to disk.\n\n    Returns:\n        A dictionary containing the necessary information to recreate the evaluator from disk.\n    \"\"\"\n    output = {\"type\": \"SR_evaluator\",\n              \"metadata\": self.metadata,\n              \"symbol_library\": self.symbol_library.to_dict(),\n              \"max_evaluations\": self.max_evaluations,\n              \"success_threshold\": self.success_threshold,\n              \"ranking_function\": self.ranking_function,\n              \"result_augmenters\": [ra.to_dict(base_path, name) for ra in self.result_augmenters],\n              \"seed\": self.seed,\n              \"kwargs\": self.kwargs}\n\n    if not os.path.isdir(base_path):\n        os.makedirs(base_path)\n\n    X_path = f\"{base_path}/{name}_X.npy\"\n    np.save(X_path, self.X)\n    output[\"X\"] = X_path\n\n    if self.y is not None:\n        y_path = f\"{base_path}/{name}_y.npy\"\n        np.save(y_path, self.y)\n        output[\"y\"] = y_path\n    else:\n        output[\"y\"] = None\n\n    if self.ground_truth is None:\n        output[\"ground_truth\"] = None\n    else:\n        if isinstance(self.ground_truth, list):\n            output[\"ground_truth\"] = self.ground_truth\n        elif isinstance(self.ground_truth, Node):\n            output[\"ground_truth\"] = self.ground_truth.to_list(self.symbol_library)\n        else:\n            gt_path = f\"{base_path}/{name}_gt.npy\"\n            np.save(gt_path, self.ground_truth)\n            output[\"ground_truth\"] = gt_path\n\n    return output\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.SR_evaluator.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; SR_evaluator\n</code></pre> <p>Creates an instance of the SR_evaluator from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>A dictionary containing the necessary information to recreate the evaluator.</p> required <code>augmenter_map</code> <code>Optional[dict]</code> <p>A dictionary mapping the names of the augmenters to the augmenter classes.</p> <code>None</code> <p>Returns:</p> Type Description <code>SR_evaluator</code> <p>An instance of the SR_evaluator.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>if unable to load data for X/y/ground truth data, if result augmenters provided but not the augmenter map or if the result augmentor does not occur in the augmenter map.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>@staticmethod\ndef from_dict(data: dict, augmenter_map: Optional[dict] = None) -&gt; \"SR_evaluator\":\n    \"\"\"\n    Creates an instance of the SR_evaluator from a dictionary.\n\n    Args:\n        data: A dictionary containing the necessary information to recreate the evaluator.\n        augmenter_map: A dictionary mapping the names of the augmenters to the augmenter classes.\n\n    Returns:\n        An instance of the SR_evaluator.\n\n    Raises:\n        Exception: if unable to load data for X/y/ground truth data, if result augmenters provided but not the\n            augmenter map or if the result augmentor does not occur in the augmenter map.\n    \"\"\"\n    try:\n        X = np.load(data[\"X\"])\n\n        if data[\"y\"] is not None:\n            y = np.load(data[\"y\"])\n        else:\n            y = None\n\n        if data[\"ground_truth\"] is None:\n            gt = None\n        else:\n            if isinstance(data[\"ground_truth\"], list):\n                gt = data[\"ground_truth\"]\n            else:\n                gt = np.load(data[\"ground_truth\"])\n    except Exception as e:\n        raise ValueError(f\"[SR_evaluator.from_dict] Unable to load data for X/y/ground truth due to {e}\")\n\n\n    result_augmenters = []\n    for ra_data in data[\"result_augmenters\"]:\n        if augmenter_map is None:\n            raise ValueError(\"[SR_evaluator.from_dict] Argument augmenter_map must be provided when loading \"\n                             \"the dictionary contains result augmenters.\")\n        if ra_data[\"type\"] not in augmenter_map:\n            raise ValueError(f\"[SR_evaluator.from_dict] Result augmenter {ra_data['type']} not found in the \"\n                             f\"augmenter map.\")\n        result_augmenters.append(augmenter_map[ra_data[\"type\"]].from_dict(ra_data, augmenter_map))\n\n    symbol_library = SymbolLibrary.from_dict(data[\"symbol_library\"])\n    return SR_evaluator(X, y=y, ground_truth=gt, symbol_library=symbol_library,\n                        max_evaluations=data[\"max_evaluations\"], success_threshold=data[\"success_threshold\"],\n                        ranking_function=data[\"ranking_function\"], result_augmenters=result_augmenters,\n                        seed=data[\"seed\"], metadata=data[\"metadata\"], **data[\"kwargs\"])\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.SR_results","title":"SR_results","text":"<pre><code>SR_results()\n</code></pre> <p>Initializes an SR_results object. This object stores the results of an equation discovery/symbolic regression experiments.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; results = se.get_results(top_k=1) # Obtain an instance of SR_results\n&gt;&gt;&gt; print(results[0][\"num_evaluated\"])\n1\n&gt;&gt;&gt; print(results[0][\"evaluation_calls\"])\n1\n&gt;&gt;&gt; print(results[0][\"best_expr\"])\nC*X_1-X_0\n&gt;&gt;&gt; print(results[0][\"min_error\"] &lt; 1e-6)\nTrue\n&gt;&gt;&gt; print(1.99 &lt; results[0][\"top_models\"][0][\"parameters\"][0] &lt; 2.01)\nTrue\n</code></pre> <p>Attributes:</p> Name Type Description <code>results</code> <p>A list of dictionaries containing the results of each evaluation.</p> <p>Functions:</p> Name Description <code>add_results</code> <p>Adds the results of an evaluation to the results object. If needed, the results are additionally augmented using the provided result augmenters.</p> <code>print_results</code> <p>Prints the results of the evaluation.</p> <code>__len__</code> <p>Returns the number of results stored in the results object.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes an SR_results object. This object stores the results of an equation discovery/symbolic regression experiments.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; results = se.get_results(top_k=1) # Obtain an instance of SR_results\n        &gt;&gt;&gt; print(results[0][\"num_evaluated\"])\n        1\n        &gt;&gt;&gt; print(results[0][\"evaluation_calls\"])\n        1\n        &gt;&gt;&gt; print(results[0][\"best_expr\"])\n        C*X_1-X_0\n        &gt;&gt;&gt; print(results[0][\"min_error\"] &lt; 1e-6)\n        True\n        &gt;&gt;&gt; print(1.99 &lt; results[0][\"top_models\"][0][\"parameters\"][0] &lt; 2.01)\n        True\n\n    Attributes:\n        results: A list of dictionaries containing the results of each evaluation.\n\n    Methods:\n        add_results: Adds the results of an evaluation to the results object. If needed, the results are\n            additionally augmented using the provided result augmenters.\n        print_results: Prints the results of the evaluation.\n        __len__: Returns the number of results stored in the results object.\n    \"\"\"\n    self.results = list()\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.SR_results.add_results","title":"add_results","text":"<pre><code>add_results(models: Dict[str, dict], top_k: int, result_augmenters: List[ResultAugmenter], total_evaluations: int, success_threshold: Optional[float], approach_name: str, metadata: Optional[dict] = None)\n</code></pre> <p>Adds the results of an evaluation to the results object. If needed, the results are additionally augmented using the provided result augmenters. For an example of how to use this function, look at the SR_evaluator.get_results method.</p> <p>Parameters:</p> Name Type Description Default <code>models</code> <code>Dict[str, dict]</code> <p>A dictionary mapping expressions to their evaluation results.</p> required <code>top_k</code> <code>int</code> <p>The number of top results to include in the output.</p> required <code>result_augmenters</code> <code>List[ResultAugmenter]</code> <p>A list of result augmenters to use for augmenting the results.</p> required <code>total_evaluations</code> <code>int</code> <p>The total number of evaluations performed during the evaluation.</p> required <code>success_threshold</code> <code>Optional[float]</code> <p>The success threshold used to determine whether the evaluation was successful.</p> required <code>approach_name</code> <code>str</code> <p>The name of the approach used to discover the equations.</p> required <code>metadata</code> <code>Optional[dict]</code> <p>A dictionary containing additional metadata about the evaluation.</p> <code>None</code> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def add_results(self, models: Dict[str, dict], top_k: int, result_augmenters: List[ResultAugmenter],\n                total_evaluations: int, success_threshold: Optional[float], approach_name: str,\n                metadata: Optional[dict] = None):\n    \"\"\"\n    Adds the results of an evaluation to the results object. If needed, the results are additionally augmented\n    using the provided result augmenters. For an example of how to use this function, look at the SR_evaluator.get_results method.\n\n    Args:\n        models: A dictionary mapping expressions to their evaluation results.\n        top_k: The number of top results to include in the output.\n        result_augmenters: A list of result augmenters to use for augmenting the results.\n        total_evaluations: The total number of evaluations performed during the evaluation.\n        success_threshold: The success threshold used to determine whether the evaluation was successful.\n        approach_name: The name of the approach used to discover the equations.\n        metadata: A dictionary containing additional metadata about the evaluation.\n    \"\"\"\n    models = list(models.values())\n    best_indices = np.argsort([v[\"error\"] for v in models])\n    models = [models[i] for i in best_indices]\n\n    results_dict = {\n        \"min_error\": models[0][\"error\"],\n        \"best_expr\": \"\".join(models[0][\"expr\"]),\n        \"num_evaluated\": len(models),\n        \"evaluation_calls\": total_evaluations,\n        \"top_models\": list(),\n        \"metadata\": metadata,\n        \"all_models\": models,\n        \"approach_name\": approach_name\n    }\n\n    # Determine success based on the predefined success threshold\n    if (\n            success_threshold is not None\n            and results_dict[\"min_error\"] &lt; success_threshold\n    ):\n        results_dict[\"success\"] = True\n    else:\n        results_dict[\"success\"] = False\n\n    for model in models[:top_k]:\n        m = {\"expr\": model[\"expr\"], \"error\": model[\"error\"]}\n        if \"parameters\" in model:\n            m[\"parameters\"] = model[\"parameters\"]\n\n        results_dict[\"top_models\"].append(m)\n\n    for augmenter in result_augmenters:\n        try:\n            results_dict = augmenter.augment_results(results_dict, models)\n        except Exception as e:\n            print(\n                f\"Error augmenting results, skipping current augmentor because of the following error: {e}\"\n            )\n\n    self.results.append(results_dict)\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.SR_results.print_results","title":"print_results","text":"<pre><code>print_results(experiment_number: Optional[int] = None, detailed: bool = False)\n</code></pre> <p>Prints the results of the SR_evaluator. Specifically, prints the minimum error, the best expression, the number of evaluated expressions, the number of times the \"evaluate_expr\" function was called, whether the evaluation was successful, and the metadata and the approach name, if present. If detailed is True, prints all the information about the top models.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; results = se.get_results(top_k=1)\n&gt;&gt;&gt; results.print_results()\nExperiment 0:\nBest expression found: C*X_1-X_0\nError: 6.8864915460553005e-09\nNumber of evaluated expressions: 1\nNumber of times evaluate_expr was called: 1\nSuccess: True\n\n-----------------------------------------\n&gt;&gt;&gt; results.print_results(detailed=True, experiment_number=0)\nBest expression found: C*X_1-X_0\nError: 6.8864915460553005e-09\nNumber of evaluated expressions: 1\nNumber of times evaluate_expr was called: 1\nSuccess: True\n\nTop models:\nModel 1 - expr: ['C', '*', 'X_1', '-', 'X_0'], error: 6.8864915460553005e-09, parameters: [2.]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>experiment_number</code> <code>Optional[int]</code> <p>Number of the experiment you want to print the results for. If None, prints the results for all experiments.</p> <code>None</code> <code>detailed</code> <code>bool</code> <p>If True, prints all the information about the top models.</p> <code>False</code> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def print_results(self, experiment_number: Optional[int] = None, detailed: bool = False):\n    r\"\"\"\n    Prints the results of the SR_evaluator. Specifically, prints the minimum error, the best expression,\n    the number of evaluated expressions, the number of times the \"evaluate_expr\" function was called, whether\n    the evaluation was successful, and the metadata and the approach name, if present. If detailed is True, prints\n    all the information about the top models.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; results = se.get_results(top_k=1)\n        &gt;&gt;&gt; results.print_results()\n        Experiment 0:\n        Best expression found: C*X_1-X_0\n        Error: 6.8864915460553005e-09\n        Number of evaluated expressions: 1\n        Number of times evaluate_expr was called: 1\n        Success: True\n        &lt;BLANKLINE&gt;\n        -----------------------------------------\n        &gt;&gt;&gt; results.print_results(detailed=True, experiment_number=0)\n        Best expression found: C*X_1-X_0\n        Error: 6.8864915460553005e-09\n        Number of evaluated expressions: 1\n        Number of times evaluate_expr was called: 1\n        Success: True\n        &lt;BLANKLINE&gt;\n        Top models:\n        Model 1 - expr: ['C', '*', 'X_1', '-', 'X_0'], error: 6.8864915460553005e-09, parameters: [2.]\n        &lt;BLANKLINE&gt;\n\n    Args:\n        experiment_number: Number of the experiment you want to print the results for. If None, prints the results for all experiments.\n        detailed: If True, prints all the information about the top models.\n\n    \"\"\"\n    if experiment_number is None:\n        for i, result in enumerate(self.results):\n            print(f\"Experiment {i+1}/{len(self.results)}:\")\n            SR_results._print_result_(result, detailed)\n            print(\"-----------------------------------------\")\n\n    else:\n        assert experiment_number &lt; len(self.results), \"[SR_Results.print_results] experiment number out of bounds\"\n        SR_results._print_result_(self.results[experiment_number], detailed)\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.SR_results.__add__","title":"__add__","text":"<pre><code>__add__(other)\n</code></pre> <p>Returns a new SR_results object that is the concatenation of the current SR_results object with the other SR_results object.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>SR_results object to concatenate with the current SR_results object.</p> required <p>Returns:</p> Type Description <p>The concatenated SR_results objects.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def __add__(self, other):\n    \"\"\"\n    Returns a new SR_results object that is the concatenation of the current SR_results object with the other SR_results object.\n\n    Args:\n        other: SR_results object to concatenate with the current SR_results object.\n\n    Returns:\n        The concatenated SR_results objects.\n    \"\"\"\n    self.results += other.results\n    return self\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.SR_results.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(item)\n</code></pre> <p>Returns the results of the experiment with the given index.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; results = se.get_results(top_k=1)\n&gt;&gt;&gt; result_of_first_experiment = results[0]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>item</code> <p>the index of the experiment.</p> required <p>Returns:</p> Type Description <p>The results of the experiment with the given index.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def __getitem__(self, item):\n    \"\"\"\n    Returns the results of the experiment with the given index.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; results = se.get_results(top_k=1)\n        &gt;&gt;&gt; result_of_first_experiment = results[0]\n\n    Args:\n        item: the index of the experiment.\n\n    Returns:\n        The results of the experiment with the given index.\n\n    \"\"\"\n    assert isinstance(item, int), \"[SR_Results.__getitem__] Item must be an integer.\"\n    assert 0 &lt;= item &lt; len(self.results), \"[SR_Results.__getitem__] Item out of bounds.\"\n    return self.results[item]\n</code></pre>"},{"location":"references/evaluation/sr_evaluator/#SRToolkit.evaluation.sr_evaluator.SR_results.__len__","title":"__len__","text":"<pre><code>__len__()\n</code></pre> <p>Returns the number of results stored in the results object. Usually, each result corresponds to a single experiment.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n&gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n&gt;&gt;&gt; se = SR_evaluator(X, y)\n&gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n&gt;&gt;&gt; results = se.get_results(top_k=1)\n&gt;&gt;&gt; len(results)\n1\n</code></pre> <p>Returns:</p> Type Description <p>The number of results stored in the results object.</p> Source code in <code>SRToolkit/evaluation/sr_evaluator.py</code> <pre><code>def __len__(self):\n    \"\"\"\n    Returns the number of results stored in the results object. Usually, each result corresponds to a single experiment.\n\n    Examples:\n        &gt;&gt;&gt; X = np.array([[1, 2], [8, 4], [5, 4], [7, 9], ])\n        &gt;&gt;&gt; y = np.array([3, 0, 3, 11])\n        &gt;&gt;&gt; se = SR_evaluator(X, y)\n        &gt;&gt;&gt; rmse = se.evaluate_expr([\"C\", \"*\", \"X_1\", \"-\", \"X_0\"])\n        &gt;&gt;&gt; results = se.get_results(top_k=1)\n        &gt;&gt;&gt; len(results)\n        1\n\n    Returns:\n        The number of results stored in the results object.\n    \"\"\"\n    return len(self.results)\n</code></pre>"},{"location":"references/utils/","title":"Utils Submodule","text":""},{"location":"references/utils/#SRToolkit.utils","title":"SRToolkit.utils","text":"<p>The module containing the <code>utils</code>.</p> <p>The <code>utils</code> module provides a set of utilities used in the package and for expression compilation.</p> <p>Modules:</p> Name Description <code>symbol_library</code> <p>The module containing the symbol library data structure for managing symbols that can occur in expressions and their properties.</p> <code>expression_tree</code> <p>The module containing the expression tree data structure and functions for transforming expressions into trees and back.</p> <code>expression_compiler</code> <p>The module containing functions that transform expressions in the infix notation (represented as lists of tokens) to executable python functions.</p> <code>expression_simplifier</code> <p>The module containing functions that simplify an expression using SymPy</p> <code>expression_generator</code> <p>The module containing helper functions for generating expressions</p> <code>measures</code> <p>The module containing functions for computing various performance measures on expressions</p>"},{"location":"references/utils/#SRToolkit.utils.Node","title":"Node","text":"<pre><code>Node(symbol: str = None, right: Node = None, left: Node = None)\n</code></pre> <p>Initializes a Node object. We assume that nodes containing functions have only one child node, i.e. right is None.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n&gt;&gt;&gt; len(node)\n3\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol string stored in this node.</p> <code>None</code> <code>right</code> <code>Node</code> <p>The right child of this node.</p> <code>None</code> <code>left</code> <code>Node</code> <p>The left child of this node.</p> <code>None</code> <p>Functions:</p> Name Description <code>__len__</code> <p>Returns the number of nodes in the tree rooted at this node.</p> <code>height</code> <p>Returns the height of the tree rooted at this node.</p> <code>__str__</code> <p>Returns a string representation of the tree rooted at this node.</p> <code>to_list</code> <p>str = \"infix\", symbol_library: SymbolLibrary = None): Returns a list representation of the tree rooted at this node.</p> <code>to_latex</code> <p>SymbolLibrary): Returns a LaTeX representation of the tree rooted at this node.</p> <code>__copy__</code> <p>Returns a copy of the expression (tree).</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def __init__(self, symbol: str = None, right: \"Node\" = None, left: \"Node\" = None):\n    \"\"\"\n    Initializes a Node object. We assume that nodes containing functions have only one child node, i.e. right is None.\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n        &gt;&gt;&gt; len(node)\n        3\n\n    Args:\n        symbol: The symbol string stored in this node.\n        right: The right child of this node.\n        left: The left child of this node.\n\n    Methods:\n        __len__(self):\n            Returns the number of nodes in the tree rooted at this node.\n        height(self):\n            Returns the height of the tree rooted at this node.\n        __str__(self):\n            Returns a string representation of the tree rooted at this node.\n        to_list(self, notation: str = \"infix\", symbol_library: SymbolLibrary = None):\n            Returns a list representation of the tree rooted at this node.\n        to_latex(self, symbol_library: SymbolLibrary):\n            Returns a LaTeX representation of the tree rooted at this node.\n        __copy__(self):\n            Returns a copy of the expression (tree).\n\n    \"\"\"\n    self.symbol = symbol\n    self.right = right\n    self.left = left\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.Node.to_list","title":"to_list","text":"<pre><code>to_list(symbol_library: SymbolLibrary = None, notation: str = 'infix') -&gt; List[str]\n</code></pre> <p>Transforms the tree rooted at this node into a list of tokens.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n&gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n['1', '+', 'X_0']\n&gt;&gt;&gt; node.to_list(notation=\"postfix\")\n['1', 'X_0', '+']\n&gt;&gt;&gt; node.to_list(notation=\"prefix\")\n['+', '1', 'X_0']\n&gt;&gt;&gt; node = Node(\"+\", Node(\"*\", Node(\"X_0\"), Node(\"X_1\")), Node(\"1\"))\n&gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n['1', '+', 'X_1', '*', 'X_0']\n&gt;&gt;&gt; node.to_list(notation=\"infix\")\n['1', '+', '(', 'X_1', '*', 'X_0', ')']\n&gt;&gt;&gt; node = Node(\"sin\", None, Node(\"X_0\"))\n&gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n['sin', '(', 'X_0', ')']\n&gt;&gt;&gt; node = Node(\"^2\", None, Node(\"X_0\"))\n&gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n['X_0', '^2']\n&gt;&gt;&gt; node.to_list()\n['(', 'X_0', ')', '^2']\n&gt;&gt;&gt; node = Node(\"*\", Node(\"*\", Node(\"X_0\"), Node(\"X_0\")),  Node(\"X_0\"))\n&gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols(),notation=\"infix\")\n['X_0', '*', '(', 'X_0', '*', 'X_0', ')']\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>notation</code> <code>str</code> <p>The notation to use for the resulting list of tokens. One of \"prefix\", \"postfix\", or \"infix\".</p> <code>'infix'</code> <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use when converting the tree. This library defines the properties of the symbols in the tree.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of tokens representing the tree rooted at this node in the specified notation.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the notation is not one of \"prefix\", \"postfix\", or \"infix\" or if a symbol is not in the symbol library.</p> Notes <p>If the notation is \"infix\" and the symbol library is not provided, then the resulting list of tokens may contain unnecessary parentheses or have other issues.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def to_list(\n    self, symbol_library: SymbolLibrary = None, notation: str = \"infix\"\n) -&gt; List[str]:\n    \"\"\"\n    Transforms the tree rooted at this node into a list of tokens.\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n        &gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n        ['1', '+', 'X_0']\n        &gt;&gt;&gt; node.to_list(notation=\"postfix\")\n        ['1', 'X_0', '+']\n        &gt;&gt;&gt; node.to_list(notation=\"prefix\")\n        ['+', '1', 'X_0']\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"*\", Node(\"X_0\"), Node(\"X_1\")), Node(\"1\"))\n        &gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n        ['1', '+', 'X_1', '*', 'X_0']\n        &gt;&gt;&gt; node.to_list(notation=\"infix\")\n        ['1', '+', '(', 'X_1', '*', 'X_0', ')']\n        &gt;&gt;&gt; node = Node(\"sin\", None, Node(\"X_0\"))\n        &gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n        ['sin', '(', 'X_0', ')']\n        &gt;&gt;&gt; node = Node(\"^2\", None, Node(\"X_0\"))\n        &gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n        ['X_0', '^2']\n        &gt;&gt;&gt; node.to_list()\n        ['(', 'X_0', ')', '^2']\n        &gt;&gt;&gt; node = Node(\"*\", Node(\"*\", Node(\"X_0\"), Node(\"X_0\")),  Node(\"X_0\"))\n        &gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols(),notation=\"infix\")\n        ['X_0', '*', '(', 'X_0', '*', 'X_0', ')']\n\n    Args:\n        notation: The notation to use for the resulting list of tokens. One of \"prefix\", \"postfix\", or \"infix\".\n        symbol_library: The symbol library to use when converting the tree. This library defines the properties of the symbols in the tree.\n\n    Returns:\n        A list of tokens representing the tree rooted at this node in the specified notation.\n\n    Raises:\n         Exception: If the notation is not one of \"prefix\", \"postfix\", or \"infix\" or if a symbol is not in the symbol library.\n\n    Notes:\n        If the notation is \"infix\" and the symbol library is not provided, then the resulting list of tokens may contain unnecessary parentheses or have other issues.\n    \"\"\"\n    left = [] if self.left is None else self.left.to_list(symbol_library, notation)\n    right = (\n        [] if self.right is None else self.right.to_list(symbol_library, notation)\n    )\n\n    if notation == \"prefix\":\n        return [self.symbol] + left + right\n\n    elif notation == \"postfix\":\n        return left + right + [self.symbol]\n\n    elif notation == \"infix\" and symbol_library is None:\n        warnings.warn(\n            \"Symbol library not provided. Generated expression may contain unnecessary parentheses and\"\n            \" have other issues.\"\n        )\n        if self.left is None and self.right is None:\n            return [self.symbol]\n        if self.right is None and self.left is not None:\n            if self.symbol[0] == \"^\":\n                return [\"(\"] + left + [\")\", self.symbol]\n            else:\n                return [self.symbol, \"(\"] + left + [\")\"]\n        else:\n            if len(left) &gt; 1:\n                left = [\"(\"] + left + [\")\"]\n            if len(right) &gt; 1:\n                right = [\"(\"] + right + [\")\"]\n            return left + [self.symbol] + right\n\n    elif notation == \"infix\":\n        if is_float(self.symbol):\n            return [self.symbol]\n        if symbol_library.get_type(self.symbol) in [\"var\", \"const\", \"lit\"]:\n            return [self.symbol]\n        elif symbol_library.get_type(self.symbol) == \"fn\":\n            if symbol_library.get_precedence(self.symbol) &gt; 0:\n                return [self.symbol, \"(\"] + left + [\")\"]\n            else:\n                if len(left) &gt; 1:\n                    left = [\"(\"] + left + [\")\"]\n                return left + [self.symbol]\n        elif symbol_library.get_type(self.symbol) == \"op\":\n            if not is_float(\n                self.left.symbol\n            ) and -1 &lt; symbol_library.get_precedence(\n                self.left.symbol\n            ) &lt;= symbol_library.get_precedence(self.symbol):\n                left = [\"(\"] + left + [\")\"]\n            if not is_float(\n                self.right.symbol\n            ) and -1 &lt; symbol_library.get_precedence(\n                self.right.symbol\n            ) &lt;= symbol_library.get_precedence(self.symbol):\n                right = [\"(\"] + right + [\")\"]\n            return left + [self.symbol] + right\n        else:\n            raise Exception(f\"Invalid symbol type for symbol {self.symbol}.\")\n    else:\n        raise Exception(\n            \"Invalid notation selected. Use 'infix', 'prefix', 'postfix', or leave blank (defaults to 'infix').\"\n        )\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.Node.to_latex","title":"to_latex","text":"<pre><code>to_latex(symbol_library: SymbolLibrary) -&gt; str\n</code></pre> <p>Transforms the tree rooted at this node into a LaTeX expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n&gt;&gt;&gt; node.to_latex(symbol_library=SymbolLibrary.default_symbols())\n'$1 + X_{0}$'\n&gt;&gt;&gt; node = Node(\"+\", Node(\"*\", Node(\"X_0\"), Node(\"X_1\")), Node(\"1\"))\n&gt;&gt;&gt; print(node.to_latex(symbol_library=SymbolLibrary.default_symbols()))\n$1 + X_{1} \\cdot X_{0}$\n&gt;&gt;&gt; node = Node(\"sin\", None, Node(\"X_0\"))\n&gt;&gt;&gt; print(node.to_latex(symbol_library=SymbolLibrary.default_symbols()))\n$\\sin X_{0}$\n&gt;&gt;&gt; node = Node(\"+\", Node(\"*\", Node(\"X_0\"), Node(\"C\")), Node(\"C\"))\n&gt;&gt;&gt; print(node.to_latex(symbol_library=SymbolLibrary.default_symbols()))\n$C_{0} + C_{1} \\cdot X_{0}$\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use when converting the tree. This library defines the properties of the symbols in the tree.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A latex string representing the tree rooted at this node.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the notation is not one of \"prefix\", \"postfix\", or \"infix\" or if a symbol is not in the symbol library.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def to_latex(self, symbol_library: SymbolLibrary) -&gt; str:\n    r\"\"\"\n    Transforms the tree rooted at this node into a LaTeX expression.\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n        &gt;&gt;&gt; node.to_latex(symbol_library=SymbolLibrary.default_symbols())\n        '$1 + X_{0}$'\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"*\", Node(\"X_0\"), Node(\"X_1\")), Node(\"1\"))\n        &gt;&gt;&gt; print(node.to_latex(symbol_library=SymbolLibrary.default_symbols()))\n        $1 + X_{1} \\cdot X_{0}$\n        &gt;&gt;&gt; node = Node(\"sin\", None, Node(\"X_0\"))\n        &gt;&gt;&gt; print(node.to_latex(symbol_library=SymbolLibrary.default_symbols()))\n        $\\sin X_{0}$\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"*\", Node(\"X_0\"), Node(\"C\")), Node(\"C\"))\n        &gt;&gt;&gt; print(node.to_latex(symbol_library=SymbolLibrary.default_symbols()))\n        $C_{0} + C_{1} \\cdot X_{0}$\n\n    Args:\n        symbol_library: The symbol library to use when converting the tree. This library defines the properties of the symbols in the tree.\n\n    Returns:\n        A latex string representing the tree rooted at this node.\n\n    Raises:\n         Exception: If the notation is not one of \"prefix\", \"postfix\", or \"infix\" or if a symbol is not in the symbol library.\n    \"\"\"\n    assert symbol_library is not None, (\n        \"[Node.to_latex] parameter symbol_library should be of type SymbolLibrary\"\n    )\n    return f\"${self.__to_latex_rec(symbol_library)[0]}$\"\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.Node.height","title":"height","text":"<pre><code>height() -&gt; int\n</code></pre> <p>Returns the height of the tree rooted at this node.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n&gt;&gt;&gt; node.height()\n2\n</code></pre> <p>Returns:</p> Type Description <code>int</code> <p>The height of the tree rooted at this node.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def height(self) -&gt; int:\n    \"\"\"\n    Returns the height of the tree rooted at this node.\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n        &gt;&gt;&gt; node.height()\n        2\n\n    Returns:\n        The height of the tree rooted at this node.\n    \"\"\"\n    return 1 + max(\n        (self.left.height() if self.left is not None else 0),\n        (self.right.height() if self.right is not None else 0),\n    )\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.Node.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Returns the number of nodes in the tree rooted at this node.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n&gt;&gt;&gt; len(node)\n3\n</code></pre> <p>Returns:</p> Type Description <code>int</code> <p>The number of nodes in the tree rooted at this node.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Returns the number of nodes in the tree rooted at this node.\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n        &gt;&gt;&gt; len(node)\n        3\n\n    Returns:\n        The number of nodes in the tree rooted at this node.\n    \"\"\"\n    return (\n        1\n        + (len(self.left) if self.left is not None else 0)\n        + (len(self.right) if self.right is not None else 0)\n    )\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.Node.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Returns a string representation of the tree rooted at this node.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n&gt;&gt;&gt; str(node)\n'1+x'\n</code></pre> <p>Returns:</p> Type Description <code>str</code> <p>A string representation of the tree rooted at this node.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Returns a string representation of the tree rooted at this node.\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n        &gt;&gt;&gt; str(node)\n        '1+x'\n\n    Returns:\n        A string representation of the tree rooted at this node.\n    \"\"\"\n    return \"\".join(self.to_list())\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.Node.__copy__","title":"__copy__","text":"<pre><code>__copy__() -&gt; Node\n</code></pre> <p>Creates a copy of the expression (usefull for manipulating expressions).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n&gt;&gt;&gt; new_node = copy(node)\n&gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n['1', '+', 'X_0']\n&gt;&gt;&gt; new_node.to_list(symbol_library=SymbolLibrary.default_symbols())\n['1', '+', 'X_0']\n&gt;&gt;&gt; node == node\nTrue\n&gt;&gt;&gt; node == new_node\nFalse\n</code></pre> <p>Returns:</p> Type Description <code>Node</code> <p>A copy of the expression (tree).</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def __copy__(self) -&gt; \"Node\":\n    \"\"\"\n    Creates a copy of the expression (usefull for manipulating expressions).\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n        &gt;&gt;&gt; new_node = copy(node)\n        &gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n        ['1', '+', 'X_0']\n        &gt;&gt;&gt; new_node.to_list(symbol_library=SymbolLibrary.default_symbols())\n        ['1', '+', 'X_0']\n        &gt;&gt;&gt; node == node\n        True\n        &gt;&gt;&gt; node == new_node\n        False\n\n    Returns:\n        A copy of the expression (tree).\n    \"\"\"\n    if self.left is not None:\n        left = copy(self.left)\n    else:\n        left = None\n    if self.right is not None:\n        right = copy(self.right)\n    else:\n        right = None\n    return Node(copy(self.symbol), left=left, right=right)\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary","title":"SymbolLibrary","text":"<pre><code>SymbolLibrary(symbols: List[str] = None, num_variables: int = 0, preamble: List[str] = None)\n</code></pre> <p>Initializes an instance of the SymbolLibrary class. This class is used for managing symbols and their properties for other functionality in this package.</p> <p>By default, the library uses the numpy package for inference of operators, functions, and numpy arrays as the data structure for data and constants. If you want to define these symbols using other libraries, you should populate the preamble argument with the import statements for those libraries.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\", \"x\")\n&gt;&gt;&gt; library.get_type(\"x\")\n'var'\n&gt;&gt;&gt; library.get_precedence(\"x\")\n0\n&gt;&gt;&gt; library.get_np_fn(\"x\")\n'x'\n&gt;&gt;&gt; library.remove_symbol(\"x\")\n&gt;&gt;&gt; library = SymbolLibrary.default_symbols()\n&gt;&gt;&gt; # You can also initialize the library with a list of symbols (listed in SymbolLibrary.default_symbols)\n&gt;&gt;&gt; # and the number of variables.\n&gt;&gt;&gt; library2 = SymbolLibrary([\"+\", \"*\", \"sin\"], num_variables=2)\n&gt;&gt;&gt; len(library2)\n5\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>List[str]</code> <p>A list of symbols to be added to the library. If None, the library is initialized with no symbols. Check the SymbolLibrary.default_symbols() function for a list of supported symbols.</p> <code>None</code> <code>num_variables</code> <code>int</code> <p>The number of variables to add to the library. If None, the library is initialized with ] no variables. Variables added this way will be labeled 'X_0', 'X_1', ..., 'X_{num_variables-1}'.</p> <code>0</code> <code>preamble</code> <code>List[str]</code> <p>A list of import statements for libraries used in the preamble of the generated function. If None, the preamble is set to [\"import numpy as np\"].</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>symbols</code> <p>dict A dictionary mapping symbols to their properties (type, precedence, numpy function).</p> <p>Functions:</p> Name Description <code>add_symbol</code> <p>Adds a symbol to the library.</p> <code>remove_symbol</code> <p>Removes a symbol from the library.</p> <code>get_type</code> <p>Retrieves the type of a symbol from the library.</p> <code>get_precedence</code> <p>Returns the precedence of the given symbol.</p> <code>get_np_fn</code> <p>Returns the numpy function corresponding to the given symbol.</p> <code>default_symbols</code> <p>Returns a SymbolLibrary with the default symbols.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def __init__(self, symbols: List[str]=None, num_variables: int = 0, preamble: List[str]=None):\n    \"\"\"\n    Initializes an instance of the SymbolLibrary class. This class is used for managing symbols and their\n    properties for other functionality in this package.\n\n    By default, the library uses the numpy package for inference of operators, functions, and numpy arrays as the\n    data structure for data and constants. If you want to define these symbols using other libraries, you should\n    populate the preamble argument with the import statements for those libraries.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\", \"x\")\n        &gt;&gt;&gt; library.get_type(\"x\")\n        'var'\n        &gt;&gt;&gt; library.get_precedence(\"x\")\n        0\n        &gt;&gt;&gt; library.get_np_fn(\"x\")\n        'x'\n        &gt;&gt;&gt; library.remove_symbol(\"x\")\n        &gt;&gt;&gt; library = SymbolLibrary.default_symbols()\n        &gt;&gt;&gt; # You can also initialize the library with a list of symbols (listed in SymbolLibrary.default_symbols)\n        &gt;&gt;&gt; # and the number of variables.\n        &gt;&gt;&gt; library2 = SymbolLibrary([\"+\", \"*\", \"sin\"], num_variables=2)\n        &gt;&gt;&gt; len(library2)\n        5\n\n    Args:\n        symbols: A list of symbols to be added to the library. If None, the library is initialized with no symbols.\n            Check the SymbolLibrary.default_symbols() function for a list of supported symbols.\n        num_variables: The number of variables to add to the library. If None, the library is initialized with ]\n            no variables. Variables added this way will be labeled 'X_0', 'X_1', ..., 'X_{num_variables-1}'.\n        preamble: A list of import statements for libraries used in the preamble of the generated function. If\n            None, the preamble is set to [\"import numpy as np\"].\n\n    Attributes:\n        symbols : dict\n            A dictionary mapping symbols to their properties (type, precedence, numpy function).\n\n    Methods:\n        add_symbol(symbol, symbol_type, precedence, np_fn):\n            Adds a symbol to the library.\n        remove_symbol(symbol):\n            Removes a symbol from the library.\n        get_type(symbol):\n            Retrieves the type of a symbol from the library.\n        get_precedence(symbol):\n            Returns the precedence of the given symbol.\n        get_np_fn(symbol):\n            Returns the numpy function corresponding to the given symbol.\n        default_symbols():\n            Returns a SymbolLibrary with the default symbols.\n    \"\"\"\n    if preamble is None:\n        self.preamble = [\"import numpy as np\"]\n    else:\n        self.preamble = preamble\n\n    if symbols is None and num_variables == 0:\n        self.symbols = dict()\n        self.num_variables = 0\n    else:\n        if symbols is None:\n            symbols = []\n\n        self.symbols = SymbolLibrary.from_symbol_list(symbols, num_variables).symbols\n        self.num_variables = num_variables\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.add_symbol","title":"add_symbol","text":"<pre><code>add_symbol(symbol: str, symbol_type: str, precedence: int, np_fn: str, latex_str: str = None)\n</code></pre> <p>Adds a symbol to the library. A symbol should have a type, precedence, a numpy function, and a LaTeX template associated with it. Type \"op\" should be used for symbols operating on two operands, \"fn\" for symbols operating on one operand, \"lit\" for constants with a known value (such as pi or e), \"const\" for constants/parameters without a value that need to be optimized, and \"var\" for variables whose values are provided as input data.</p> <p>We recommend you use a single token of \"const\" type as using multiple might lead to more work, errors, and less readability.</p> <p>If the argument 'latex_str' is ommited, a default LaTeX template will be generated for the symbol. In case of symbol 'symb', the default template will be '{} \\text{symb} {}' for an operator,'\\text{symb} {}' for a function, and '\\text{symb}' otherwise.</p> <p>For example, look at the default_symbols function for the SymbolLibrary class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; library.add_symbol(\"sin\", \"fn\", 5, \"np.sin({})\", r\"\\sin {}\")\n&gt;&gt;&gt; library.add_symbol(\"C\", \"const\", 5, \"C[{}]\", r\"c_{}\")\n&gt;&gt;&gt; library.add_symbol(\"X_0\", \"var\", 5, \"X[:, 0]\", r\"X_0\")\n&gt;&gt;&gt; library.add_symbol(\"pi\", \"lit\", 5, \"np.pi\", r\"\\pi\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol to be added to the library.</p> required <code>symbol_type</code> <code>str</code> <p>The type of the symbol, one of \"op\" (operator), \"fn\" (function), \"lit\" (literal), \"const\" (constant), or \"var\" (variable).</p> required <code>precedence</code> <code>int</code> <p>The precedence of the symbol, used to determine the order of operations.</p> required <code>np_fn</code> <code>str</code> <p>A string representing the numpy function associated with this symbol.</p> required <code>latex_str</code> <code>str</code> <p>A string that represents how the symbol is written in LaTeX</p> <code>None</code> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def add_symbol(\n    self,\n    symbol: str,\n    symbol_type: str,\n    precedence: int,\n    np_fn: str,\n    latex_str: str = None,\n):\n    r\"\"\"\n    Adds a symbol to the library. A symbol should have a type, precedence, a numpy function, and a LaTeX template associated with it.\n    Type \"op\" should be used for symbols operating on two operands, \"fn\" for symbols operating on one operand,\n    \"lit\" for constants with a known value (such as pi or e), \"const\" for constants/parameters without a value that\n    need to be optimized, and \"var\" for variables whose values are provided as input data.\n\n    We recommend you use a single token of \"const\" type as using multiple might lead to more work, errors, and less\n    readability.\n\n    If the argument 'latex_str' is ommited, a default LaTeX template will be generated for the symbol. In case of symbol 'symb', the default template\n    will be '{} \\text{symb} {}' for an operator,'\\text{symb} {}' for a function, and '\\text{symb}' otherwise.\n\n    For example, look at the default_symbols function for the SymbolLibrary class.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; library.add_symbol(\"sin\", \"fn\", 5, \"np.sin({})\", r\"\\sin {}\")\n        &gt;&gt;&gt; library.add_symbol(\"C\", \"const\", 5, \"C[{}]\", r\"c_{}\")\n        &gt;&gt;&gt; library.add_symbol(\"X_0\", \"var\", 5, \"X[:, 0]\", r\"X_0\")\n        &gt;&gt;&gt; library.add_symbol(\"pi\", \"lit\", 5, \"np.pi\", r\"\\pi\")\n\n    Args:\n        symbol: The symbol to be added to the library.\n        symbol_type: The type of the symbol, one of \"op\" (operator), \"fn\" (function), \"lit\" (literal), \"const\" (constant), or \"var\" (variable).\n        precedence: The precedence of the symbol, used to determine the order of operations.\n        np_fn: A string representing the numpy function associated with this symbol.\n        latex_str: A string that represents how the symbol is written in LaTeX\n    \"\"\"\n    if latex_str is None:\n        if symbol_type == \"var\":\n            latex_str = f\"{{}} \\text{{{symbol}}} {{}}\"\n        elif symbol_type == \"fn\":\n            latex_str = f\"\\text{{{symbol}}} {{}}\"\n        else:\n            latex_str = f\"\\text{{{symbol}}}\"\n\n    if symbol_type == \"var\" and (np_fn is None or np_fn == \"\"):\n        np_fn = \"X[:, {}]\".format(self.num_variables)\n\n    if symbol_type == \"var\":\n        self.num_variables += 1\n\n    self.symbols[symbol] = {\n        \"symbol\": symbol,\n        \"type\": symbol_type,\n        \"precedence\": precedence,\n        \"np_fn\": np_fn,\n        \"latex_str\": latex_str,\n    }\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.remove_symbol","title":"remove_symbol","text":"<pre><code>remove_symbol(symbol: str)\n</code></pre> <p>Removes a symbol from the library.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; len(library.symbols)\n1\n&gt;&gt;&gt; library.remove_symbol(\"x\")\n&gt;&gt;&gt; len(library.symbols)\n0\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol to be removed from the library.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If the symbol does not exist in the library.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def remove_symbol(self, symbol: str):\n    \"\"\"\n    Removes a symbol from the library.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; len(library.symbols)\n        1\n        &gt;&gt;&gt; library.remove_symbol(\"x\")\n        &gt;&gt;&gt; len(library.symbols)\n        0\n\n    Args:\n        symbol: The symbol to be removed from the library.\n\n    Raises:\n        KeyError: If the symbol does not exist in the library.\n    \"\"\"\n    del self.symbols[symbol]\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.get_type","title":"get_type","text":"<pre><code>get_type(symbol: str) -&gt; str\n</code></pre> <p>Retrieves the type of a symbol from the library.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; library.get_type(\"x\")\n'var'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol whose type is to be retrieved.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The type of the symbol if it exists in the library, otherwise an empty string.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def get_type(self, symbol: str) -&gt; str:\n    \"\"\"\n    Retrieves the type of a symbol from the library.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; library.get_type(\"x\")\n        'var'\n\n    Args:\n        symbol: The symbol whose type is to be retrieved.\n\n    Returns:\n        The type of the symbol if it exists in the library, otherwise an empty string.\n    \"\"\"\n    if symbol in self.symbols:\n        return self.symbols[symbol][\"type\"]\n    else:\n        return \"\"\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.get_precedence","title":"get_precedence","text":"<pre><code>get_precedence(symbol: str) -&gt; int\n</code></pre> <p>Retrieves the precedence of the given symbol.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; library.get_precedence(\"x\")\n0\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol whose precedence is to be retrieved.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The precedence of the symbol if it exists in the library, otherwise -1.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def get_precedence(self, symbol: str) -&gt; int:\n    \"\"\"\n    Retrieves the precedence of the given symbol.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; library.get_precedence(\"x\")\n        0\n\n    Args:\n        symbol: The symbol whose precedence is to be retrieved.\n\n    Returns:\n        The precedence of the symbol if it exists in the library, otherwise -1.\n    \"\"\"\n    if symbol in self.symbols:\n        return self.symbols[symbol][\"precedence\"]\n    else:\n        return -1\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.get_np_fn","title":"get_np_fn","text":"<pre><code>get_np_fn(symbol: str) -&gt; str\n</code></pre> <p>Returns the numpy function corresponding to the given symbol.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; library.get_np_fn(\"x\")\n'x'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol to look up.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The numpy function corresponding to the given symbol, or an empty string if the symbol was not found.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def get_np_fn(self, symbol: str) -&gt; str:\n    \"\"\"\n    Returns the numpy function corresponding to the given symbol.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; library.get_np_fn(\"x\")\n        'x'\n\n    Args:\n        symbol: The symbol to look up.\n\n    Returns:\n        The numpy function corresponding to the given symbol, or an empty string if the symbol was not found.\n    \"\"\"\n    if symbol in self.symbols:\n        return self.symbols[symbol][\"np_fn\"]\n    else:\n        return \"\"\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.get_latex_str","title":"get_latex_str","text":"<pre><code>get_latex_str(symbol: str) -&gt; str\n</code></pre> <p>Returns the LaTeX template for the corresponding symbol.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\", \"test\")\n&gt;&gt;&gt; library.get_latex_str(\"x\")\n'test'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol to look up.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The LaTeX template for the corresponding symbol, or an empty string if the symbol was not found.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def get_latex_str(self, symbol: str) -&gt; str:\n    \"\"\"\n    Returns the LaTeX template for the corresponding symbol.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\", \"test\")\n        &gt;&gt;&gt; library.get_latex_str(\"x\")\n        'test'\n\n    Args:\n        symbol: The symbol to look up.\n\n    Returns:\n        The LaTeX template for the corresponding symbol, or an empty string if the symbol was not found.\n    \"\"\"\n    if symbol in self.symbols:\n        return self.symbols[symbol][\"latex_str\"]\n    else:\n        return \"\"\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.get_symbols_of_type","title":"get_symbols_of_type","text":"<pre><code>get_symbols_of_type(symbol_type: str) -&gt; List[str]\n</code></pre> <p>Returns a list of symbols with the requested type (\"op\", \"fn\", \"var\", \"const\", \"lit\").</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; library.add_symbol(\"y\", \"var\", 0, \"y\")\n&gt;&gt;&gt; library.get_symbols_of_type(\"var\")\n['x', 'y']\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol_type</code> <code>str</code> <p>Type of symbols you want to get.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of symbols with the requested type</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def get_symbols_of_type(self, symbol_type: str) -&gt; List[str]:\n    \"\"\"\n    Returns a list of symbols with the requested type (\"op\", \"fn\", \"var\", \"const\", \"lit\").\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; library.add_symbol(\"y\", \"var\", 0, \"y\")\n        &gt;&gt;&gt; library.get_symbols_of_type(\"var\")\n        ['x', 'y']\n\n    Args:\n        symbol_type: Type of symbols you want to get.\n\n    Returns:\n        A list of symbols with the requested type\n    \"\"\"\n    symbols = list()\n    for symbol in self.symbols.keys():\n        if self.get_type(symbol) == symbol_type:\n            symbols.append(symbol)\n\n    return symbols\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.symbols2index","title":"symbols2index","text":"<pre><code>symbols2index() -&gt; Dict[str, int]\n</code></pre> <p>Generates a dictionary mapping symbols to their indices in the symbol list.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; library.add_symbol(\"y\", \"var\", 0, \"y\")\n&gt;&gt;&gt; print(library.symbols2index())\n{'x': 0, 'y': 1}\n&gt;&gt;&gt; library.remove_symbol(\"x\")\n&gt;&gt;&gt; print(library.symbols2index())\n{'y': 0}\n</code></pre> <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>A dictionary mapping symbols to their indices in the symbol list.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def symbols2index(self) -&gt; Dict[str, int]:\n    \"\"\"\n    Generates a dictionary mapping symbols to their indices in the symbol list.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; library.add_symbol(\"y\", \"var\", 0, \"y\")\n        &gt;&gt;&gt; print(library.symbols2index())\n        {'x': 0, 'y': 1}\n        &gt;&gt;&gt; library.remove_symbol(\"x\")\n        &gt;&gt;&gt; print(library.symbols2index())\n        {'y': 0}\n\n    Returns:\n        A dictionary mapping symbols to their indices in the symbol list.\n    \"\"\"\n    return {s: i for i, s in enumerate(self.symbols.keys())}\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.from_symbol_list","title":"from_symbol_list  <code>staticmethod</code>","text":"<pre><code>from_symbol_list(symbols: List[str], num_variables: int = 25) -&gt; SymbolLibrary\n</code></pre> <p>Creates an instance of SymbolLibrary from a list of symbols and number of variables. The list of currently supported symbols (by default) can be seen in the SymbolLibrary.default_symbols() function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary().from_symbol_list([\"+\", \"*\", \"C\"], num_variables=2)\n&gt;&gt;&gt; len(library.symbols)\n5\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>List[str]</code> <p>List of symbols you want.</p> required <code>num_variables</code> <code>int</code> <p>Number of variables you want.</p> <code>25</code> <p>Returns:</p> Type Description <code>SymbolLibrary</code> <p>An instance of SymbolLibrary</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>@staticmethod\ndef from_symbol_list(\n    symbols: List[str], num_variables: int = 25\n) -&gt; \"SymbolLibrary\":\n    \"\"\"\n    Creates an instance of SymbolLibrary from a list of symbols and number of variables. The list of currently\n    supported symbols (by default) can be seen in the SymbolLibrary.default_symbols() function.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary().from_symbol_list([\"+\", \"*\", \"C\"], num_variables=2)\n        &gt;&gt;&gt; len(library.symbols)\n        5\n\n    Args:\n        symbols: List of symbols you want.\n        num_variables: Number of variables you want.\n\n    Returns:\n        An instance of SymbolLibrary\n    \"\"\"\n    variables = [f\"X_{i}\" for i in range(num_variables)]\n    symbols = symbols + variables\n\n    sl = SymbolLibrary.default_symbols(num_variables)\n\n    all_symbols = list(sl.symbols.keys())\n    for symbol in all_symbols:\n        if symbol not in symbols:\n            sl.remove_symbol(symbol)\n\n    return sl\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.default_symbols","title":"default_symbols  <code>staticmethod</code>","text":"<pre><code>default_symbols(num_variables: int = 25) -&gt; SymbolLibrary\n</code></pre> <p>Creates a SymbolLibrary instance populated with default mathematical symbols.</p> <p>This method adds a set of predefined symbols to a SymbolLibrary instance, representing common mathematical operations, functions, constants, and optional variables. The symbols include basic arithmetic operations, trigonometric and exponential functions, and mathematical constants like pi and e.</p> <p>If num_variables is greater than 0, it adds variables labeled 'X_0' to 'X_{num_variables-1}', each  associated with a column in a data array X.</p> <p>By default, we currently support the following symbols: \"+\", \"-\", \"*\", \"/\", \"^\", \"u-\" (unary minus), \"sqrt\", \"sin\", \"cos\", \"exp\", \"tan\", \"arcsin\", \"arccos\", \"arctan\", \"sinh\", \"cosh\", \"tanh\", \"floor\", \"ceil\", \"ln\", \"log\", \"^-1\", \"^2\", \"^3\", \"^4\", \"^5\", \"pi\", \"e\", \"C\" (unknown constant).</p> <p>Notes: The variables in the default_symbols function are added in the predefined order, which is the same order as the columns in the data array X.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary.default_symbols()\n&gt;&gt;&gt; len(library.symbols)\n54\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>num_variables</code> <code>int</code> <p>The number of variables to add to the library (default is 25).</p> <code>25</code> <p>Returns:</p> Type Description <code>SymbolLibrary</code> <p>A SymbolLibrary instance populated with default mathematical symbols.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>@staticmethod\ndef default_symbols(num_variables: int = 25) -&gt; \"SymbolLibrary\":\n    \"\"\"\n    Creates a SymbolLibrary instance populated with default mathematical symbols.\n\n    This method adds a set of predefined symbols to a SymbolLibrary instance,\n    representing common mathematical operations, functions, constants, and optional\n    variables. The symbols include basic arithmetic operations, trigonometric and\n    exponential functions, and mathematical constants like pi and e.\n\n    If num_variables is greater than 0, it adds variables labeled 'X_0' to 'X_{num_variables-1}', each\n     associated with a column in a data array X.\n\n    By default, we currently support the following symbols: \"+\", \"-\", \"*\", \"/\", \"^\", \"u-\" (unary minus), \"sqrt\",\n    \"sin\", \"cos\", \"exp\", \"tan\", \"arcsin\", \"arccos\", \"arctan\", \"sinh\", \"cosh\", \"tanh\", \"floor\", \"ceil\", \"ln\", \"log\",\n    \"^-1\", \"^2\", \"^3\", \"^4\", \"^5\", \"pi\", \"e\", \"C\" (unknown constant).\n\n    Notes: The variables in the default_symbols function are added in the predefined order,\n    which is the same order as the columns in the data array X.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary.default_symbols()\n        &gt;&gt;&gt; len(library.symbols)\n        54\n\n    Args:\n        num_variables: The number of variables to add to the library (default is 25).\n\n    Returns:\n        A SymbolLibrary instance populated with default mathematical symbols.\n    \"\"\"\n    sl = SymbolLibrary()\n    sl.add_symbol(\n        \"+\",\n        symbol_type=\"op\",\n        precedence=0,\n        np_fn=\"{} = {} + {}\",\n        latex_str=r\"{} + {}\",\n    )\n    sl.add_symbol(\n        \"-\",\n        symbol_type=\"op\",\n        precedence=0,\n        np_fn=\"{} = {} - {}\",\n        latex_str=r\"{} - {}\",\n    )\n    sl.add_symbol(\n        \"*\",\n        symbol_type=\"op\",\n        precedence=1,\n        np_fn=\"{} = {} * {}\",\n        latex_str=r\"{} \\cdot {}\",\n    )\n    sl.add_symbol(\n        \"/\",\n        symbol_type=\"op\",\n        precedence=1,\n        np_fn=\"{} = {} / {}\",\n        latex_str=r\"\\frac{{{}}}{{{}}}\",\n    )\n    sl.add_symbol(\n        \"^\",\n        symbol_type=\"op\",\n        precedence=2,\n        np_fn=\"{} = np.power({},{})\",\n        latex_str=r\"{}^{{{}}}\",\n    )\n    sl.add_symbol(\n        \"u-\", symbol_type=\"fn\", precedence=5, np_fn=\"{} = -{}\", latex_str=r\"- {}\"\n    )\n    sl.add_symbol(\n        \"sqrt\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.sqrt({})\",\n        latex_str=r\"\\sqrt {{{}}}\",\n    )\n    sl.add_symbol(\n        \"sin\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.sin({})\",\n        latex_str=r\"\\sin {}\",\n    )\n    sl.add_symbol(\n        \"cos\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.cos({})\",\n        latex_str=r\"\\cos {}\",\n    )\n    sl.add_symbol(\n        \"exp\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.exp({})\",\n        latex_str=r\"e^{{{}}}\",\n    )\n    sl.add_symbol(\n        \"tan\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.tan({})\",\n        latex_str=r\"\\tan {}\",\n    )\n    sl.add_symbol(\n        \"arcsin\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.arcsin({})\",\n        latex_str=r\"\\arcsin {}\",\n    )\n    sl.add_symbol(\n        \"arccos\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.arccos({})\",\n        latex_str=r\"\\arccos {}\",\n    )\n    sl.add_symbol(\n        \"arctan\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.arctan({})\",\n        latex_str=r\"\\arctan {}\",\n    )\n    sl.add_symbol(\n        \"sinh\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.sinh({})\",\n        latex_str=r\"\\sinh {}\",\n    )\n    sl.add_symbol(\n        \"cosh\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.cosh({})\",\n        latex_str=r\"\\cosh {}\",\n    )\n    sl.add_symbol(\n        \"tanh\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.tanh({})\",\n        latex_str=r\"\\tanh {}\",\n    )\n    sl.add_symbol(\n        \"floor\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.floor({})\",\n        latex_str=r\"\\lfloor {} \\rfloor\",\n    )\n    sl.add_symbol(\n        \"ceil\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.ceil({})\",\n        latex_str=r\"\\lceil {} \\rceil\",\n    )\n    sl.add_symbol(\n        \"ln\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.log({})\",\n        latex_str=r\"\\ln {}\",\n    )\n    sl.add_symbol(\n        \"log\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.log10({})\",\n        latex_str=r\"\\log_{{10}} {}\",\n    )\n    sl.add_symbol(\n        \"^-1\",\n        symbol_type=\"fn\",\n        precedence=-1,\n        np_fn=\"{} = 1/{}\",\n        latex_str=r\"{}^{{-1}}\",\n    )\n    sl.add_symbol(\n        \"^2\", symbol_type=\"fn\", precedence=-1, np_fn=\"{} = {}**2\", latex_str=r\"{}^2\"\n    )\n    sl.add_symbol(\n        \"^3\", symbol_type=\"fn\", precedence=-1, np_fn=\"{} = {}**3\", latex_str=r\"{}^3\"\n    )\n    sl.add_symbol(\n        \"^4\", symbol_type=\"fn\", precedence=-1, np_fn=\"{} = {}**4\", latex_str=r\"{}^4\"\n    )\n    sl.add_symbol(\n        \"^5\", symbol_type=\"fn\", precedence=-1, np_fn=\"{} = {}**5\", latex_str=r\"{}^5\"\n    )\n    sl.add_symbol(\n        \"pi\",\n        symbol_type=\"lit\",\n        precedence=5,\n        np_fn=\"np.full(X.shape[0], np.pi)\",\n        latex_str=r\"\\pi\",\n    )\n    sl.add_symbol(\n        \"e\",\n        symbol_type=\"lit\",\n        precedence=5,\n        np_fn=\"np.full(X.shape[0], np.e)\",\n        latex_str=r\"e\",\n    )\n    sl.add_symbol(\n        \"C\",\n        symbol_type=\"const\",\n        precedence=5,\n        np_fn=\"np.full(X.shape[0], C[{}])\",\n        latex_str=r\"C_{{{}}}\",\n    )\n\n    if num_variables &gt; 0:\n        for i in range(num_variables):\n            sl.add_symbol(\n                f\"X_{i}\", \"var\", 5, \"X[:, {}]\".format(i), \"X_{{{}}}\".format(i)\n            )\n\n    return sl\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the SymbolLibrary instance.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the symbol library's data.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the SymbolLibrary instance.\n\n    Returns:\n        A dictionary containing the symbol library's data.\n    \"\"\"\n    return {\"type\": \"SymbolLibrary\",\n            \"symbols\": self.symbols,\n            \"preamble\": self.preamble,\n            \"num_variables\": self.num_variables}\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(d: dict) -&gt; SymbolLibrary\n</code></pre> <p>Creates a SymbolLibrary instance from its dictionary representation.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>the dictionary containing data about the symbol library.</p> required <p>Returns:</p> Type Description <code>SymbolLibrary</code> <p>The SymbolLibrary instance created from the dictionary.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>@staticmethod\ndef from_dict(d: dict) -&gt; \"SymbolLibrary\":\n    \"\"\"\n    Creates a SymbolLibrary instance from its dictionary representation.\n\n    Args:\n        d: the dictionary containing data about the symbol library.\n\n    Returns:\n        The SymbolLibrary instance created from the dictionary.\n    \"\"\"\n    sl = SymbolLibrary()\n    sl.symbols = d[\"symbols\"]\n    sl.preamble = d[\"preamble\"]\n    sl.num_variables = d[\"num_variables\"]\n    return sl\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Returns the number of symbols currently stored in the SymbolLibrary.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary.default_symbols(5)\n&gt;&gt;&gt; len(library)\n34\n&gt;&gt;&gt; library.add_symbol(\"a\", \"lit\", 5, \"a\", \"a\")\n&gt;&gt;&gt; len(library)\n35\n</code></pre> <p>Returns     Number of symbols currently stored in the SymbolLibrary.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Returns the number of symbols currently stored in the SymbolLibrary.\n\n    Examples:\n         &gt;&gt;&gt; library = SymbolLibrary.default_symbols(5)\n         &gt;&gt;&gt; len(library)\n         34\n         &gt;&gt;&gt; library.add_symbol(\"a\", \"lit\", 5, \"a\", \"a\")\n         &gt;&gt;&gt; len(library)\n         35\n\n    Returns\n        Number of symbols currently stored in the SymbolLibrary.\n    \"\"\"\n    return len(self.symbols)\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Returns a string representation of the SymbolLibrary instance.</p> <p>This method provides a comma-separated string of all the symbol keys currently stored in the SymbolLibrary.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\", \"x\")\n&gt;&gt;&gt; str(library)\n'x'\n&gt;&gt;&gt; library.add_symbol(\"sin\", \"fn\", 5, \"{} = np.sin({})\", r\"\\sin {}\")\n&gt;&gt;&gt; str(library)\n'x, sin'\n</code></pre> <p>Returns:</p> Type Description <code>str</code> <p>A string containing all symbols in the library, separated by commas.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def __str__(self) -&gt; str:\n    r\"\"\"\n    Returns a string representation of the SymbolLibrary instance.\n\n    This method provides a comma-separated string of all the symbol keys\n    currently stored in the SymbolLibrary.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\", \"x\")\n        &gt;&gt;&gt; str(library)\n        'x'\n        &gt;&gt;&gt; library.add_symbol(\"sin\", \"fn\", 5, \"{} = np.sin({})\", r\"\\sin {}\")\n        &gt;&gt;&gt; str(library)\n        'x, sin'\n\n    Returns:\n        A string containing all symbols in the library, separated by commas.\n    \"\"\"\n    return \", \".join(self.symbols.keys())\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.SymbolLibrary.__copy__","title":"__copy__","text":"<pre><code>__copy__() -&gt; SymbolLibrary\n</code></pre> <p>Creates a copy of the SymbolLibrary instance.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; old_symbols = SymbolLibrary()\n&gt;&gt;&gt; old_symbols.add_symbol(\"x\", \"var\", 0, \"x\", \"x\")\n&gt;&gt;&gt; print(old_symbols)\nx\n&gt;&gt;&gt; new_symbols = copy.copy(old_symbols)\n&gt;&gt;&gt; new_symbols.add_symbol(\"sin\", \"fn\", 5, \"{} = np.sin({})\", r\"\\sin {}\")\n&gt;&gt;&gt; print(old_symbols)\nx\n&gt;&gt;&gt; print(new_symbols)\nx, sin\n</code></pre> <p>Returns:</p> Type Description <code>SymbolLibrary</code> <p>A copy of the SymbolLibrary instance.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def __copy__(self) -&gt; \"SymbolLibrary\":\n    r\"\"\"\n    Creates a copy of the SymbolLibrary instance.\n\n    Examples:\n        &gt;&gt;&gt; old_symbols = SymbolLibrary()\n        &gt;&gt;&gt; old_symbols.add_symbol(\"x\", \"var\", 0, \"x\", \"x\")\n        &gt;&gt;&gt; print(old_symbols)\n        x\n        &gt;&gt;&gt; new_symbols = copy.copy(old_symbols)\n        &gt;&gt;&gt; new_symbols.add_symbol(\"sin\", \"fn\", 5, \"{} = np.sin({})\", r\"\\sin {}\")\n        &gt;&gt;&gt; print(old_symbols)\n        x\n        &gt;&gt;&gt; print(new_symbols)\n        x, sin\n\n    Returns:\n        A copy of the SymbolLibrary instance.\n    \"\"\"\n    sl = SymbolLibrary()\n    sl.symbols = copy.deepcopy(self.symbols)\n    sl.preamble = self.preamble\n    sl.num_variables = self.num_variables\n    return sl\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.tokens_to_tree","title":"tokens_to_tree","text":"<pre><code>tokens_to_tree(tokens: List[str], sl: SymbolLibrary) -&gt; Node\n</code></pre> <p>Converts a list of tokens to a tree data structure. Throws an exception if the expression is invalid (check syntax and that all symbols are in the symbol library correctly defined).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tree = tokens_to_tree([\"(\", \"X_0\", \"+\", \"X_1\", \")\"], SymbolLibrary.default_symbols())\n&gt;&gt;&gt; len(tree)\n3\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>List[str]</code> <p>The list of tokens to convert.</p> required <code>sl</code> <code>SymbolLibrary</code> <p>The symbol library to use when parsing the tokens.</p> required <p>Returns:</p> Type Description <code>Node</code> <p>The root of the expression tree data structure.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the expression is invalid. Usually this means that a symbol is not in the symbol library or that        there is a syntactic error in the expression.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def tokens_to_tree(tokens: List[str], sl: SymbolLibrary) -&gt; Node:\n    \"\"\"\n    Converts a list of tokens to a tree data structure. Throws an exception if the expression is invalid (check syntax\n    and that all symbols are in the symbol library correctly defined).\n\n    Examples:\n        &gt;&gt;&gt; tree = tokens_to_tree([\"(\", \"X_0\", \"+\", \"X_1\", \")\"], SymbolLibrary.default_symbols())\n        &gt;&gt;&gt; len(tree)\n        3\n\n    Args:\n        tokens: The list of tokens to convert.\n        sl: The symbol library to use when parsing the tokens.\n\n    Returns:\n        The root of the expression tree data structure.\n\n    Raises:\n        Exception: If the expression is invalid. Usually this means that a symbol is not in the symbol library or that\n                   there is a syntactic error in the expression.\n    \"\"\"\n    num_tokens = len([t for t in tokens if t != \"(\" and t != \")\"])\n    expr_str = \"\".join(tokens)\n    tokens = [\"(\"] + tokens + [\")\"]\n    operator_stack = []\n    out_stack = []\n    for token in tokens:\n        if token == \"(\":\n            operator_stack.append(token)\n        elif sl.get_type(token) in [\"var\", \"const\", \"lit\"] or is_float(token):\n            out_stack.append(Node(token))\n        elif sl.get_type(token) == \"fn\":\n            if token[0] == \"^\":\n                out_stack.append(Node(token, left=out_stack.pop()))\n            else:\n                operator_stack.append(token)\n        elif sl.get_type(token) == \"op\":\n            while (\n                len(operator_stack) &gt; 0\n                and operator_stack[-1] != \"(\"\n                and sl.get_precedence(operator_stack[-1]) &gt;= sl.get_precedence(token)\n            ):\n                if sl.get_type(operator_stack[-1]) == \"fn\":\n                    out_stack.append(Node(operator_stack.pop(), left=out_stack.pop()))\n                else:\n                    out_stack.append(\n                        Node(operator_stack.pop(), out_stack.pop(), out_stack.pop())\n                    )\n            operator_stack.append(token)\n        else:\n            if token != \")\":\n                raise Exception(\n                    f'Invalid symbol \"{token}\" in expression {expr_str}. Did you add token \"{token}\" to the symbol library?'\n                )\n\n            while len(operator_stack) &gt; 0 and operator_stack[-1] != \"(\":\n                if sl.get_type(operator_stack[-1]) == \"fn\":\n                    out_stack.append(Node(operator_stack.pop(), left=out_stack.pop()))\n                else:\n                    out_stack.append(\n                        Node(operator_stack.pop(), out_stack.pop(), out_stack.pop())\n                    )\n            operator_stack.pop()\n            if len(operator_stack) &gt; 0 and sl.get_type(operator_stack[-1]) == \"fn\":\n                out_stack.append(Node(operator_stack.pop(), left=out_stack.pop()))\n    if len(out_stack[-1]) == num_tokens:\n        return out_stack[-1]\n    else:\n        raise Exception(f\"Error while parsing expression {expr_str}.\")\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.is_float","title":"is_float","text":"<pre><code>is_float(element: any) -&gt; bool\n</code></pre> <p>Checks if a given element is a float.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_float(1.0)\nTrue\n&gt;&gt;&gt; is_float(\"1.0\")\nTrue\n&gt;&gt;&gt; is_float(\"1\")\nTrue\n&gt;&gt;&gt; is_float(None)\nFalse\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>element</code> <code>any</code> <p>The element to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the element is a float, False otherwise.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def is_float(element: any) -&gt; bool:\n    \"\"\"\n    Checks if a given element is a float.\n\n    Examples:\n        &gt;&gt;&gt; is_float(1.0)\n        True\n        &gt;&gt;&gt; is_float(\"1.0\")\n        True\n        &gt;&gt;&gt; is_float(\"1\")\n        True\n        &gt;&gt;&gt; is_float(None)\n        False\n\n\n    Args:\n        element: The element to check.\n\n    Returns:\n        True if the element is a float, False otherwise.\n    \"\"\"\n    if element is None:\n        return False\n    try:\n        float(element)\n        return True\n    except ValueError:\n        return False\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.expr_to_latex","title":"expr_to_latex","text":"<pre><code>expr_to_latex(expr: Union[Node, List[str]], symbol_library: SymbolLibrary) -&gt; str\n</code></pre> <p>Transforms an expression into a LaTeX string.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; expr_to_latex([\"(\", \"X_0\", \"+\", \"X_1\", \")\"], SymbolLibrary.default_symbols())\n'$X_{0} + X_{1}$'\n&gt;&gt;&gt; expr = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n&gt;&gt;&gt; expr_to_latex(expr, SymbolLibrary.default_symbols())\n'$1 + X_{0}$'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[Node, List[str]]</code> <p>An expression</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A LaTeX string representing the expression.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def expr_to_latex(expr: Union[Node, List[str]], symbol_library: SymbolLibrary) -&gt; str:\n    \"\"\"\n    Transforms an expression into a LaTeX string.\n\n    Examples:\n        &gt;&gt;&gt; expr_to_latex([\"(\", \"X_0\", \"+\", \"X_1\", \")\"], SymbolLibrary.default_symbols())\n        '$X_{0} + X_{1}$'\n        &gt;&gt;&gt; expr = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n        &gt;&gt;&gt; expr_to_latex(expr, SymbolLibrary.default_symbols())\n        '$1 + X_{0}$'\n\n    Args:\n        expr: An expression\n        symbol_library: The symbol library.\n\n    Returns:\n        A LaTeX string representing the expression.\n    \"\"\"\n    try:\n        if isinstance(expr, Node):\n            return expr.to_latex(symbol_library)\n        elif isinstance(expr, list):\n            return tokens_to_tree(expr, symbol_library).to_latex(symbol_library)\n        else:\n            raise Exception(\n                f\"Invalid type for expression {str(expr)}. Should be SRToolkit.utils.Node or a list of tokens.\"\n            )\n    except Exception as e:\n        print(f\"Error while converting expression {str(expr)} to LaTeX: {str(e)}\")\n        return \"\"\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.tree_to_function_rec","title":"tree_to_function_rec","text":"<pre><code>tree_to_function_rec(tree: Node, symbol_library: SymbolLibrary, var_counter: int = 0, const_counter: int = 0) -&gt; Tuple[List[str], str, int, int]\n</code></pre> <p>Recursively converts a parse tree into a string of Python code that can be executed to evaluate the expression represented by the tree. For usage examples, see code for expr_to_executable_function and expr_to_error_function.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>Node</code> <p>The root of the parse tree to convert.</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use when converting the tree. This library defines the properties of the symbols in the tree.</p> required <code>var_counter</code> <code>int</code> <p>The number of variables encountered so far. This is used to create a unique variable name for each variable.</p> <code>0</code> <code>const_counter</code> <code>int</code> <p>The number of constants encountered so far. This is used to select the correct constant value from the constant array.</p> <code>0</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of strings, where each string contains a line of Python code to execute to evaluate the expression represented by the tree.</p> <code>str</code> <p>The name of the variable that represents the output of the expression.</p> <code>int</code> <p>The updated value of <code>var_counter</code>.</p> <code>int</code> <p>The updated value of <code>const_counter</code>.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the parse tree contains an invalid symbol.</p> Notes <p>This function is a helper function for <code>expr_to_executable_function</code> and similar and should not be called directly unless you want to customize the way the expression is defined. For examples, see the code of <code>expr_to_executable_function</code> and <code>expr_to_error_function</code> in this module.</p> Source code in <code>SRToolkit/utils/expression_compiler.py</code> <pre><code>def tree_to_function_rec(\n    tree: Node,\n    symbol_library: SymbolLibrary,\n    var_counter: int = 0,\n    const_counter: int = 0,\n) -&gt; Tuple[List[str], str, int, int]:\n    \"\"\"\n    Recursively converts a parse tree into a string of Python code that can be executed to evaluate the expression\n    represented by the tree. For usage examples, see code for expr_to_executable_function and expr_to_error_function.\n\n    Args:\n        tree: The root of the parse tree to convert.\n        symbol_library: The symbol library to use when converting the tree. This library defines the properties of the symbols in the tree.\n        var_counter: The number of variables encountered so far. This is used to create a unique variable name for each variable.\n        const_counter: The number of constants encountered so far. This is used to select the correct constant value from the constant array.\n\n    Returns:\n        A list of strings, where each string contains a line of Python code to execute to evaluate the expression represented by the tree.\n        The name of the variable that represents the output of the expression.\n        The updated value of `var_counter`.\n        The updated value of `const_counter`.\n\n    Raises:\n        Exception: If the parse tree contains an invalid symbol.\n\n    Notes:\n        This function is a helper function for `expr_to_executable_function` and similar and should not be called directly\n        unless you want to customize the way the expression is defined. For examples, see the code of `expr_to_executable_function` and `expr_to_error_function` in this module.\n    \"\"\"\n    if tree.left is None and tree.right is None:\n        if symbol_library.get_type(tree.symbol) in [\"var\", \"lit\"]:\n            return [], symbol_library.get_np_fn(tree.symbol), var_counter, const_counter\n        elif symbol_library.get_type(tree.symbol) == \"const\":\n            return (\n                [],\n                symbol_library.get_np_fn(tree.symbol).format(const_counter),\n                var_counter,\n                const_counter + 1,\n            )\n        else:\n            if is_float(tree.symbol):\n                return [], tree.symbol, var_counter, const_counter\n            else:\n                raise Exception(\n                    f\"Encountered invalid symbol {tree.symbol} while converting to function.\"\n                )\n\n    elif tree.left is not None and tree.right is None:\n        code, symbol, var_counter, const_counter = tree_to_function_rec(\n            tree.left, symbol_library, var_counter, const_counter\n        )\n        output_symbol = \"y_{}\".format(var_counter)\n        code.append(symbol_library.get_np_fn(tree.symbol).format(output_symbol, symbol))\n        return code, output_symbol, var_counter + 1, const_counter\n\n    else:\n        left_code, left_symbol, var_counter, const_counter = tree_to_function_rec(\n            tree.left, symbol_library, var_counter, const_counter\n        )\n        right_code, right_symbol, var_counter, const_counter = tree_to_function_rec(\n            tree.right, symbol_library, var_counter, const_counter\n        )\n        output_symbol = \"y_{}\".format(var_counter)\n        code = left_code + right_code\n        code.append(\n            symbol_library.get_np_fn(tree.symbol).format(\n                output_symbol, left_symbol, right_symbol\n            )\n        )\n        return code, output_symbol, var_counter + 1, const_counter\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.expr_to_executable_function","title":"expr_to_executable_function","text":"<pre><code>expr_to_executable_function(expr: Union[List[str], Node], symbol_library: SymbolLibrary = SymbolLibrary.default_symbols()) -&gt; Callable[[np.ndarray, np.ndarray], np.ndarray]\n</code></pre> <p>Converts an expression in infix notation to an executable function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; executable_fun = expr_to_executable_function([\"X_0\", \"+\", \"1\"])\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]))\narray([2, 3, 4, 5])\n&gt;&gt;&gt; executable_fun = expr_to_executable_function([\"pi\"])\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([1]))\narray([3.14159265, 3.14159265, 3.14159265, 3.14159265])\n&gt;&gt;&gt; executable_fun = expr_to_executable_function([\"C\"])\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([1]))\narray([1, 1, 1, 1])\n&gt;&gt;&gt; tree = tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1))\n&gt;&gt;&gt; executable_fun = expr_to_executable_function(tree)\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]))\narray([2, 3, 4, 5])\n&gt;&gt;&gt; # In case you need libraries other than numpy for the evaluation of your expressions,\n&gt;&gt;&gt; # you can add them to the preamble in the SymbolLibrary. Here is how a preamble would look like:\n&gt;&gt;&gt; symbol_library = SymbolLibrary.default_symbols(1)\n&gt;&gt;&gt; symbol_library.preamble = [\"import numpy as np\"]\n&gt;&gt;&gt; # Usually this is done when initializing the SymbolLibrary as SymbolLibrary(preamble=preamble)\n&gt;&gt;&gt; executable_fun = expr_to_executable_function(tree, symbol_library)\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]))\narray([2, 3, 4, 5])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[List[str], Node]</code> <p>The expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use. Defaults to SymbolLibrary.default_symbols().</p> <code>default_symbols()</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If expression is not of the right type</p> <p>Returns:</p> Type Description <code>Callable[[ndarray, ndarray], ndarray]</code> <p>An executable function that takes in a 2D array of input values and a 1D array of constant values and returns the output of the expression.</p> Source code in <code>SRToolkit/utils/expression_compiler.py</code> <pre><code>def expr_to_executable_function(\n    expr: Union[List[str], Node],\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n) -&gt; Callable[[np.ndarray, np.ndarray], np.ndarray]:\n    \"\"\"\n    Converts an expression in infix notation to an executable function.\n\n    Examples:\n        &gt;&gt;&gt; executable_fun = expr_to_executable_function([\"X_0\", \"+\", \"1\"])\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]))\n        array([2, 3, 4, 5])\n        &gt;&gt;&gt; executable_fun = expr_to_executable_function([\"pi\"])\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([1]))\n        array([3.14159265, 3.14159265, 3.14159265, 3.14159265])\n        &gt;&gt;&gt; executable_fun = expr_to_executable_function([\"C\"])\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([1]))\n        array([1, 1, 1, 1])\n        &gt;&gt;&gt; tree = tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1))\n        &gt;&gt;&gt; executable_fun = expr_to_executable_function(tree)\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]))\n        array([2, 3, 4, 5])\n        &gt;&gt;&gt; # In case you need libraries other than numpy for the evaluation of your expressions,\n        &gt;&gt;&gt; # you can add them to the preamble in the SymbolLibrary. Here is how a preamble would look like:\n        &gt;&gt;&gt; symbol_library = SymbolLibrary.default_symbols(1)\n        &gt;&gt;&gt; symbol_library.preamble = [\"import numpy as np\"]\n        &gt;&gt;&gt; # Usually this is done when initializing the SymbolLibrary as SymbolLibrary(preamble=preamble)\n        &gt;&gt;&gt; executable_fun = expr_to_executable_function(tree, symbol_library)\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]))\n        array([2, 3, 4, 5])\n\n    Args:\n        expr: The expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        symbol_library: The symbol library to use. Defaults to SymbolLibrary.default_symbols().\n\n    Raises:\n        Exception: If expression is not of the right type\n\n    Returns:\n        An executable function that takes in a 2D array of input values and a 1D array of constant values and returns the output of the expression.\n    \"\"\"\n    if not (isinstance(expr, list) or isinstance(expr, Node)):\n        raise Exception(\n            \"Expression must be given as either a list of tokens or a tree (an instance of the \"\n            \"SRToolkit.utils.expression_tree.Node class)\"\n        )\n\n    if isinstance(expr, list):\n        tree = tokens_to_tree(expr, symbol_library)\n    else:\n        tree = expr\n    code, symbol, var_counter, const_counter = tree_to_function_rec(\n        tree, symbol_library\n    )\n\n    fun_string = \"\\n\".join(symbol_library.preamble) + \"\\ndef _executable_expression_(X, C):\\n\"\n    for c in code:\n        fun_string += \"\\t\" + c + \"\\n\"\n    fun_string += \"\\treturn \" + symbol\n\n    fun_assignment_dict = {}\n    exec(fun_string, globals(), fun_assignment_dict)\n    return fun_assignment_dict[\"_executable_expression_\"]\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.expr_to_error_function","title":"expr_to_error_function","text":"<pre><code>expr_to_error_function(expr: Union[List[str], Node], symbol_library: SymbolLibrary = SymbolLibrary.default_symbols()) -&gt; Callable[[np.ndarray, np.ndarray, np.ndarray], float]\n</code></pre> <p>Converts an expression in infix notation to an executable function that returns the root mean squared error between the output of the expression and the target values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; executable_fun = expr_to_error_function([\"X_0\", \"+\", \"1\"])\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]), np.array([2, 3, 4, 5]))\n0.0\n&gt;&gt;&gt; tree = tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1))\n&gt;&gt;&gt; executable_fun = expr_to_error_function(tree)\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]), np.array([2, 3, 4, 5]))\n0.0\n&gt;&gt;&gt; # In case you need libraries other than numpy for the evaluation of your expressions,\n&gt;&gt;&gt; # you can add them to the preamble in the SymbolLibrary. Here is how a preamble would look like:\n&gt;&gt;&gt; symbol_library = SymbolLibrary.default_symbols(1)\n&gt;&gt;&gt; symbol_library.preamble = [\"import numpy as np\"]\n&gt;&gt;&gt; # Usually this is done when initializing the SymbolLibrary as SymbolLibrary(preamble=preamble)\n&gt;&gt;&gt; executable_fun = expr_to_error_function(tree, symbol_library)\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]), np.array([2, 3, 4, 5]))\n0.0\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[List[str], Node]</code> <p>The expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use. Defaults to SymbolLibrary.default_symbols().</p> <code>default_symbols()</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If expression is not of the right type</p> <p>Returns:</p> Type Description <code>Callable[[ndarray, ndarray, ndarray], float]</code> <p>An executable function that takes in a 2D array of input values <code>X</code>, a 1D array of constant values <code>C</code>, and a 1D array of target values <code>y</code>. It returns the root mean squared error between the output of the expression and the target values.</p> Source code in <code>SRToolkit/utils/expression_compiler.py</code> <pre><code>def expr_to_error_function(\n    expr: Union[List[str], Node],\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n) -&gt; Callable[[np.ndarray, np.ndarray, np.ndarray], float]:\n    \"\"\"\n    Converts an expression in infix notation to an executable function that returns the root mean squared error between\n    the output of the expression and the target values.\n\n    Examples:\n        &gt;&gt;&gt; executable_fun = expr_to_error_function([\"X_0\", \"+\", \"1\"])\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]), np.array([2, 3, 4, 5]))\n        0.0\n        &gt;&gt;&gt; tree = tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1))\n        &gt;&gt;&gt; executable_fun = expr_to_error_function(tree)\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]), np.array([2, 3, 4, 5]))\n        0.0\n        &gt;&gt;&gt; # In case you need libraries other than numpy for the evaluation of your expressions,\n        &gt;&gt;&gt; # you can add them to the preamble in the SymbolLibrary. Here is how a preamble would look like:\n        &gt;&gt;&gt; symbol_library = SymbolLibrary.default_symbols(1)\n        &gt;&gt;&gt; symbol_library.preamble = [\"import numpy as np\"]\n        &gt;&gt;&gt; # Usually this is done when initializing the SymbolLibrary as SymbolLibrary(preamble=preamble)\n        &gt;&gt;&gt; executable_fun = expr_to_error_function(tree, symbol_library)\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]), np.array([2, 3, 4, 5]))\n        0.0\n\n    Args:\n        expr: The expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        symbol_library: The symbol library to use. Defaults to SymbolLibrary.default_symbols().\n\n    Raises:\n        Exception: If expression is not of the right type\n\n    Returns:\n        An executable function that takes in a 2D array of input values `X`, a 1D array of constant values `C`, and a 1D array of target values `y`. It returns the root mean squared error between the output of the expression and the target values.\n    \"\"\"\n    if not (isinstance(expr, list) or isinstance(expr, Node)):\n        raise Exception(\n            \"Expression must be given as either a list of tokens or a tree (an instance of the \"\n            \"SRToolkit.utils.expression_tree.Node class)\"\n        )\n\n    if isinstance(expr, list):\n        tree = tokens_to_tree(expr, symbol_library)\n    else:\n        tree = expr\n    code, symbol, var_counter, const_counter = tree_to_function_rec(\n        tree, symbol_library\n    )\n\n    fun_string = \"\\n\".join(symbol_library.preamble) + \"\\ndef _executable_expression_(X, C, y):\\n\"\n    for c in code:\n        fun_string += \"\\t\" + c + \"\\n\"\n    fun_string += f\"\\treturn np.sqrt(np.mean(({symbol}-y)**2))\"\n\n    fun_assignment_dict = {}\n    exec(fun_string, globals(), fun_assignment_dict)\n    return fun_assignment_dict[\"_executable_expression_\"]\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.simplify","title":"simplify","text":"<pre><code>simplify(expr: Union[List[str], Node], symbol_library: SymbolLibrary = SymbolLibrary.default_symbols()) -&gt; Union[List[str], Node]\n</code></pre> Simplifies a mathematical expression by <ol> <li>Making use of sympy's simplification functions</li> <li>Simplifying constants, e.g. C*C + C -&gt; C</li> </ol> <p>Examples:</p> <pre><code>&gt;&gt;&gt; expr = [\"C\", \"+\", \"C\" \"*\", \"C\", \"+\", \"X_0\", \"*\", \"X_1\", \"/\", \"X_0\"]\n&gt;&gt;&gt; print(\"\".join(simplify(expr)))\nC+X_1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[List[str], Node]</code> <p>The expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use. Defaults to SymbolLibrary.default_symbols().</p> <code>default_symbols()</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If problems occur during simplification or if the expression contains invalid symbols.</p> <p>Returns:</p> Type Description <code>Union[List[str], Node]</code> <p>The simplified expression</p> Source code in <code>SRToolkit/utils/expression_simplifier.py</code> <pre><code>def simplify(\n    expr: Union[List[str], Node],\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n) -&gt; Union[List[str], Node]:\n    \"\"\"\n    Simplifies a mathematical expression by:\n        1. Making use of sympy's simplification functions\n        2. Simplifying constants, e.g. C*C + C -&gt; C\n\n    Examples:\n        &gt;&gt;&gt; expr = [\"C\", \"+\", \"C\" \"*\", \"C\", \"+\", \"X_0\", \"*\", \"X_1\", \"/\", \"X_0\"]\n        &gt;&gt;&gt; print(\"\".join(simplify(expr)))\n        C+X_1\n\n    Args:\n        expr: The expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        symbol_library: The symbol library to use. Defaults to SymbolLibrary.default_symbols().\n\n    Raises:\n        Exception: If problems occur during simplification or if the expression contains invalid symbols.\n\n    Returns:\n        The simplified expression\n    \"\"\"\n    is_tree = False\n    if isinstance(expr, Node):\n        expr = expr.to_list(symbol_library=symbol_library, notation=\"infix\")\n        is_tree = True\n\n    variables = symbol_library.get_symbols_of_type(\"var\")\n\n    # We expect only one symbol for constants\n    if len(symbol_library.get_symbols_of_type(\"const\")) &gt; 0:\n        constant = symbol_library.get_symbols_of_type(\"const\")[0]\n    else:\n        # In this case constants shouldn't be problematic as they are not in the SymbolLibrary\n        # Just in case and to not change other functions, I changed it to __C__.\n        constant = \"__C__\"\n\n    expr = _simplify_expression(\"\".join(expr), constant, variables)\n    expr = sympify(_denumerate_constants(str(expr), constant), evaluate=False)\n    expr = _sympy_to_sr(expr)\n    if not _check_tree(expr, symbol_library):\n        raise Exception(\n            \"Simplified expression contains invalid symbols. Possibly skip its simplification or add symbols to the SymbolLibrary.\"\n        )\n\n    if is_tree:\n        return expr\n    else:\n        return expr.to_list(symbol_library=symbol_library, notation=\"infix\")\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.generate_from_pcfg","title":"generate_from_pcfg","text":"<pre><code>generate_from_pcfg(grammar_str: str, start_symbol: str = 'E', max_depth: int = 40, limit: int = 100) -&gt; List[str]\n</code></pre> <p>Generates a random expression from a PCFG with monte-carlo sampling.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; generate_from_pcfg(\"E -&gt; '1' [1.0]\")\n['1']\n&gt;&gt;&gt; grammar = create_generic_pcfg(SymbolLibrary.default_symbols())\n&gt;&gt;&gt; len(generate_from_pcfg(grammar)) &gt; 0\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>grammar_str</code> <code>str</code> <p>Grammar given as a string in the NLTK notation</p> required <code>start_symbol</code> <code>str</code> <p>Non-terminal symbol used as the starting point</p> <code>'E'</code> <code>max_depth</code> <code>int</code> <p>Maximum depth of the generated parse trees. If less than 0, expressions can have arbitrary depth</p> <code>40</code> <code>limit</code> <code>int</code> <p>Number of times the function tries to generate a valid expression before raising an Exception.</p> <code>100</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If the maximum number of tries is reached without generating a valid expression</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>An expression written as a list of string tokens in the infix notation.</p> Source code in <code>SRToolkit/utils/expression_generator.py</code> <pre><code>def generate_from_pcfg(\n    grammar_str: str, start_symbol: str = \"E\", max_depth: int = 40, limit: int = 100\n) -&gt; List[str]:\n    \"\"\"\n    Generates a random expression from a PCFG with monte-carlo sampling.\n\n    Examples:\n        &gt;&gt;&gt; generate_from_pcfg(\"E -&gt; '1' [1.0]\")\n        ['1']\n        &gt;&gt;&gt; grammar = create_generic_pcfg(SymbolLibrary.default_symbols())\n        &gt;&gt;&gt; len(generate_from_pcfg(grammar)) &gt; 0\n        True\n\n    Args:\n        grammar_str: Grammar given as a string in the NLTK notation\n        start_symbol: Non-terminal symbol used as the starting point\n        max_depth: Maximum depth of the generated parse trees. If less than 0, expressions can have arbitrary depth\n        limit: Number of times the function tries to generate a valid expression before raising an Exception.\n\n    Raises:\n        Exception: If the maximum number of tries is reached without generating a valid expression\n\n    Returns:\n        An expression written as a list of string tokens in the infix notation.\n    \"\"\"\n    start_symbol = nltk.grammar.Nonterminal(start_symbol)\n    grammar = nltk.PCFG.fromstring(grammar_str)\n    expr = _expand(grammar, start_symbol, 0, max_depth)\n    tries = 1\n    while expr is None and tries &lt; limit:\n        expr = _expand(grammar, start_symbol, 0, max_depth)\n\n    if expr is None:\n        raise Exception(\n            f\"[Expression generation] Couldn't find an expression with max_depth {max_depth} from this grammar in {limit} tries.\"\n        )\n\n    return expr\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.create_generic_pcfg","title":"create_generic_pcfg","text":"<pre><code>create_generic_pcfg(symbol_library: SymbolLibrary) -&gt; str\n</code></pre> <p>Creates a generic PCFG from the SymbolLibrary.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sl = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"sin\", \"^2\", \"pi\"], 2)\n&gt;&gt;&gt; print(create_generic_pcfg(sl))\nE -&gt; E '+' F [0.2]\nE -&gt; E '-' F [0.2]\nE -&gt; F [0.6]\nF -&gt; F '*' B [0.4]\nF -&gt; B [0.6]\nB -&gt; T [1.0]\nT -&gt; R [0.2]\nT -&gt; C [0.2]\nT -&gt; V [0.6]\nC -&gt; 'pi' [1.0]\nR -&gt; 'sin' '(' E ')' [0.4]\nR -&gt; P [0.15]\nR -&gt; '(' E ')' [0.45]\nP -&gt; '(' E ')' '^2' [1.0]\nV -&gt; 'X_0' [0.5]\nV -&gt; 'X_1' [0.5]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use. Defaults to SymbolLibrary.default_symbols().</p> required <p>Returns:</p> Type Description <code>str</code> <p>A PCFG with generic probabilities, written as a string.</p> Source code in <code>SRToolkit/utils/expression_generator.py</code> <pre><code>def create_generic_pcfg(symbol_library: SymbolLibrary) -&gt; str:\n    \"\"\"\n    Creates a generic PCFG from the SymbolLibrary.\n\n    Examples:\n        &gt;&gt;&gt; sl = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"sin\", \"^2\", \"pi\"], 2)\n        &gt;&gt;&gt; print(create_generic_pcfg(sl))\n        E -&gt; E '+' F [0.2]\n        E -&gt; E '-' F [0.2]\n        E -&gt; F [0.6]\n        F -&gt; F '*' B [0.4]\n        F -&gt; B [0.6]\n        B -&gt; T [1.0]\n        T -&gt; R [0.2]\n        T -&gt; C [0.2]\n        T -&gt; V [0.6]\n        C -&gt; 'pi' [1.0]\n        R -&gt; 'sin' '(' E ')' [0.4]\n        R -&gt; P [0.15]\n        R -&gt; '(' E ')' [0.45]\n        P -&gt; '(' E ')' '^2' [1.0]\n        V -&gt; 'X_0' [0.5]\n        V -&gt; 'X_1' [0.5]\n        &lt;BLANKLINE&gt;\n\n    Args:\n        symbol_library: The symbol library to use. Defaults to SymbolLibrary.default_symbols().\n\n    Returns:\n        A PCFG with generic probabilities, written as a string.\n    \"\"\"\n    symbols = symbol_library.symbols.values()\n    E = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"op\" and s[\"precedence\"] == 0]\n    F = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"op\" and s[\"precedence\"] == 1]\n    BP = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"op\" and s[\"precedence\"] == 2]\n    R = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"fn\" and s[\"precedence\"] == 5]\n    P = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"fn\" and s[\"precedence\"] == -1]\n    V = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"var\"]\n    Cc = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"const\"]\n    Cl = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"lit\"]\n\n    grammar = \"\"\n    if len(E) &gt; 0:\n        for s in E:\n            grammar += f\"E -&gt; E '{s}' F [{0.4 / len(E)}]\\n\"\n        grammar += \"E -&gt; F [0.6]\\n\"\n    else:\n        grammar += \"E -&gt; F [1.0]\\n\"\n\n    if len(F) &gt; 0:\n        for s in F:\n            grammar += f\"F -&gt; F '{s}' B [{0.4 / len(F)}]\\n\"\n        grammar += \"F -&gt; B [0.6]\\n\"\n    else:\n        grammar += \"F -&gt; B [1.0]\\n\"\n\n    if len(BP) &gt; 0:\n        for s in BP:\n            grammar += f\"B -&gt; B '{s}' T [{0.05 / len(BP)}]\\n\"\n        grammar += \"B -&gt; T [0.95]\\n\"\n    else:\n        grammar += \"B -&gt; T [1.0]\\n\"\n\n    if len(Cc) + len(Cl) &gt; 0:\n        grammar += \"T -&gt; R [0.2]\\n\"\n        grammar += \"T -&gt; C [0.2]\\n\"\n        grammar += \"T -&gt; V [0.6]\\n\"\n        if len(Cl) &gt; 0 and len(Cc) &gt; 0:\n            for s in Cl:\n                grammar += f\"C -&gt; '{s}' [{0.2 / len(Cl)}]\\n\"\n            for s in Cc:\n                grammar += f\"C -&gt; '{s}' [{0.8 / len(Cc)}]\\n\"\n        elif len(Cl) &gt; 0:\n            for s in Cl:\n                grammar += f\"C -&gt; '{s}' [{1 / len(Cl)}]\\n\"\n        elif len(Cc) &gt; 0:\n            for s in Cc:\n                grammar += f\"C -&gt; '{s}' [{1 / len(Cc)}]\\n\"\n    else:\n        grammar += \"T -&gt; R [0.3]\\n\"\n        grammar += \"T -&gt; V [0.7]\\n\"\n\n    if len(R) &gt; 0:\n        for s in R:\n            grammar += f\"R -&gt; '{s}' '(' E ')' [{0.4 / len(R)}]\\n\"\n        if len(P) &gt; 0:\n            grammar += \"R -&gt; P [0.15]\\n\"\n            grammar += \"R -&gt; '(' E ')' [0.45]\\n\"\n        else:\n            grammar += \"R -&gt; '(' E ')' [0.6]\\n\"\n    else:\n        if len(P) &gt; 0:\n            grammar += \"R -&gt; P [0.15]\\n\"\n            grammar += \"R -&gt; '(' E ')' [0.85]\\n\"\n        else:\n            grammar += \"R -&gt; '(' E ')' [1.0]\\n\"\n\n    if len(P) &gt; 0:\n        total = sum([1 / abs(float(s[1:])) for s in P])\n        for s in P:\n            grammar += f\"P -&gt; '(' E ')' '{s}' [{(1 / abs(float(s[1:]))) / total}]\\n\"\n\n    if len(V) &gt; 0:\n        for s in V:\n            grammar += f\"V -&gt; '{s}' [{1 / len(V)}]\\n\"\n\n    return grammar\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.generate_n_expressions","title":"generate_n_expressions","text":"<pre><code>generate_n_expressions(expression_description: Union[str, SymbolLibrary], num_expressions: int, unique: bool = True, max_expression_length: int = 50, verbose: bool = True) -&gt; List[List[str]]\n</code></pre> <p>Generates a set of n expressions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; len(generate_n_expressions(SymbolLibrary.default_symbols(5), 100, verbose=False))\n100\n&gt;&gt;&gt; generate_n_expressions(SymbolLibrary.from_symbol_list([], 1), 3, unique=False, verbose=False, max_expression_length=1)\n[['X_0'], ['X_0'], ['X_0']]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expression_description</code> <code>Union[str, SymbolLibrary]</code> <p>Decription of expressions, given as either a grammar in the NLTK notation or a SymbolLibrary instance</p> required <code>num_expressions</code> <code>int</code> <p>Number of generated expressions</p> required <code>unique</code> <code>bool</code> <p>When True, each generated expression will be unique (not necesarily unequivalent to others)</p> <code>True</code> <code>max_expression_length</code> <code>int</code> <p>Generated expressions will have at most \"max_expression_length\" tokens. If less than 0, expressions can be of arbitrary size.</p> <code>50</code> <code>verbose</code> <code>bool</code> <p>If True, adds a progress bar</p> <code>True</code> <p>Returns:</p> Type Description <code>List[List[str]]</code> <p>A list of expressions represented as lists of tokens</p> Source code in <code>SRToolkit/utils/expression_generator.py</code> <pre><code>def generate_n_expressions(\n    expression_description: Union[str, SymbolLibrary],\n    num_expressions: int,\n    unique: bool = True,\n    max_expression_length: int = 50,\n    verbose: bool = True,\n) -&gt; List[List[str]]:\n    \"\"\"\n    Generates a set of n expressions.\n\n    Examples:\n        &gt;&gt;&gt; len(generate_n_expressions(SymbolLibrary.default_symbols(5), 100, verbose=False))\n        100\n        &gt;&gt;&gt; generate_n_expressions(SymbolLibrary.from_symbol_list([], 1), 3, unique=False, verbose=False, max_expression_length=1)\n        [['X_0'], ['X_0'], ['X_0']]\n\n    Args:\n        expression_description: Decription of expressions, given as either a grammar in the NLTK notation or a SymbolLibrary instance\n        num_expressions: Number of generated expressions\n        unique: When True, each generated expression will be unique (not necesarily unequivalent to others)\n        max_expression_length: Generated expressions will have at most \"max_expression_length\" tokens. If less than 0, expressions can be of arbitrary size.\n        verbose: If True, adds a progress bar\n\n    Returns:\n        A list of expressions represented as lists of tokens\n    \"\"\"\n    if isinstance(expression_description, SymbolLibrary):\n        grammar = create_generic_pcfg(expression_description)\n    elif isinstance(expression_description, str):\n        grammar = expression_description\n    else:\n        raise Exception(\n            \"Description of expressions must be either a grammar written as a string or an instance of SymbolLibrary.\"\n        )\n\n    expressions = []\n    expression_strings = set()\n    if verbose:\n        pbar = tqdm(total=num_expressions)\n    while len(expressions) &lt; num_expressions:\n        try:\n            expr = generate_from_pcfg(grammar, max_depth=max_expression_length * 10)\n        except Exception:\n            print(\"Couldn't generate a valid expression in 100 tries\")\n            continue\n        if len(expr) &gt; max_expression_length &gt; 0:\n            continue\n\n        expr_string = \"\".join(expr)\n        if expr_string not in expression_strings or not unique:\n            expressions.append(expr)\n            expression_strings.add(expr_string)\n            if verbose:\n                pbar.update(1)\n\n    if verbose:\n        pbar.close()\n    return expressions\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.bed","title":"bed","text":"<pre><code>bed(expr1: Union[Node, List[str], ndarray], expr2: Union[Node, List[str], ndarray], X: Optional[ndarray] = None, num_consts_sampled: int = 32, num_points_sampled: int = 64, domain_bounds: Optional[List[Tuple[float, float]]] = None, consts_bounds: Tuple[float, float] = (-5, 5), symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(), seed: int = None) -&gt; float\n</code></pre> <p>Computes the Behavioral Embedding Distance (BED) between two expressions or behavior matrices over a given dataset or domain, using Wasserstein distance as a metric.</p> <p>The BED is computed either by using precomputed behavior matrices or by sampling points from a domain and evaluating the expressions over them.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.random.rand(10, 2) - 0.5\n&gt;&gt;&gt; expr1 = [\"X_0\", \"+\", \"C\"] # instances of SRToolkit.utils.expression_tree.Node work as well\n&gt;&gt;&gt; expr2 = [\"X_1\", \"+\", \"C\"]\n&gt;&gt;&gt; bed(expr1, expr2, X) &lt; 1\nTrue\n&gt;&gt;&gt; # Changing the number of sampled constants\n&gt;&gt;&gt; bed(expr1, expr2, X, num_consts_sampled=128, consts_bounds=(-2, 2)) &lt; 1\nTrue\n&gt;&gt;&gt; # Sampling X instead of giving it directly by defining a domain\n&gt;&gt;&gt; bed(expr1, expr2, domain_bounds=[(0, 1), (0, 1)]) &lt; 1\nTrue\n&gt;&gt;&gt; bed(expr1, expr2, domain_bounds=[(0, 1), (0, 1)], num_points_sampled=128) &lt; 1\nTrue\n&gt;&gt;&gt; # You can use behavior matrices instead of expressions (this has potential computational advantages if same expression is used multiple times)\n&gt;&gt;&gt; bm1 = create_behavior_matrix(expr1, X)\n&gt;&gt;&gt; bed(bm1, expr2, X) &lt; 1\nTrue\n&gt;&gt;&gt; bm2 = create_behavior_matrix(expr2, X)\n&gt;&gt;&gt; bed(bm1, bm2) &lt; 1\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr1</code> <code>Union[Node, List[str], ndarray]</code> <p>The first expression or behavior matrix. If it is an expression, it must be provided as a Node or a list of string representations. If it is already a behavior matrix, it should be a numpy array of size (num_points_sampled, num_consts_sampled).</p> required <code>expr2</code> <code>Union[Node, List[str], ndarray]</code> <p>The second expression or behavior matrix. Similar to expr1, it should be either a Node, list of strings representing the expression, or a numpy array representing the behavior matrix.</p> required <code>X</code> <code>Optional[ndarray]</code> <p>Array of points over which behavior is evaluated. If not provided, the domain bounds parameter will be used to sample points.</p> <code>None</code> <code>num_consts_sampled</code> <code>int</code> <p>Number of constants sampled for behavior evaluation if expressions are given as Nodes or lists rather than matrices. Default is 32.</p> <code>32</code> <code>num_points_sampled</code> <code>int</code> <p>Number of points sampled from the domain if X is not provided. Default is 64.</p> <code>64</code> <code>domain_bounds</code> <code>Optional[List[Tuple[float, float]]]</code> <p>The bounds of the domain for sampling points when X is not given. Each tuple represents the lower and upper bounds for a domain feature (e.g., [(0, 1), (0, 2)]).</p> <code>None</code> <code>consts_bounds</code> <code>Tuple[float, float]</code> <p>The lower and upper bounds for sampling constants when evaluating expressions. Default is (-5, 5).</p> <code>(-5, 5)</code> <code>symbol_library</code> <code>SymbolLibrary</code> <p>The library of symbols used to parse and evaluate expressions. Default is the default symbol library from SymbolLibrary.</p> <code>default_symbols()</code> <code>seed</code> <code>int</code> <p>Seed for random number generation during sampling for deterministic results. Default is None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The mean Wasserstein distance computed between the behaviors of the two expressions or</p> <code>float</code> <p>matrices over the sampled points.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If X is not provided and domain_bounds is missing, this exception is raised to ensure proper sampling of points for behavior evaluation.</p> <code>AssertionError</code> <p>Raised when the shapes of the behavior matrices or sampling points do not match the expected dimensions.</p> Source code in <code>SRToolkit/utils/measures.py</code> <pre><code>def bed(\n    expr1: Union[Node, List[str], np.ndarray],\n    expr2: Union[Node, List[str], np.ndarray],\n    X: Optional[np.ndarray] = None,\n    num_consts_sampled: int = 32,\n    num_points_sampled: int = 64,\n    domain_bounds: Optional[List[Tuple[float, float]]] = None,\n    consts_bounds: Tuple[float, float] = (-5, 5),\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n    seed: int = None,\n) -&gt; float:\n    \"\"\"\n    Computes the Behavioral Embedding Distance (BED) between two expressions or behavior matrices over a\n    given dataset or domain, using Wasserstein distance as a metric.\n\n    The BED is computed either by using precomputed behavior matrices or by sampling points from a\n    domain and evaluating the expressions over them.\n\n    Examples:\n        &gt;&gt;&gt; X = np.random.rand(10, 2) - 0.5\n        &gt;&gt;&gt; expr1 = [\"X_0\", \"+\", \"C\"] # instances of SRToolkit.utils.expression_tree.Node work as well\n        &gt;&gt;&gt; expr2 = [\"X_1\", \"+\", \"C\"]\n        &gt;&gt;&gt; bed(expr1, expr2, X) &lt; 1\n        True\n        &gt;&gt;&gt; # Changing the number of sampled constants\n        &gt;&gt;&gt; bed(expr1, expr2, X, num_consts_sampled=128, consts_bounds=(-2, 2)) &lt; 1\n        True\n        &gt;&gt;&gt; # Sampling X instead of giving it directly by defining a domain\n        &gt;&gt;&gt; bed(expr1, expr2, domain_bounds=[(0, 1), (0, 1)]) &lt; 1\n        True\n        &gt;&gt;&gt; bed(expr1, expr2, domain_bounds=[(0, 1), (0, 1)], num_points_sampled=128) &lt; 1\n        True\n        &gt;&gt;&gt; # You can use behavior matrices instead of expressions (this has potential computational advantages if same expression is used multiple times)\n        &gt;&gt;&gt; bm1 = create_behavior_matrix(expr1, X)\n        &gt;&gt;&gt; bed(bm1, expr2, X) &lt; 1\n        True\n        &gt;&gt;&gt; bm2 = create_behavior_matrix(expr2, X)\n        &gt;&gt;&gt; bed(bm1, bm2) &lt; 1\n        True\n\n    Args:\n        expr1: The first expression or behavior matrix. If it is\n            an expression, it must be provided as a Node or a list of string representations. If it is\n            already a behavior matrix, it should be a numpy array of size (num_points_sampled, num_consts_sampled).\n        expr2: The second expression or behavior matrix. Similar\n            to expr1, it should be either a Node, list of strings representing the expression, or a\n            numpy array representing the behavior matrix.\n        X: Array of points over which behavior is evaluated. If not provided, the domain bounds parameter will be\n            used to sample points.\n        num_consts_sampled: Number of constants sampled for behavior evaluation if expressions\n            are given as Nodes or lists rather than matrices. Default is 32.\n        num_points_sampled: Number of points sampled from the domain if X is not provided. Default is 64.\n        domain_bounds: The bounds of the domain for sampling points when X is not given. Each tuple represents the\n            lower and upper bounds for a domain feature (e.g., [(0, 1), (0, 2)]).\n        consts_bounds: The lower and upper bounds for sampling constants when evaluating expressions. Default is (-5, 5).\n        symbol_library: The library of symbols used to parse and evaluate expressions. Default is the default symbol\n            library from SymbolLibrary.\n        seed: Seed for random number generation during sampling for deterministic results. Default is None.\n\n    Returns:\n        float: The mean Wasserstein distance computed between the behaviors of the two expressions or\n        matrices over the sampled points.\n\n    Raises:\n        Exception: If X is not provided and domain_bounds is missing, this exception is raised to\n            ensure proper sampling of points for behavior evaluation.\n        AssertionError: Raised when the shapes of the behavior matrices or sampling points do not match\n            the expected dimensions.\n    \"\"\"\n\n    if (\n        X is None\n        and not isinstance(expr1, np.ndarray)\n        and not isinstance(expr2, np.ndarray)\n    ):\n        if domain_bounds is None:\n            raise Exception(\n                \"If X is not given and both expressions are not given as a behavior matrix, \"\n                \"then domain_bounds parameter must be given\"\n            )\n        interval_length = np.array([ub - lb for (lb, ub) in domain_bounds])\n        lower_bound = np.array([lb for (lb, ub) in domain_bounds])\n        lho = LatinHypercube(len(domain_bounds), optimization=\"random-cd\", seed=seed)\n        X = lho.random(num_points_sampled) * interval_length + lower_bound\n    elif X is None and (isinstance(expr1, np.ndarray) != isinstance(expr2, np.ndarray)):\n        raise Exception(\n            \"If X is not given, both expressions must be given as a behavior matrix or as a list of \"\n            \"tokens/SRToolkit.utils.Node objects. Otherwise, behavior matrices are uncomparable.\"\n        )\n\n    if isinstance(expr1, list) or isinstance(expr1, Node):\n        expr1 = create_behavior_matrix(\n            expr1, X, num_consts_sampled, consts_bounds, symbol_library, seed\n        )\n\n    if isinstance(expr2, list) or isinstance(expr2, Node):\n        expr2 = create_behavior_matrix(\n            expr2, X, num_consts_sampled, consts_bounds, symbol_library, seed\n        )\n\n    assert expr1.shape[0] == expr2.shape[0], (\n        \"Behavior matrices must have the same number rows (points \"\n        \"on which behavior is evaluated.)\"\n    )\n    assert expr1.shape[0] &gt; 0, (\n        \"Behavior matrices must have at least one row. if your expressions are given as behavior\"\n        \"matrices, make sure they are not empty. Otherwise, if X is given, make sure it contains\"\n        \"at least one point. If X is not given, make sure num_points_sampled is greater than 0.\"\n    )\n    wds = []\n    for i in range(expr1.shape[0]):\n        u = expr1[i][np.isfinite(expr1[i])]\n        v = expr2[i][np.isfinite(expr2[i])]\n        if u.shape[0] &gt; 0 and v.shape[0] &gt; 0:\n            wds.append(_custom_wasserstein(u, v))\n        elif u.shape[0] == 0 and v.shape[0] == 0:\n            wds.append(0)\n        else:\n            wds.append(np.inf)\n\n    return float(np.mean(wds))\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.create_behavior_matrix","title":"create_behavior_matrix","text":"<pre><code>create_behavior_matrix(expr: Union[Node, List[str]], X: ndarray, num_consts_sampled: int = 32, consts_bounds: Tuple[float, float] = (-5, 5), symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(), seed: int = None) -&gt; np.ndarray\n</code></pre> <p>Creates a behavior matrix from an expression with free parameters. The shape of the matrix is (X.shape[0], num_consts_sampled).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.random.rand(10, 2) - 0.5\n&gt;&gt;&gt; create_behavior_matrix([\"X_0\", \"+\", \"C\"], X, num_consts_sampled=32).shape\n(10, 32)\n&gt;&gt;&gt; mean_0_1 = np.mean(create_behavior_matrix([\"X_0\", \"+\", \"C\"], X, num_consts_sampled=32, consts_bounds=(0, 1)))\n&gt;&gt;&gt; mean_1_5 = np.mean(create_behavior_matrix([\"X_0\", \"+\", \"C\"], X, num_consts_sampled=32, consts_bounds=(1, 5)))\n&gt;&gt;&gt; mean_0_1 &lt; mean_1_5\nTrue\n&gt;&gt;&gt; # Deterministic expressions always produce the same behavior matrix\n&gt;&gt;&gt; bm1 = create_behavior_matrix([\"X_0\", \"+\", \"X_1\"], X)\n&gt;&gt;&gt; bm2 = create_behavior_matrix([\"X_0\", \"+\", \"X_1\"], X)\n&gt;&gt;&gt; np.array_equal(bm1, bm2)\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[Node, List[str]]</code> <p>An expression given as a list of tokens in the infix notation.</p> required <code>X</code> <code>ndarray</code> <p>Points on which the expression is evaluated to determine the behavior</p> required <code>num_consts_sampled</code> <code>int</code> <p>Number of sets of constants sampled</p> <code>32</code> <code>consts_bounds</code> <code>Tuple[float, float]</code> <p>Bounds between which constant values are sampled</p> <code>(-5, 5)</code> <code>symbol_library</code> <code>SymbolLibrary</code> <p>Symbol library used to transform the expression into an executable function.</p> <code>default_symbols()</code> <code>seed</code> <code>int</code> <p>Random seed. If None, generation will be random.</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If expr is not a list of tokens or an instance of SRToolkit.utils.expression_tree.Node.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>A matrix of size (X.shape[0], num_consts_sampled) that represents the behavior of an expression.</p> Source code in <code>SRToolkit/utils/measures.py</code> <pre><code>def create_behavior_matrix(\n    expr: Union[Node, List[str]],\n    X: np.ndarray,\n    num_consts_sampled: int = 32,\n    consts_bounds: Tuple[float, float] = (-5, 5),\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n    seed: int = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Creates a behavior matrix from an expression with free parameters. The shape of the matrix is (X.shape[0], num_consts_sampled).\n\n    Examples:\n        &gt;&gt;&gt; X = np.random.rand(10, 2) - 0.5\n        &gt;&gt;&gt; create_behavior_matrix([\"X_0\", \"+\", \"C\"], X, num_consts_sampled=32).shape\n        (10, 32)\n        &gt;&gt;&gt; mean_0_1 = np.mean(create_behavior_matrix([\"X_0\", \"+\", \"C\"], X, num_consts_sampled=32, consts_bounds=(0, 1)))\n        &gt;&gt;&gt; mean_1_5 = np.mean(create_behavior_matrix([\"X_0\", \"+\", \"C\"], X, num_consts_sampled=32, consts_bounds=(1, 5)))\n        &gt;&gt;&gt; mean_0_1 &lt; mean_1_5\n        True\n        &gt;&gt;&gt; # Deterministic expressions always produce the same behavior matrix\n        &gt;&gt;&gt; bm1 = create_behavior_matrix([\"X_0\", \"+\", \"X_1\"], X)\n        &gt;&gt;&gt; bm2 = create_behavior_matrix([\"X_0\", \"+\", \"X_1\"], X)\n        &gt;&gt;&gt; np.array_equal(bm1, bm2)\n        True\n\n\n    Args:\n        expr: An expression given as a list of tokens in the infix notation.\n        X: Points on which the expression is evaluated to determine the behavior\n        num_consts_sampled: Number of sets of constants sampled\n        consts_bounds: Bounds between which constant values are sampled\n        symbol_library: Symbol library used to transform the expression into an executable function.\n        seed: Random seed. If None, generation will be random.\n\n    Raises:\n        Exception: If expr is not a list of tokens or an instance of SRToolkit.utils.expression_tree.Node.\n\n    Returns:\n        A matrix of size (X.shape[0], num_consts_sampled) that represents the behavior of an expression.\n    \"\"\"\n    if isinstance(expr, list):\n        num_constants = expr.count(\"C\")\n    elif isinstance(expr, Node):\n        num_constants = expr.to_list(notation=\"postfix\").count(\"C\")\n    else:\n        raise Exception(\"Expression should be a list of strings (tokens) or a Node\")\n\n    expr = expr_to_executable_function(expr, symbol_library)\n\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\", over=\"ignore\", under=\"ignore\"):\n        if num_constants &gt; 0:\n            lho = LatinHypercube(num_constants, seed=seed)\n            constants = (\n                lho.random(num_consts_sampled) * (consts_bounds[1] - consts_bounds[0])\n                + consts_bounds[0]\n            )\n            ys = []\n            for c in constants:\n                ys.append(expr(X, c))\n            return np.array(ys).T\n        else:\n            return np.repeat(expr(X, None)[:, None], num_consts_sampled, axis=1)\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.edit_distance","title":"edit_distance","text":"<pre><code>edit_distance(expr1: Union[List[str], Node], expr2: Union[List[str], Node], notation: str = 'postfix', symbol_library: SymbolLibrary = SymbolLibrary.default_symbols()) -&gt; int\n</code></pre> <p>Calculates the edit distance between two expressions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"+\", \"1\"])\n0\n&gt;&gt;&gt; edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"-\", \"1\"])\n1\n&gt;&gt;&gt; edit_distance(tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1)), tokens_to_tree([\"X_0\", \"-\", \"1\"], SymbolLibrary.default_symbols(1)))\n1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr1</code> <code>Union[List[str], Node]</code> <p>Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>expr2</code> <code>Union[List[str], Node]</code> <p>Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>notation</code> <code>str</code> <p>The notation in which the distance between the two expressions is computed. Can be one of \"infix\", \"postfix\", or \"prefix\". By default, \"postfix\" is used to avoid inconsistencies that occur because of parenthesis.</p> <code>'postfix'</code> <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use when converting the expressions to lists of tokens and vice versa. Defaults to SymbolLibrary.default_symbols().</p> <code>default_symbols()</code> <p>Returns:</p> Type Description <code>int</code> <p>The edit distance between the two expressions written in a given notation.</p> Source code in <code>SRToolkit/utils/measures.py</code> <pre><code>def edit_distance(\n    expr1: Union[List[str], Node],\n    expr2: Union[List[str], Node],\n    notation: str = \"postfix\",\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n) -&gt; int:\n    \"\"\"\n    Calculates the edit distance between two expressions.\n\n    Examples:\n        &gt;&gt;&gt; edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"+\", \"1\"])\n        0\n        &gt;&gt;&gt; edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"-\", \"1\"])\n        1\n        &gt;&gt;&gt; edit_distance(tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1)), tokens_to_tree([\"X_0\", \"-\", \"1\"], SymbolLibrary.default_symbols(1)))\n        1\n\n    Args:\n        expr1: Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        expr2: Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        notation: The notation in which the distance between the two expressions is computed. Can be one of \"infix\", \"postfix\", or \"prefix\".\n            By default, \"postfix\" is used to avoid inconsistencies that occur because of parenthesis.\n        symbol_library: The symbol library to use when converting the expressions to lists of tokens and vice versa. Defaults to SymbolLibrary.default_symbols().\n\n    Returns:\n        The edit distance between the two expressions written in a given notation.\n    \"\"\"\n    if isinstance(expr1, Node):\n        expr1 = expr1.to_list(symbol_library=symbol_library, notation=notation)\n    elif isinstance(expr1, list):\n        expr1 = tokens_to_tree(expr1, symbol_library).to_list(\n            symbol_library=symbol_library, notation=notation\n        )\n\n    if isinstance(expr2, Node):\n        expr2 = expr2.to_list(symbol_library=symbol_library, notation=notation)\n    elif isinstance(expr2, list):\n        expr2 = tokens_to_tree(expr2, symbol_library).to_list(\n            symbol_library=symbol_library, notation=notation\n        )\n\n    return editdistance.eval(expr1, expr2)\n</code></pre>"},{"location":"references/utils/#SRToolkit.utils.tree_edit_distance","title":"tree_edit_distance","text":"<pre><code>tree_edit_distance(expr1: Union[Node, List[str]], expr2: Union[Node, List[str]], symbol_library: SymbolLibrary = SymbolLibrary.default_symbols()) -&gt; int\n</code></pre> <p>Calculates the tree edit distance between two expressions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tree_edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"+\", \"1\"])\n0\n&gt;&gt;&gt; tree_edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"-\", \"1\"])\n1\n&gt;&gt;&gt; tree_edit_distance(tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1)), tokens_to_tree([\"X_0\", \"-\", \"1\"], SymbolLibrary.default_symbols(1)))\n1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr1</code> <code>Union[Node, List[str]]</code> <p>Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>expr2</code> <code>Union[Node, List[str]]</code> <p>Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>Symbol library to use when converting the lists of tokens into an instance of SRToolkit.utils.expression_tree.Node.</p> <code>default_symbols()</code> <p>Returns:</p> Type Description <code>int</code> <p>The tree edit distance between the two expressions.</p> Source code in <code>SRToolkit/utils/measures.py</code> <pre><code>def tree_edit_distance(\n    expr1: Union[Node, List[str]],\n    expr2: Union[Node, List[str]],\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n) -&gt; int:\n    \"\"\"\n    Calculates the tree edit distance between two expressions.\n\n    Examples:\n        &gt;&gt;&gt; tree_edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"+\", \"1\"])\n        0\n        &gt;&gt;&gt; tree_edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"-\", \"1\"])\n        1\n        &gt;&gt;&gt; tree_edit_distance(tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1)), tokens_to_tree([\"X_0\", \"-\", \"1\"], SymbolLibrary.default_symbols(1)))\n        1\n\n    Args:\n        expr1: Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        expr2: Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        symbol_library: Symbol library to use when converting the lists of tokens into an instance of SRToolkit.utils.expression_tree.Node.\n\n    Returns:\n        The tree edit distance between the two expressions.\n    \"\"\"\n    if isinstance(expr1, Node):\n        expr1 = _expr_to_zss(expr1)\n    elif isinstance(expr1, list):\n        expr1 = _expr_to_zss(tokens_to_tree(expr1, symbol_library))\n\n    if isinstance(expr2, Node):\n        expr2 = _expr_to_zss(expr2)\n    elif isinstance(expr2, list):\n        expr2 = _expr_to_zss(tokens_to_tree(expr2, symbol_library))\n\n    return int(zss.simple_distance(expr1, expr2))\n</code></pre>"},{"location":"references/utils/expression_compiler/","title":"Expression Compiler","text":""},{"location":"references/utils/expression_compiler/#SRToolkit.utils.expression_compiler","title":"SRToolkit.utils.expression_compiler","text":"<p>This module contains functions that convert an expression in infix notation to an executable python function.</p>"},{"location":"references/utils/expression_compiler/#SRToolkit.utils.expression_compiler.expr_to_executable_function","title":"expr_to_executable_function","text":"<pre><code>expr_to_executable_function(expr: Union[List[str], Node], symbol_library: SymbolLibrary = SymbolLibrary.default_symbols()) -&gt; Callable[[np.ndarray, np.ndarray], np.ndarray]\n</code></pre> <p>Converts an expression in infix notation to an executable function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; executable_fun = expr_to_executable_function([\"X_0\", \"+\", \"1\"])\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]))\narray([2, 3, 4, 5])\n&gt;&gt;&gt; executable_fun = expr_to_executable_function([\"pi\"])\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([1]))\narray([3.14159265, 3.14159265, 3.14159265, 3.14159265])\n&gt;&gt;&gt; executable_fun = expr_to_executable_function([\"C\"])\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([1]))\narray([1, 1, 1, 1])\n&gt;&gt;&gt; tree = tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1))\n&gt;&gt;&gt; executable_fun = expr_to_executable_function(tree)\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]))\narray([2, 3, 4, 5])\n&gt;&gt;&gt; # In case you need libraries other than numpy for the evaluation of your expressions,\n&gt;&gt;&gt; # you can add them to the preamble in the SymbolLibrary. Here is how a preamble would look like:\n&gt;&gt;&gt; symbol_library = SymbolLibrary.default_symbols(1)\n&gt;&gt;&gt; symbol_library.preamble = [\"import numpy as np\"]\n&gt;&gt;&gt; # Usually this is done when initializing the SymbolLibrary as SymbolLibrary(preamble=preamble)\n&gt;&gt;&gt; executable_fun = expr_to_executable_function(tree, symbol_library)\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]))\narray([2, 3, 4, 5])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[List[str], Node]</code> <p>The expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use. Defaults to SymbolLibrary.default_symbols().</p> <code>default_symbols()</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If expression is not of the right type</p> <p>Returns:</p> Type Description <code>Callable[[ndarray, ndarray], ndarray]</code> <p>An executable function that takes in a 2D array of input values and a 1D array of constant values and returns the output of the expression.</p> Source code in <code>SRToolkit/utils/expression_compiler.py</code> <pre><code>def expr_to_executable_function(\n    expr: Union[List[str], Node],\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n) -&gt; Callable[[np.ndarray, np.ndarray], np.ndarray]:\n    \"\"\"\n    Converts an expression in infix notation to an executable function.\n\n    Examples:\n        &gt;&gt;&gt; executable_fun = expr_to_executable_function([\"X_0\", \"+\", \"1\"])\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]))\n        array([2, 3, 4, 5])\n        &gt;&gt;&gt; executable_fun = expr_to_executable_function([\"pi\"])\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([1]))\n        array([3.14159265, 3.14159265, 3.14159265, 3.14159265])\n        &gt;&gt;&gt; executable_fun = expr_to_executable_function([\"C\"])\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([1]))\n        array([1, 1, 1, 1])\n        &gt;&gt;&gt; tree = tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1))\n        &gt;&gt;&gt; executable_fun = expr_to_executable_function(tree)\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]))\n        array([2, 3, 4, 5])\n        &gt;&gt;&gt; # In case you need libraries other than numpy for the evaluation of your expressions,\n        &gt;&gt;&gt; # you can add them to the preamble in the SymbolLibrary. Here is how a preamble would look like:\n        &gt;&gt;&gt; symbol_library = SymbolLibrary.default_symbols(1)\n        &gt;&gt;&gt; symbol_library.preamble = [\"import numpy as np\"]\n        &gt;&gt;&gt; # Usually this is done when initializing the SymbolLibrary as SymbolLibrary(preamble=preamble)\n        &gt;&gt;&gt; executable_fun = expr_to_executable_function(tree, symbol_library)\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]))\n        array([2, 3, 4, 5])\n\n    Args:\n        expr: The expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        symbol_library: The symbol library to use. Defaults to SymbolLibrary.default_symbols().\n\n    Raises:\n        Exception: If expression is not of the right type\n\n    Returns:\n        An executable function that takes in a 2D array of input values and a 1D array of constant values and returns the output of the expression.\n    \"\"\"\n    if not (isinstance(expr, list) or isinstance(expr, Node)):\n        raise Exception(\n            \"Expression must be given as either a list of tokens or a tree (an instance of the \"\n            \"SRToolkit.utils.expression_tree.Node class)\"\n        )\n\n    if isinstance(expr, list):\n        tree = tokens_to_tree(expr, symbol_library)\n    else:\n        tree = expr\n    code, symbol, var_counter, const_counter = tree_to_function_rec(\n        tree, symbol_library\n    )\n\n    fun_string = \"\\n\".join(symbol_library.preamble) + \"\\ndef _executable_expression_(X, C):\\n\"\n    for c in code:\n        fun_string += \"\\t\" + c + \"\\n\"\n    fun_string += \"\\treturn \" + symbol\n\n    fun_assignment_dict = {}\n    exec(fun_string, globals(), fun_assignment_dict)\n    return fun_assignment_dict[\"_executable_expression_\"]\n</code></pre>"},{"location":"references/utils/expression_compiler/#SRToolkit.utils.expression_compiler.expr_to_error_function","title":"expr_to_error_function","text":"<pre><code>expr_to_error_function(expr: Union[List[str], Node], symbol_library: SymbolLibrary = SymbolLibrary.default_symbols()) -&gt; Callable[[np.ndarray, np.ndarray, np.ndarray], float]\n</code></pre> <p>Converts an expression in infix notation to an executable function that returns the root mean squared error between the output of the expression and the target values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; executable_fun = expr_to_error_function([\"X_0\", \"+\", \"1\"])\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]), np.array([2, 3, 4, 5]))\n0.0\n&gt;&gt;&gt; tree = tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1))\n&gt;&gt;&gt; executable_fun = expr_to_error_function(tree)\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]), np.array([2, 3, 4, 5]))\n0.0\n&gt;&gt;&gt; # In case you need libraries other than numpy for the evaluation of your expressions,\n&gt;&gt;&gt; # you can add them to the preamble in the SymbolLibrary. Here is how a preamble would look like:\n&gt;&gt;&gt; symbol_library = SymbolLibrary.default_symbols(1)\n&gt;&gt;&gt; symbol_library.preamble = [\"import numpy as np\"]\n&gt;&gt;&gt; # Usually this is done when initializing the SymbolLibrary as SymbolLibrary(preamble=preamble)\n&gt;&gt;&gt; executable_fun = expr_to_error_function(tree, symbol_library)\n&gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]), np.array([2, 3, 4, 5]))\n0.0\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[List[str], Node]</code> <p>The expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use. Defaults to SymbolLibrary.default_symbols().</p> <code>default_symbols()</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If expression is not of the right type</p> <p>Returns:</p> Type Description <code>Callable[[ndarray, ndarray, ndarray], float]</code> <p>An executable function that takes in a 2D array of input values <code>X</code>, a 1D array of constant values <code>C</code>, and a 1D array of target values <code>y</code>. It returns the root mean squared error between the output of the expression and the target values.</p> Source code in <code>SRToolkit/utils/expression_compiler.py</code> <pre><code>def expr_to_error_function(\n    expr: Union[List[str], Node],\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n) -&gt; Callable[[np.ndarray, np.ndarray, np.ndarray], float]:\n    \"\"\"\n    Converts an expression in infix notation to an executable function that returns the root mean squared error between\n    the output of the expression and the target values.\n\n    Examples:\n        &gt;&gt;&gt; executable_fun = expr_to_error_function([\"X_0\", \"+\", \"1\"])\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]), np.array([2, 3, 4, 5]))\n        0.0\n        &gt;&gt;&gt; tree = tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1))\n        &gt;&gt;&gt; executable_fun = expr_to_error_function(tree)\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]), np.array([2, 3, 4, 5]))\n        0.0\n        &gt;&gt;&gt; # In case you need libraries other than numpy for the evaluation of your expressions,\n        &gt;&gt;&gt; # you can add them to the preamble in the SymbolLibrary. Here is how a preamble would look like:\n        &gt;&gt;&gt; symbol_library = SymbolLibrary.default_symbols(1)\n        &gt;&gt;&gt; symbol_library.preamble = [\"import numpy as np\"]\n        &gt;&gt;&gt; # Usually this is done when initializing the SymbolLibrary as SymbolLibrary(preamble=preamble)\n        &gt;&gt;&gt; executable_fun = expr_to_error_function(tree, symbol_library)\n        &gt;&gt;&gt; executable_fun(np.array([[1], [2], [3], [4]]), np.array([]), np.array([2, 3, 4, 5]))\n        0.0\n\n    Args:\n        expr: The expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        symbol_library: The symbol library to use. Defaults to SymbolLibrary.default_symbols().\n\n    Raises:\n        Exception: If expression is not of the right type\n\n    Returns:\n        An executable function that takes in a 2D array of input values `X`, a 1D array of constant values `C`, and a 1D array of target values `y`. It returns the root mean squared error between the output of the expression and the target values.\n    \"\"\"\n    if not (isinstance(expr, list) or isinstance(expr, Node)):\n        raise Exception(\n            \"Expression must be given as either a list of tokens or a tree (an instance of the \"\n            \"SRToolkit.utils.expression_tree.Node class)\"\n        )\n\n    if isinstance(expr, list):\n        tree = tokens_to_tree(expr, symbol_library)\n    else:\n        tree = expr\n    code, symbol, var_counter, const_counter = tree_to_function_rec(\n        tree, symbol_library\n    )\n\n    fun_string = \"\\n\".join(symbol_library.preamble) + \"\\ndef _executable_expression_(X, C, y):\\n\"\n    for c in code:\n        fun_string += \"\\t\" + c + \"\\n\"\n    fun_string += f\"\\treturn np.sqrt(np.mean(({symbol}-y)**2))\"\n\n    fun_assignment_dict = {}\n    exec(fun_string, globals(), fun_assignment_dict)\n    return fun_assignment_dict[\"_executable_expression_\"]\n</code></pre>"},{"location":"references/utils/expression_compiler/#SRToolkit.utils.expression_compiler.tree_to_function_rec","title":"tree_to_function_rec","text":"<pre><code>tree_to_function_rec(tree: Node, symbol_library: SymbolLibrary, var_counter: int = 0, const_counter: int = 0) -&gt; Tuple[List[str], str, int, int]\n</code></pre> <p>Recursively converts a parse tree into a string of Python code that can be executed to evaluate the expression represented by the tree. For usage examples, see code for expr_to_executable_function and expr_to_error_function.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>Node</code> <p>The root of the parse tree to convert.</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use when converting the tree. This library defines the properties of the symbols in the tree.</p> required <code>var_counter</code> <code>int</code> <p>The number of variables encountered so far. This is used to create a unique variable name for each variable.</p> <code>0</code> <code>const_counter</code> <code>int</code> <p>The number of constants encountered so far. This is used to select the correct constant value from the constant array.</p> <code>0</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of strings, where each string contains a line of Python code to execute to evaluate the expression represented by the tree.</p> <code>str</code> <p>The name of the variable that represents the output of the expression.</p> <code>int</code> <p>The updated value of <code>var_counter</code>.</p> <code>int</code> <p>The updated value of <code>const_counter</code>.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the parse tree contains an invalid symbol.</p> Notes <p>This function is a helper function for <code>expr_to_executable_function</code> and similar and should not be called directly unless you want to customize the way the expression is defined. For examples, see the code of <code>expr_to_executable_function</code> and <code>expr_to_error_function</code> in this module.</p> Source code in <code>SRToolkit/utils/expression_compiler.py</code> <pre><code>def tree_to_function_rec(\n    tree: Node,\n    symbol_library: SymbolLibrary,\n    var_counter: int = 0,\n    const_counter: int = 0,\n) -&gt; Tuple[List[str], str, int, int]:\n    \"\"\"\n    Recursively converts a parse tree into a string of Python code that can be executed to evaluate the expression\n    represented by the tree. For usage examples, see code for expr_to_executable_function and expr_to_error_function.\n\n    Args:\n        tree: The root of the parse tree to convert.\n        symbol_library: The symbol library to use when converting the tree. This library defines the properties of the symbols in the tree.\n        var_counter: The number of variables encountered so far. This is used to create a unique variable name for each variable.\n        const_counter: The number of constants encountered so far. This is used to select the correct constant value from the constant array.\n\n    Returns:\n        A list of strings, where each string contains a line of Python code to execute to evaluate the expression represented by the tree.\n        The name of the variable that represents the output of the expression.\n        The updated value of `var_counter`.\n        The updated value of `const_counter`.\n\n    Raises:\n        Exception: If the parse tree contains an invalid symbol.\n\n    Notes:\n        This function is a helper function for `expr_to_executable_function` and similar and should not be called directly\n        unless you want to customize the way the expression is defined. For examples, see the code of `expr_to_executable_function` and `expr_to_error_function` in this module.\n    \"\"\"\n    if tree.left is None and tree.right is None:\n        if symbol_library.get_type(tree.symbol) in [\"var\", \"lit\"]:\n            return [], symbol_library.get_np_fn(tree.symbol), var_counter, const_counter\n        elif symbol_library.get_type(tree.symbol) == \"const\":\n            return (\n                [],\n                symbol_library.get_np_fn(tree.symbol).format(const_counter),\n                var_counter,\n                const_counter + 1,\n            )\n        else:\n            if is_float(tree.symbol):\n                return [], tree.symbol, var_counter, const_counter\n            else:\n                raise Exception(\n                    f\"Encountered invalid symbol {tree.symbol} while converting to function.\"\n                )\n\n    elif tree.left is not None and tree.right is None:\n        code, symbol, var_counter, const_counter = tree_to_function_rec(\n            tree.left, symbol_library, var_counter, const_counter\n        )\n        output_symbol = \"y_{}\".format(var_counter)\n        code.append(symbol_library.get_np_fn(tree.symbol).format(output_symbol, symbol))\n        return code, output_symbol, var_counter + 1, const_counter\n\n    else:\n        left_code, left_symbol, var_counter, const_counter = tree_to_function_rec(\n            tree.left, symbol_library, var_counter, const_counter\n        )\n        right_code, right_symbol, var_counter, const_counter = tree_to_function_rec(\n            tree.right, symbol_library, var_counter, const_counter\n        )\n        output_symbol = \"y_{}\".format(var_counter)\n        code = left_code + right_code\n        code.append(\n            symbol_library.get_np_fn(tree.symbol).format(\n                output_symbol, left_symbol, right_symbol\n            )\n        )\n        return code, output_symbol, var_counter + 1, const_counter\n</code></pre>"},{"location":"references/utils/expression_generator/","title":"Expression Generator","text":""},{"location":"references/utils/expression_generator/#SRToolkit.utils.expression_generator","title":"SRToolkit.utils.expression_generator","text":"<p>This module contains helper functions for creating a PCFG with generic probabilities from the SymbolLibrary and to use it for generating random expressions.</p>"},{"location":"references/utils/expression_generator/#SRToolkit.utils.expression_generator.create_generic_pcfg","title":"create_generic_pcfg","text":"<pre><code>create_generic_pcfg(symbol_library: SymbolLibrary) -&gt; str\n</code></pre> <p>Creates a generic PCFG from the SymbolLibrary.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sl = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"sin\", \"^2\", \"pi\"], 2)\n&gt;&gt;&gt; print(create_generic_pcfg(sl))\nE -&gt; E '+' F [0.2]\nE -&gt; E '-' F [0.2]\nE -&gt; F [0.6]\nF -&gt; F '*' B [0.4]\nF -&gt; B [0.6]\nB -&gt; T [1.0]\nT -&gt; R [0.2]\nT -&gt; C [0.2]\nT -&gt; V [0.6]\nC -&gt; 'pi' [1.0]\nR -&gt; 'sin' '(' E ')' [0.4]\nR -&gt; P [0.15]\nR -&gt; '(' E ')' [0.45]\nP -&gt; '(' E ')' '^2' [1.0]\nV -&gt; 'X_0' [0.5]\nV -&gt; 'X_1' [0.5]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use. Defaults to SymbolLibrary.default_symbols().</p> required <p>Returns:</p> Type Description <code>str</code> <p>A PCFG with generic probabilities, written as a string.</p> Source code in <code>SRToolkit/utils/expression_generator.py</code> <pre><code>def create_generic_pcfg(symbol_library: SymbolLibrary) -&gt; str:\n    \"\"\"\n    Creates a generic PCFG from the SymbolLibrary.\n\n    Examples:\n        &gt;&gt;&gt; sl = SymbolLibrary.from_symbol_list([\"+\", \"-\", \"*\", \"sin\", \"^2\", \"pi\"], 2)\n        &gt;&gt;&gt; print(create_generic_pcfg(sl))\n        E -&gt; E '+' F [0.2]\n        E -&gt; E '-' F [0.2]\n        E -&gt; F [0.6]\n        F -&gt; F '*' B [0.4]\n        F -&gt; B [0.6]\n        B -&gt; T [1.0]\n        T -&gt; R [0.2]\n        T -&gt; C [0.2]\n        T -&gt; V [0.6]\n        C -&gt; 'pi' [1.0]\n        R -&gt; 'sin' '(' E ')' [0.4]\n        R -&gt; P [0.15]\n        R -&gt; '(' E ')' [0.45]\n        P -&gt; '(' E ')' '^2' [1.0]\n        V -&gt; 'X_0' [0.5]\n        V -&gt; 'X_1' [0.5]\n        &lt;BLANKLINE&gt;\n\n    Args:\n        symbol_library: The symbol library to use. Defaults to SymbolLibrary.default_symbols().\n\n    Returns:\n        A PCFG with generic probabilities, written as a string.\n    \"\"\"\n    symbols = symbol_library.symbols.values()\n    E = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"op\" and s[\"precedence\"] == 0]\n    F = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"op\" and s[\"precedence\"] == 1]\n    BP = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"op\" and s[\"precedence\"] == 2]\n    R = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"fn\" and s[\"precedence\"] == 5]\n    P = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"fn\" and s[\"precedence\"] == -1]\n    V = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"var\"]\n    Cc = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"const\"]\n    Cl = [s[\"symbol\"] for s in symbols if s[\"type\"] == \"lit\"]\n\n    grammar = \"\"\n    if len(E) &gt; 0:\n        for s in E:\n            grammar += f\"E -&gt; E '{s}' F [{0.4 / len(E)}]\\n\"\n        grammar += \"E -&gt; F [0.6]\\n\"\n    else:\n        grammar += \"E -&gt; F [1.0]\\n\"\n\n    if len(F) &gt; 0:\n        for s in F:\n            grammar += f\"F -&gt; F '{s}' B [{0.4 / len(F)}]\\n\"\n        grammar += \"F -&gt; B [0.6]\\n\"\n    else:\n        grammar += \"F -&gt; B [1.0]\\n\"\n\n    if len(BP) &gt; 0:\n        for s in BP:\n            grammar += f\"B -&gt; B '{s}' T [{0.05 / len(BP)}]\\n\"\n        grammar += \"B -&gt; T [0.95]\\n\"\n    else:\n        grammar += \"B -&gt; T [1.0]\\n\"\n\n    if len(Cc) + len(Cl) &gt; 0:\n        grammar += \"T -&gt; R [0.2]\\n\"\n        grammar += \"T -&gt; C [0.2]\\n\"\n        grammar += \"T -&gt; V [0.6]\\n\"\n        if len(Cl) &gt; 0 and len(Cc) &gt; 0:\n            for s in Cl:\n                grammar += f\"C -&gt; '{s}' [{0.2 / len(Cl)}]\\n\"\n            for s in Cc:\n                grammar += f\"C -&gt; '{s}' [{0.8 / len(Cc)}]\\n\"\n        elif len(Cl) &gt; 0:\n            for s in Cl:\n                grammar += f\"C -&gt; '{s}' [{1 / len(Cl)}]\\n\"\n        elif len(Cc) &gt; 0:\n            for s in Cc:\n                grammar += f\"C -&gt; '{s}' [{1 / len(Cc)}]\\n\"\n    else:\n        grammar += \"T -&gt; R [0.3]\\n\"\n        grammar += \"T -&gt; V [0.7]\\n\"\n\n    if len(R) &gt; 0:\n        for s in R:\n            grammar += f\"R -&gt; '{s}' '(' E ')' [{0.4 / len(R)}]\\n\"\n        if len(P) &gt; 0:\n            grammar += \"R -&gt; P [0.15]\\n\"\n            grammar += \"R -&gt; '(' E ')' [0.45]\\n\"\n        else:\n            grammar += \"R -&gt; '(' E ')' [0.6]\\n\"\n    else:\n        if len(P) &gt; 0:\n            grammar += \"R -&gt; P [0.15]\\n\"\n            grammar += \"R -&gt; '(' E ')' [0.85]\\n\"\n        else:\n            grammar += \"R -&gt; '(' E ')' [1.0]\\n\"\n\n    if len(P) &gt; 0:\n        total = sum([1 / abs(float(s[1:])) for s in P])\n        for s in P:\n            grammar += f\"P -&gt; '(' E ')' '{s}' [{(1 / abs(float(s[1:]))) / total}]\\n\"\n\n    if len(V) &gt; 0:\n        for s in V:\n            grammar += f\"V -&gt; '{s}' [{1 / len(V)}]\\n\"\n\n    return grammar\n</code></pre>"},{"location":"references/utils/expression_generator/#SRToolkit.utils.expression_generator.generate_from_pcfg","title":"generate_from_pcfg","text":"<pre><code>generate_from_pcfg(grammar_str: str, start_symbol: str = 'E', max_depth: int = 40, limit: int = 100) -&gt; List[str]\n</code></pre> <p>Generates a random expression from a PCFG with monte-carlo sampling.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; generate_from_pcfg(\"E -&gt; '1' [1.0]\")\n['1']\n&gt;&gt;&gt; grammar = create_generic_pcfg(SymbolLibrary.default_symbols())\n&gt;&gt;&gt; len(generate_from_pcfg(grammar)) &gt; 0\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>grammar_str</code> <code>str</code> <p>Grammar given as a string in the NLTK notation</p> required <code>start_symbol</code> <code>str</code> <p>Non-terminal symbol used as the starting point</p> <code>'E'</code> <code>max_depth</code> <code>int</code> <p>Maximum depth of the generated parse trees. If less than 0, expressions can have arbitrary depth</p> <code>40</code> <code>limit</code> <code>int</code> <p>Number of times the function tries to generate a valid expression before raising an Exception.</p> <code>100</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If the maximum number of tries is reached without generating a valid expression</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>An expression written as a list of string tokens in the infix notation.</p> Source code in <code>SRToolkit/utils/expression_generator.py</code> <pre><code>def generate_from_pcfg(\n    grammar_str: str, start_symbol: str = \"E\", max_depth: int = 40, limit: int = 100\n) -&gt; List[str]:\n    \"\"\"\n    Generates a random expression from a PCFG with monte-carlo sampling.\n\n    Examples:\n        &gt;&gt;&gt; generate_from_pcfg(\"E -&gt; '1' [1.0]\")\n        ['1']\n        &gt;&gt;&gt; grammar = create_generic_pcfg(SymbolLibrary.default_symbols())\n        &gt;&gt;&gt; len(generate_from_pcfg(grammar)) &gt; 0\n        True\n\n    Args:\n        grammar_str: Grammar given as a string in the NLTK notation\n        start_symbol: Non-terminal symbol used as the starting point\n        max_depth: Maximum depth of the generated parse trees. If less than 0, expressions can have arbitrary depth\n        limit: Number of times the function tries to generate a valid expression before raising an Exception.\n\n    Raises:\n        Exception: If the maximum number of tries is reached without generating a valid expression\n\n    Returns:\n        An expression written as a list of string tokens in the infix notation.\n    \"\"\"\n    start_symbol = nltk.grammar.Nonterminal(start_symbol)\n    grammar = nltk.PCFG.fromstring(grammar_str)\n    expr = _expand(grammar, start_symbol, 0, max_depth)\n    tries = 1\n    while expr is None and tries &lt; limit:\n        expr = _expand(grammar, start_symbol, 0, max_depth)\n\n    if expr is None:\n        raise Exception(\n            f\"[Expression generation] Couldn't find an expression with max_depth {max_depth} from this grammar in {limit} tries.\"\n        )\n\n    return expr\n</code></pre>"},{"location":"references/utils/expression_generator/#SRToolkit.utils.expression_generator.generate_n_expressions","title":"generate_n_expressions","text":"<pre><code>generate_n_expressions(expression_description: Union[str, SymbolLibrary], num_expressions: int, unique: bool = True, max_expression_length: int = 50, verbose: bool = True) -&gt; List[List[str]]\n</code></pre> <p>Generates a set of n expressions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; len(generate_n_expressions(SymbolLibrary.default_symbols(5), 100, verbose=False))\n100\n&gt;&gt;&gt; generate_n_expressions(SymbolLibrary.from_symbol_list([], 1), 3, unique=False, verbose=False, max_expression_length=1)\n[['X_0'], ['X_0'], ['X_0']]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expression_description</code> <code>Union[str, SymbolLibrary]</code> <p>Decription of expressions, given as either a grammar in the NLTK notation or a SymbolLibrary instance</p> required <code>num_expressions</code> <code>int</code> <p>Number of generated expressions</p> required <code>unique</code> <code>bool</code> <p>When True, each generated expression will be unique (not necesarily unequivalent to others)</p> <code>True</code> <code>max_expression_length</code> <code>int</code> <p>Generated expressions will have at most \"max_expression_length\" tokens. If less than 0, expressions can be of arbitrary size.</p> <code>50</code> <code>verbose</code> <code>bool</code> <p>If True, adds a progress bar</p> <code>True</code> <p>Returns:</p> Type Description <code>List[List[str]]</code> <p>A list of expressions represented as lists of tokens</p> Source code in <code>SRToolkit/utils/expression_generator.py</code> <pre><code>def generate_n_expressions(\n    expression_description: Union[str, SymbolLibrary],\n    num_expressions: int,\n    unique: bool = True,\n    max_expression_length: int = 50,\n    verbose: bool = True,\n) -&gt; List[List[str]]:\n    \"\"\"\n    Generates a set of n expressions.\n\n    Examples:\n        &gt;&gt;&gt; len(generate_n_expressions(SymbolLibrary.default_symbols(5), 100, verbose=False))\n        100\n        &gt;&gt;&gt; generate_n_expressions(SymbolLibrary.from_symbol_list([], 1), 3, unique=False, verbose=False, max_expression_length=1)\n        [['X_0'], ['X_0'], ['X_0']]\n\n    Args:\n        expression_description: Decription of expressions, given as either a grammar in the NLTK notation or a SymbolLibrary instance\n        num_expressions: Number of generated expressions\n        unique: When True, each generated expression will be unique (not necesarily unequivalent to others)\n        max_expression_length: Generated expressions will have at most \"max_expression_length\" tokens. If less than 0, expressions can be of arbitrary size.\n        verbose: If True, adds a progress bar\n\n    Returns:\n        A list of expressions represented as lists of tokens\n    \"\"\"\n    if isinstance(expression_description, SymbolLibrary):\n        grammar = create_generic_pcfg(expression_description)\n    elif isinstance(expression_description, str):\n        grammar = expression_description\n    else:\n        raise Exception(\n            \"Description of expressions must be either a grammar written as a string or an instance of SymbolLibrary.\"\n        )\n\n    expressions = []\n    expression_strings = set()\n    if verbose:\n        pbar = tqdm(total=num_expressions)\n    while len(expressions) &lt; num_expressions:\n        try:\n            expr = generate_from_pcfg(grammar, max_depth=max_expression_length * 10)\n        except Exception:\n            print(\"Couldn't generate a valid expression in 100 tries\")\n            continue\n        if len(expr) &gt; max_expression_length &gt; 0:\n            continue\n\n        expr_string = \"\".join(expr)\n        if expr_string not in expression_strings or not unique:\n            expressions.append(expr)\n            expression_strings.add(expr_string)\n            if verbose:\n                pbar.update(1)\n\n    if verbose:\n        pbar.close()\n    return expressions\n</code></pre>"},{"location":"references/utils/expression_simplifier/","title":"Expression Simplifier","text":""},{"location":"references/utils/expression_simplifier/#SRToolkit.utils.expression_simplifier","title":"SRToolkit.utils.expression_simplifier","text":""},{"location":"references/utils/expression_simplifier/#SRToolkit.utils.expression_simplifier.simplify","title":"simplify","text":"<pre><code>simplify(expr: Union[List[str], Node], symbol_library: SymbolLibrary = SymbolLibrary.default_symbols()) -&gt; Union[List[str], Node]\n</code></pre> Simplifies a mathematical expression by <ol> <li>Making use of sympy's simplification functions</li> <li>Simplifying constants, e.g. C*C + C -&gt; C</li> </ol> <p>Examples:</p> <pre><code>&gt;&gt;&gt; expr = [\"C\", \"+\", \"C\" \"*\", \"C\", \"+\", \"X_0\", \"*\", \"X_1\", \"/\", \"X_0\"]\n&gt;&gt;&gt; print(\"\".join(simplify(expr)))\nC+X_1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[List[str], Node]</code> <p>The expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use. Defaults to SymbolLibrary.default_symbols().</p> <code>default_symbols()</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If problems occur during simplification or if the expression contains invalid symbols.</p> <p>Returns:</p> Type Description <code>Union[List[str], Node]</code> <p>The simplified expression</p> Source code in <code>SRToolkit/utils/expression_simplifier.py</code> <pre><code>def simplify(\n    expr: Union[List[str], Node],\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n) -&gt; Union[List[str], Node]:\n    \"\"\"\n    Simplifies a mathematical expression by:\n        1. Making use of sympy's simplification functions\n        2. Simplifying constants, e.g. C*C + C -&gt; C\n\n    Examples:\n        &gt;&gt;&gt; expr = [\"C\", \"+\", \"C\" \"*\", \"C\", \"+\", \"X_0\", \"*\", \"X_1\", \"/\", \"X_0\"]\n        &gt;&gt;&gt; print(\"\".join(simplify(expr)))\n        C+X_1\n\n    Args:\n        expr: The expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        symbol_library: The symbol library to use. Defaults to SymbolLibrary.default_symbols().\n\n    Raises:\n        Exception: If problems occur during simplification or if the expression contains invalid symbols.\n\n    Returns:\n        The simplified expression\n    \"\"\"\n    is_tree = False\n    if isinstance(expr, Node):\n        expr = expr.to_list(symbol_library=symbol_library, notation=\"infix\")\n        is_tree = True\n\n    variables = symbol_library.get_symbols_of_type(\"var\")\n\n    # We expect only one symbol for constants\n    if len(symbol_library.get_symbols_of_type(\"const\")) &gt; 0:\n        constant = symbol_library.get_symbols_of_type(\"const\")[0]\n    else:\n        # In this case constants shouldn't be problematic as they are not in the SymbolLibrary\n        # Just in case and to not change other functions, I changed it to __C__.\n        constant = \"__C__\"\n\n    expr = _simplify_expression(\"\".join(expr), constant, variables)\n    expr = sympify(_denumerate_constants(str(expr), constant), evaluate=False)\n    expr = _sympy_to_sr(expr)\n    if not _check_tree(expr, symbol_library):\n        raise Exception(\n            \"Simplified expression contains invalid symbols. Possibly skip its simplification or add symbols to the SymbolLibrary.\"\n        )\n\n    if is_tree:\n        return expr\n    else:\n        return expr.to_list(symbol_library=symbol_library, notation=\"infix\")\n</code></pre>"},{"location":"references/utils/expression_tree/","title":"Expression Tree","text":""},{"location":"references/utils/expression_tree/#SRToolkit.utils.expression_tree","title":"SRToolkit.utils.expression_tree","text":"<p>The module containing the expression tree data structure and functions for transforming expressions into trees and back.</p>"},{"location":"references/utils/expression_tree/#SRToolkit.utils.expression_tree.Node","title":"Node","text":"<pre><code>Node(symbol: str = None, right: Node = None, left: Node = None)\n</code></pre> <p>Initializes a Node object. We assume that nodes containing functions have only one child node, i.e. right is None.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n&gt;&gt;&gt; len(node)\n3\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol string stored in this node.</p> <code>None</code> <code>right</code> <code>Node</code> <p>The right child of this node.</p> <code>None</code> <code>left</code> <code>Node</code> <p>The left child of this node.</p> <code>None</code> <p>Functions:</p> Name Description <code>__len__</code> <p>Returns the number of nodes in the tree rooted at this node.</p> <code>height</code> <p>Returns the height of the tree rooted at this node.</p> <code>__str__</code> <p>Returns a string representation of the tree rooted at this node.</p> <code>to_list</code> <p>str = \"infix\", symbol_library: SymbolLibrary = None): Returns a list representation of the tree rooted at this node.</p> <code>to_latex</code> <p>SymbolLibrary): Returns a LaTeX representation of the tree rooted at this node.</p> <code>__copy__</code> <p>Returns a copy of the expression (tree).</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def __init__(self, symbol: str = None, right: \"Node\" = None, left: \"Node\" = None):\n    \"\"\"\n    Initializes a Node object. We assume that nodes containing functions have only one child node, i.e. right is None.\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n        &gt;&gt;&gt; len(node)\n        3\n\n    Args:\n        symbol: The symbol string stored in this node.\n        right: The right child of this node.\n        left: The left child of this node.\n\n    Methods:\n        __len__(self):\n            Returns the number of nodes in the tree rooted at this node.\n        height(self):\n            Returns the height of the tree rooted at this node.\n        __str__(self):\n            Returns a string representation of the tree rooted at this node.\n        to_list(self, notation: str = \"infix\", symbol_library: SymbolLibrary = None):\n            Returns a list representation of the tree rooted at this node.\n        to_latex(self, symbol_library: SymbolLibrary):\n            Returns a LaTeX representation of the tree rooted at this node.\n        __copy__(self):\n            Returns a copy of the expression (tree).\n\n    \"\"\"\n    self.symbol = symbol\n    self.right = right\n    self.left = left\n</code></pre>"},{"location":"references/utils/expression_tree/#SRToolkit.utils.expression_tree.Node.to_list","title":"to_list","text":"<pre><code>to_list(symbol_library: SymbolLibrary = None, notation: str = 'infix') -&gt; List[str]\n</code></pre> <p>Transforms the tree rooted at this node into a list of tokens.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n&gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n['1', '+', 'X_0']\n&gt;&gt;&gt; node.to_list(notation=\"postfix\")\n['1', 'X_0', '+']\n&gt;&gt;&gt; node.to_list(notation=\"prefix\")\n['+', '1', 'X_0']\n&gt;&gt;&gt; node = Node(\"+\", Node(\"*\", Node(\"X_0\"), Node(\"X_1\")), Node(\"1\"))\n&gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n['1', '+', 'X_1', '*', 'X_0']\n&gt;&gt;&gt; node.to_list(notation=\"infix\")\n['1', '+', '(', 'X_1', '*', 'X_0', ')']\n&gt;&gt;&gt; node = Node(\"sin\", None, Node(\"X_0\"))\n&gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n['sin', '(', 'X_0', ')']\n&gt;&gt;&gt; node = Node(\"^2\", None, Node(\"X_0\"))\n&gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n['X_0', '^2']\n&gt;&gt;&gt; node.to_list()\n['(', 'X_0', ')', '^2']\n&gt;&gt;&gt; node = Node(\"*\", Node(\"*\", Node(\"X_0\"), Node(\"X_0\")),  Node(\"X_0\"))\n&gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols(),notation=\"infix\")\n['X_0', '*', '(', 'X_0', '*', 'X_0', ')']\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>notation</code> <code>str</code> <p>The notation to use for the resulting list of tokens. One of \"prefix\", \"postfix\", or \"infix\".</p> <code>'infix'</code> <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use when converting the tree. This library defines the properties of the symbols in the tree.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of tokens representing the tree rooted at this node in the specified notation.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the notation is not one of \"prefix\", \"postfix\", or \"infix\" or if a symbol is not in the symbol library.</p> Notes <p>If the notation is \"infix\" and the symbol library is not provided, then the resulting list of tokens may contain unnecessary parentheses or have other issues.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def to_list(\n    self, symbol_library: SymbolLibrary = None, notation: str = \"infix\"\n) -&gt; List[str]:\n    \"\"\"\n    Transforms the tree rooted at this node into a list of tokens.\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n        &gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n        ['1', '+', 'X_0']\n        &gt;&gt;&gt; node.to_list(notation=\"postfix\")\n        ['1', 'X_0', '+']\n        &gt;&gt;&gt; node.to_list(notation=\"prefix\")\n        ['+', '1', 'X_0']\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"*\", Node(\"X_0\"), Node(\"X_1\")), Node(\"1\"))\n        &gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n        ['1', '+', 'X_1', '*', 'X_0']\n        &gt;&gt;&gt; node.to_list(notation=\"infix\")\n        ['1', '+', '(', 'X_1', '*', 'X_0', ')']\n        &gt;&gt;&gt; node = Node(\"sin\", None, Node(\"X_0\"))\n        &gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n        ['sin', '(', 'X_0', ')']\n        &gt;&gt;&gt; node = Node(\"^2\", None, Node(\"X_0\"))\n        &gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n        ['X_0', '^2']\n        &gt;&gt;&gt; node.to_list()\n        ['(', 'X_0', ')', '^2']\n        &gt;&gt;&gt; node = Node(\"*\", Node(\"*\", Node(\"X_0\"), Node(\"X_0\")),  Node(\"X_0\"))\n        &gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols(),notation=\"infix\")\n        ['X_0', '*', '(', 'X_0', '*', 'X_0', ')']\n\n    Args:\n        notation: The notation to use for the resulting list of tokens. One of \"prefix\", \"postfix\", or \"infix\".\n        symbol_library: The symbol library to use when converting the tree. This library defines the properties of the symbols in the tree.\n\n    Returns:\n        A list of tokens representing the tree rooted at this node in the specified notation.\n\n    Raises:\n         Exception: If the notation is not one of \"prefix\", \"postfix\", or \"infix\" or if a symbol is not in the symbol library.\n\n    Notes:\n        If the notation is \"infix\" and the symbol library is not provided, then the resulting list of tokens may contain unnecessary parentheses or have other issues.\n    \"\"\"\n    left = [] if self.left is None else self.left.to_list(symbol_library, notation)\n    right = (\n        [] if self.right is None else self.right.to_list(symbol_library, notation)\n    )\n\n    if notation == \"prefix\":\n        return [self.symbol] + left + right\n\n    elif notation == \"postfix\":\n        return left + right + [self.symbol]\n\n    elif notation == \"infix\" and symbol_library is None:\n        warnings.warn(\n            \"Symbol library not provided. Generated expression may contain unnecessary parentheses and\"\n            \" have other issues.\"\n        )\n        if self.left is None and self.right is None:\n            return [self.symbol]\n        if self.right is None and self.left is not None:\n            if self.symbol[0] == \"^\":\n                return [\"(\"] + left + [\")\", self.symbol]\n            else:\n                return [self.symbol, \"(\"] + left + [\")\"]\n        else:\n            if len(left) &gt; 1:\n                left = [\"(\"] + left + [\")\"]\n            if len(right) &gt; 1:\n                right = [\"(\"] + right + [\")\"]\n            return left + [self.symbol] + right\n\n    elif notation == \"infix\":\n        if is_float(self.symbol):\n            return [self.symbol]\n        if symbol_library.get_type(self.symbol) in [\"var\", \"const\", \"lit\"]:\n            return [self.symbol]\n        elif symbol_library.get_type(self.symbol) == \"fn\":\n            if symbol_library.get_precedence(self.symbol) &gt; 0:\n                return [self.symbol, \"(\"] + left + [\")\"]\n            else:\n                if len(left) &gt; 1:\n                    left = [\"(\"] + left + [\")\"]\n                return left + [self.symbol]\n        elif symbol_library.get_type(self.symbol) == \"op\":\n            if not is_float(\n                self.left.symbol\n            ) and -1 &lt; symbol_library.get_precedence(\n                self.left.symbol\n            ) &lt;= symbol_library.get_precedence(self.symbol):\n                left = [\"(\"] + left + [\")\"]\n            if not is_float(\n                self.right.symbol\n            ) and -1 &lt; symbol_library.get_precedence(\n                self.right.symbol\n            ) &lt;= symbol_library.get_precedence(self.symbol):\n                right = [\"(\"] + right + [\")\"]\n            return left + [self.symbol] + right\n        else:\n            raise Exception(f\"Invalid symbol type for symbol {self.symbol}.\")\n    else:\n        raise Exception(\n            \"Invalid notation selected. Use 'infix', 'prefix', 'postfix', or leave blank (defaults to 'infix').\"\n        )\n</code></pre>"},{"location":"references/utils/expression_tree/#SRToolkit.utils.expression_tree.Node.to_latex","title":"to_latex","text":"<pre><code>to_latex(symbol_library: SymbolLibrary) -&gt; str\n</code></pre> <p>Transforms the tree rooted at this node into a LaTeX expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n&gt;&gt;&gt; node.to_latex(symbol_library=SymbolLibrary.default_symbols())\n'$1 + X_{0}$'\n&gt;&gt;&gt; node = Node(\"+\", Node(\"*\", Node(\"X_0\"), Node(\"X_1\")), Node(\"1\"))\n&gt;&gt;&gt; print(node.to_latex(symbol_library=SymbolLibrary.default_symbols()))\n$1 + X_{1} \\cdot X_{0}$\n&gt;&gt;&gt; node = Node(\"sin\", None, Node(\"X_0\"))\n&gt;&gt;&gt; print(node.to_latex(symbol_library=SymbolLibrary.default_symbols()))\n$\\sin X_{0}$\n&gt;&gt;&gt; node = Node(\"+\", Node(\"*\", Node(\"X_0\"), Node(\"C\")), Node(\"C\"))\n&gt;&gt;&gt; print(node.to_latex(symbol_library=SymbolLibrary.default_symbols()))\n$C_{0} + C_{1} \\cdot X_{0}$\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use when converting the tree. This library defines the properties of the symbols in the tree.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A latex string representing the tree rooted at this node.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the notation is not one of \"prefix\", \"postfix\", or \"infix\" or if a symbol is not in the symbol library.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def to_latex(self, symbol_library: SymbolLibrary) -&gt; str:\n    r\"\"\"\n    Transforms the tree rooted at this node into a LaTeX expression.\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n        &gt;&gt;&gt; node.to_latex(symbol_library=SymbolLibrary.default_symbols())\n        '$1 + X_{0}$'\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"*\", Node(\"X_0\"), Node(\"X_1\")), Node(\"1\"))\n        &gt;&gt;&gt; print(node.to_latex(symbol_library=SymbolLibrary.default_symbols()))\n        $1 + X_{1} \\cdot X_{0}$\n        &gt;&gt;&gt; node = Node(\"sin\", None, Node(\"X_0\"))\n        &gt;&gt;&gt; print(node.to_latex(symbol_library=SymbolLibrary.default_symbols()))\n        $\\sin X_{0}$\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"*\", Node(\"X_0\"), Node(\"C\")), Node(\"C\"))\n        &gt;&gt;&gt; print(node.to_latex(symbol_library=SymbolLibrary.default_symbols()))\n        $C_{0} + C_{1} \\cdot X_{0}$\n\n    Args:\n        symbol_library: The symbol library to use when converting the tree. This library defines the properties of the symbols in the tree.\n\n    Returns:\n        A latex string representing the tree rooted at this node.\n\n    Raises:\n         Exception: If the notation is not one of \"prefix\", \"postfix\", or \"infix\" or if a symbol is not in the symbol library.\n    \"\"\"\n    assert symbol_library is not None, (\n        \"[Node.to_latex] parameter symbol_library should be of type SymbolLibrary\"\n    )\n    return f\"${self.__to_latex_rec(symbol_library)[0]}$\"\n</code></pre>"},{"location":"references/utils/expression_tree/#SRToolkit.utils.expression_tree.Node.height","title":"height","text":"<pre><code>height() -&gt; int\n</code></pre> <p>Returns the height of the tree rooted at this node.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n&gt;&gt;&gt; node.height()\n2\n</code></pre> <p>Returns:</p> Type Description <code>int</code> <p>The height of the tree rooted at this node.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def height(self) -&gt; int:\n    \"\"\"\n    Returns the height of the tree rooted at this node.\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n        &gt;&gt;&gt; node.height()\n        2\n\n    Returns:\n        The height of the tree rooted at this node.\n    \"\"\"\n    return 1 + max(\n        (self.left.height() if self.left is not None else 0),\n        (self.right.height() if self.right is not None else 0),\n    )\n</code></pre>"},{"location":"references/utils/expression_tree/#SRToolkit.utils.expression_tree.Node.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Returns the number of nodes in the tree rooted at this node.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n&gt;&gt;&gt; len(node)\n3\n</code></pre> <p>Returns:</p> Type Description <code>int</code> <p>The number of nodes in the tree rooted at this node.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Returns the number of nodes in the tree rooted at this node.\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n        &gt;&gt;&gt; len(node)\n        3\n\n    Returns:\n        The number of nodes in the tree rooted at this node.\n    \"\"\"\n    return (\n        1\n        + (len(self.left) if self.left is not None else 0)\n        + (len(self.right) if self.right is not None else 0)\n    )\n</code></pre>"},{"location":"references/utils/expression_tree/#SRToolkit.utils.expression_tree.Node.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Returns a string representation of the tree rooted at this node.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n&gt;&gt;&gt; str(node)\n'1+x'\n</code></pre> <p>Returns:</p> Type Description <code>str</code> <p>A string representation of the tree rooted at this node.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Returns a string representation of the tree rooted at this node.\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"x\"), Node(\"1\"))\n        &gt;&gt;&gt; str(node)\n        '1+x'\n\n    Returns:\n        A string representation of the tree rooted at this node.\n    \"\"\"\n    return \"\".join(self.to_list())\n</code></pre>"},{"location":"references/utils/expression_tree/#SRToolkit.utils.expression_tree.Node.__copy__","title":"__copy__","text":"<pre><code>__copy__() -&gt; Node\n</code></pre> <p>Creates a copy of the expression (usefull for manipulating expressions).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; node = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n&gt;&gt;&gt; new_node = copy(node)\n&gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n['1', '+', 'X_0']\n&gt;&gt;&gt; new_node.to_list(symbol_library=SymbolLibrary.default_symbols())\n['1', '+', 'X_0']\n&gt;&gt;&gt; node == node\nTrue\n&gt;&gt;&gt; node == new_node\nFalse\n</code></pre> <p>Returns:</p> Type Description <code>Node</code> <p>A copy of the expression (tree).</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def __copy__(self) -&gt; \"Node\":\n    \"\"\"\n    Creates a copy of the expression (usefull for manipulating expressions).\n\n    Examples:\n        &gt;&gt;&gt; node = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n        &gt;&gt;&gt; new_node = copy(node)\n        &gt;&gt;&gt; node.to_list(symbol_library=SymbolLibrary.default_symbols())\n        ['1', '+', 'X_0']\n        &gt;&gt;&gt; new_node.to_list(symbol_library=SymbolLibrary.default_symbols())\n        ['1', '+', 'X_0']\n        &gt;&gt;&gt; node == node\n        True\n        &gt;&gt;&gt; node == new_node\n        False\n\n    Returns:\n        A copy of the expression (tree).\n    \"\"\"\n    if self.left is not None:\n        left = copy(self.left)\n    else:\n        left = None\n    if self.right is not None:\n        right = copy(self.right)\n    else:\n        right = None\n    return Node(copy(self.symbol), left=left, right=right)\n</code></pre>"},{"location":"references/utils/expression_tree/#SRToolkit.utils.expression_tree.is_float","title":"is_float","text":"<pre><code>is_float(element: any) -&gt; bool\n</code></pre> <p>Checks if a given element is a float.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_float(1.0)\nTrue\n&gt;&gt;&gt; is_float(\"1.0\")\nTrue\n&gt;&gt;&gt; is_float(\"1\")\nTrue\n&gt;&gt;&gt; is_float(None)\nFalse\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>element</code> <code>any</code> <p>The element to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the element is a float, False otherwise.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def is_float(element: any) -&gt; bool:\n    \"\"\"\n    Checks if a given element is a float.\n\n    Examples:\n        &gt;&gt;&gt; is_float(1.0)\n        True\n        &gt;&gt;&gt; is_float(\"1.0\")\n        True\n        &gt;&gt;&gt; is_float(\"1\")\n        True\n        &gt;&gt;&gt; is_float(None)\n        False\n\n\n    Args:\n        element: The element to check.\n\n    Returns:\n        True if the element is a float, False otherwise.\n    \"\"\"\n    if element is None:\n        return False\n    try:\n        float(element)\n        return True\n    except ValueError:\n        return False\n</code></pre>"},{"location":"references/utils/expression_tree/#SRToolkit.utils.expression_tree.tokens_to_tree","title":"tokens_to_tree","text":"<pre><code>tokens_to_tree(tokens: List[str], sl: SymbolLibrary) -&gt; Node\n</code></pre> <p>Converts a list of tokens to a tree data structure. Throws an exception if the expression is invalid (check syntax and that all symbols are in the symbol library correctly defined).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tree = tokens_to_tree([\"(\", \"X_0\", \"+\", \"X_1\", \")\"], SymbolLibrary.default_symbols())\n&gt;&gt;&gt; len(tree)\n3\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>List[str]</code> <p>The list of tokens to convert.</p> required <code>sl</code> <code>SymbolLibrary</code> <p>The symbol library to use when parsing the tokens.</p> required <p>Returns:</p> Type Description <code>Node</code> <p>The root of the expression tree data structure.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the expression is invalid. Usually this means that a symbol is not in the symbol library or that        there is a syntactic error in the expression.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def tokens_to_tree(tokens: List[str], sl: SymbolLibrary) -&gt; Node:\n    \"\"\"\n    Converts a list of tokens to a tree data structure. Throws an exception if the expression is invalid (check syntax\n    and that all symbols are in the symbol library correctly defined).\n\n    Examples:\n        &gt;&gt;&gt; tree = tokens_to_tree([\"(\", \"X_0\", \"+\", \"X_1\", \")\"], SymbolLibrary.default_symbols())\n        &gt;&gt;&gt; len(tree)\n        3\n\n    Args:\n        tokens: The list of tokens to convert.\n        sl: The symbol library to use when parsing the tokens.\n\n    Returns:\n        The root of the expression tree data structure.\n\n    Raises:\n        Exception: If the expression is invalid. Usually this means that a symbol is not in the symbol library or that\n                   there is a syntactic error in the expression.\n    \"\"\"\n    num_tokens = len([t for t in tokens if t != \"(\" and t != \")\"])\n    expr_str = \"\".join(tokens)\n    tokens = [\"(\"] + tokens + [\")\"]\n    operator_stack = []\n    out_stack = []\n    for token in tokens:\n        if token == \"(\":\n            operator_stack.append(token)\n        elif sl.get_type(token) in [\"var\", \"const\", \"lit\"] or is_float(token):\n            out_stack.append(Node(token))\n        elif sl.get_type(token) == \"fn\":\n            if token[0] == \"^\":\n                out_stack.append(Node(token, left=out_stack.pop()))\n            else:\n                operator_stack.append(token)\n        elif sl.get_type(token) == \"op\":\n            while (\n                len(operator_stack) &gt; 0\n                and operator_stack[-1] != \"(\"\n                and sl.get_precedence(operator_stack[-1]) &gt;= sl.get_precedence(token)\n            ):\n                if sl.get_type(operator_stack[-1]) == \"fn\":\n                    out_stack.append(Node(operator_stack.pop(), left=out_stack.pop()))\n                else:\n                    out_stack.append(\n                        Node(operator_stack.pop(), out_stack.pop(), out_stack.pop())\n                    )\n            operator_stack.append(token)\n        else:\n            if token != \")\":\n                raise Exception(\n                    f'Invalid symbol \"{token}\" in expression {expr_str}. Did you add token \"{token}\" to the symbol library?'\n                )\n\n            while len(operator_stack) &gt; 0 and operator_stack[-1] != \"(\":\n                if sl.get_type(operator_stack[-1]) == \"fn\":\n                    out_stack.append(Node(operator_stack.pop(), left=out_stack.pop()))\n                else:\n                    out_stack.append(\n                        Node(operator_stack.pop(), out_stack.pop(), out_stack.pop())\n                    )\n            operator_stack.pop()\n            if len(operator_stack) &gt; 0 and sl.get_type(operator_stack[-1]) == \"fn\":\n                out_stack.append(Node(operator_stack.pop(), left=out_stack.pop()))\n    if len(out_stack[-1]) == num_tokens:\n        return out_stack[-1]\n    else:\n        raise Exception(f\"Error while parsing expression {expr_str}.\")\n</code></pre>"},{"location":"references/utils/expression_tree/#SRToolkit.utils.expression_tree.expr_to_latex","title":"expr_to_latex","text":"<pre><code>expr_to_latex(expr: Union[Node, List[str]], symbol_library: SymbolLibrary) -&gt; str\n</code></pre> <p>Transforms an expression into a LaTeX string.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; expr_to_latex([\"(\", \"X_0\", \"+\", \"X_1\", \")\"], SymbolLibrary.default_symbols())\n'$X_{0} + X_{1}$'\n&gt;&gt;&gt; expr = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n&gt;&gt;&gt; expr_to_latex(expr, SymbolLibrary.default_symbols())\n'$1 + X_{0}$'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[Node, List[str]]</code> <p>An expression</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A LaTeX string representing the expression.</p> Source code in <code>SRToolkit/utils/expression_tree.py</code> <pre><code>def expr_to_latex(expr: Union[Node, List[str]], symbol_library: SymbolLibrary) -&gt; str:\n    \"\"\"\n    Transforms an expression into a LaTeX string.\n\n    Examples:\n        &gt;&gt;&gt; expr_to_latex([\"(\", \"X_0\", \"+\", \"X_1\", \")\"], SymbolLibrary.default_symbols())\n        '$X_{0} + X_{1}$'\n        &gt;&gt;&gt; expr = Node(\"+\", Node(\"X_0\"), Node(\"1\"))\n        &gt;&gt;&gt; expr_to_latex(expr, SymbolLibrary.default_symbols())\n        '$1 + X_{0}$'\n\n    Args:\n        expr: An expression\n        symbol_library: The symbol library.\n\n    Returns:\n        A LaTeX string representing the expression.\n    \"\"\"\n    try:\n        if isinstance(expr, Node):\n            return expr.to_latex(symbol_library)\n        elif isinstance(expr, list):\n            return tokens_to_tree(expr, symbol_library).to_latex(symbol_library)\n        else:\n            raise Exception(\n                f\"Invalid type for expression {str(expr)}. Should be SRToolkit.utils.Node or a list of tokens.\"\n            )\n    except Exception as e:\n        print(f\"Error while converting expression {str(expr)} to LaTeX: {str(e)}\")\n        return \"\"\n</code></pre>"},{"location":"references/utils/measures/","title":"Measures","text":""},{"location":"references/utils/measures/#SRToolkit.utils.measures","title":"SRToolkit.utils.measures","text":"<p>This module contains measures for evaluating the similarity between two expressions.</p>"},{"location":"references/utils/measures/#SRToolkit.utils.measures.edit_distance","title":"edit_distance","text":"<pre><code>edit_distance(expr1: Union[List[str], Node], expr2: Union[List[str], Node], notation: str = 'postfix', symbol_library: SymbolLibrary = SymbolLibrary.default_symbols()) -&gt; int\n</code></pre> <p>Calculates the edit distance between two expressions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"+\", \"1\"])\n0\n&gt;&gt;&gt; edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"-\", \"1\"])\n1\n&gt;&gt;&gt; edit_distance(tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1)), tokens_to_tree([\"X_0\", \"-\", \"1\"], SymbolLibrary.default_symbols(1)))\n1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr1</code> <code>Union[List[str], Node]</code> <p>Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>expr2</code> <code>Union[List[str], Node]</code> <p>Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>notation</code> <code>str</code> <p>The notation in which the distance between the two expressions is computed. Can be one of \"infix\", \"postfix\", or \"prefix\". By default, \"postfix\" is used to avoid inconsistencies that occur because of parenthesis.</p> <code>'postfix'</code> <code>symbol_library</code> <code>SymbolLibrary</code> <p>The symbol library to use when converting the expressions to lists of tokens and vice versa. Defaults to SymbolLibrary.default_symbols().</p> <code>default_symbols()</code> <p>Returns:</p> Type Description <code>int</code> <p>The edit distance between the two expressions written in a given notation.</p> Source code in <code>SRToolkit/utils/measures.py</code> <pre><code>def edit_distance(\n    expr1: Union[List[str], Node],\n    expr2: Union[List[str], Node],\n    notation: str = \"postfix\",\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n) -&gt; int:\n    \"\"\"\n    Calculates the edit distance between two expressions.\n\n    Examples:\n        &gt;&gt;&gt; edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"+\", \"1\"])\n        0\n        &gt;&gt;&gt; edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"-\", \"1\"])\n        1\n        &gt;&gt;&gt; edit_distance(tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1)), tokens_to_tree([\"X_0\", \"-\", \"1\"], SymbolLibrary.default_symbols(1)))\n        1\n\n    Args:\n        expr1: Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        expr2: Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        notation: The notation in which the distance between the two expressions is computed. Can be one of \"infix\", \"postfix\", or \"prefix\".\n            By default, \"postfix\" is used to avoid inconsistencies that occur because of parenthesis.\n        symbol_library: The symbol library to use when converting the expressions to lists of tokens and vice versa. Defaults to SymbolLibrary.default_symbols().\n\n    Returns:\n        The edit distance between the two expressions written in a given notation.\n    \"\"\"\n    if isinstance(expr1, Node):\n        expr1 = expr1.to_list(symbol_library=symbol_library, notation=notation)\n    elif isinstance(expr1, list):\n        expr1 = tokens_to_tree(expr1, symbol_library).to_list(\n            symbol_library=symbol_library, notation=notation\n        )\n\n    if isinstance(expr2, Node):\n        expr2 = expr2.to_list(symbol_library=symbol_library, notation=notation)\n    elif isinstance(expr2, list):\n        expr2 = tokens_to_tree(expr2, symbol_library).to_list(\n            symbol_library=symbol_library, notation=notation\n        )\n\n    return editdistance.eval(expr1, expr2)\n</code></pre>"},{"location":"references/utils/measures/#SRToolkit.utils.measures.tree_edit_distance","title":"tree_edit_distance","text":"<pre><code>tree_edit_distance(expr1: Union[Node, List[str]], expr2: Union[Node, List[str]], symbol_library: SymbolLibrary = SymbolLibrary.default_symbols()) -&gt; int\n</code></pre> <p>Calculates the tree edit distance between two expressions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tree_edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"+\", \"1\"])\n0\n&gt;&gt;&gt; tree_edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"-\", \"1\"])\n1\n&gt;&gt;&gt; tree_edit_distance(tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1)), tokens_to_tree([\"X_0\", \"-\", \"1\"], SymbolLibrary.default_symbols(1)))\n1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr1</code> <code>Union[Node, List[str]]</code> <p>Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>expr2</code> <code>Union[Node, List[str]]</code> <p>Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node</p> required <code>symbol_library</code> <code>SymbolLibrary</code> <p>Symbol library to use when converting the lists of tokens into an instance of SRToolkit.utils.expression_tree.Node.</p> <code>default_symbols()</code> <p>Returns:</p> Type Description <code>int</code> <p>The tree edit distance between the two expressions.</p> Source code in <code>SRToolkit/utils/measures.py</code> <pre><code>def tree_edit_distance(\n    expr1: Union[Node, List[str]],\n    expr2: Union[Node, List[str]],\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n) -&gt; int:\n    \"\"\"\n    Calculates the tree edit distance between two expressions.\n\n    Examples:\n        &gt;&gt;&gt; tree_edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"+\", \"1\"])\n        0\n        &gt;&gt;&gt; tree_edit_distance([\"X_0\", \"+\", \"1\"], [\"X_0\", \"-\", \"1\"])\n        1\n        &gt;&gt;&gt; tree_edit_distance(tokens_to_tree([\"X_0\", \"+\", \"1\"], SymbolLibrary.default_symbols(1)), tokens_to_tree([\"X_0\", \"-\", \"1\"], SymbolLibrary.default_symbols(1)))\n        1\n\n    Args:\n        expr1: Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        expr2: Expression given as a list of tokens in the infix notation or as an instance of SRToolkit.utils.expression_tree.Node\n        symbol_library: Symbol library to use when converting the lists of tokens into an instance of SRToolkit.utils.expression_tree.Node.\n\n    Returns:\n        The tree edit distance between the two expressions.\n    \"\"\"\n    if isinstance(expr1, Node):\n        expr1 = _expr_to_zss(expr1)\n    elif isinstance(expr1, list):\n        expr1 = _expr_to_zss(tokens_to_tree(expr1, symbol_library))\n\n    if isinstance(expr2, Node):\n        expr2 = _expr_to_zss(expr2)\n    elif isinstance(expr2, list):\n        expr2 = _expr_to_zss(tokens_to_tree(expr2, symbol_library))\n\n    return int(zss.simple_distance(expr1, expr2))\n</code></pre>"},{"location":"references/utils/measures/#SRToolkit.utils.measures.create_behavior_matrix","title":"create_behavior_matrix","text":"<pre><code>create_behavior_matrix(expr: Union[Node, List[str]], X: ndarray, num_consts_sampled: int = 32, consts_bounds: Tuple[float, float] = (-5, 5), symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(), seed: int = None) -&gt; np.ndarray\n</code></pre> <p>Creates a behavior matrix from an expression with free parameters. The shape of the matrix is (X.shape[0], num_consts_sampled).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.random.rand(10, 2) - 0.5\n&gt;&gt;&gt; create_behavior_matrix([\"X_0\", \"+\", \"C\"], X, num_consts_sampled=32).shape\n(10, 32)\n&gt;&gt;&gt; mean_0_1 = np.mean(create_behavior_matrix([\"X_0\", \"+\", \"C\"], X, num_consts_sampled=32, consts_bounds=(0, 1)))\n&gt;&gt;&gt; mean_1_5 = np.mean(create_behavior_matrix([\"X_0\", \"+\", \"C\"], X, num_consts_sampled=32, consts_bounds=(1, 5)))\n&gt;&gt;&gt; mean_0_1 &lt; mean_1_5\nTrue\n&gt;&gt;&gt; # Deterministic expressions always produce the same behavior matrix\n&gt;&gt;&gt; bm1 = create_behavior_matrix([\"X_0\", \"+\", \"X_1\"], X)\n&gt;&gt;&gt; bm2 = create_behavior_matrix([\"X_0\", \"+\", \"X_1\"], X)\n&gt;&gt;&gt; np.array_equal(bm1, bm2)\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr</code> <code>Union[Node, List[str]]</code> <p>An expression given as a list of tokens in the infix notation.</p> required <code>X</code> <code>ndarray</code> <p>Points on which the expression is evaluated to determine the behavior</p> required <code>num_consts_sampled</code> <code>int</code> <p>Number of sets of constants sampled</p> <code>32</code> <code>consts_bounds</code> <code>Tuple[float, float]</code> <p>Bounds between which constant values are sampled</p> <code>(-5, 5)</code> <code>symbol_library</code> <code>SymbolLibrary</code> <p>Symbol library used to transform the expression into an executable function.</p> <code>default_symbols()</code> <code>seed</code> <code>int</code> <p>Random seed. If None, generation will be random.</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If expr is not a list of tokens or an instance of SRToolkit.utils.expression_tree.Node.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>A matrix of size (X.shape[0], num_consts_sampled) that represents the behavior of an expression.</p> Source code in <code>SRToolkit/utils/measures.py</code> <pre><code>def create_behavior_matrix(\n    expr: Union[Node, List[str]],\n    X: np.ndarray,\n    num_consts_sampled: int = 32,\n    consts_bounds: Tuple[float, float] = (-5, 5),\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n    seed: int = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Creates a behavior matrix from an expression with free parameters. The shape of the matrix is (X.shape[0], num_consts_sampled).\n\n    Examples:\n        &gt;&gt;&gt; X = np.random.rand(10, 2) - 0.5\n        &gt;&gt;&gt; create_behavior_matrix([\"X_0\", \"+\", \"C\"], X, num_consts_sampled=32).shape\n        (10, 32)\n        &gt;&gt;&gt; mean_0_1 = np.mean(create_behavior_matrix([\"X_0\", \"+\", \"C\"], X, num_consts_sampled=32, consts_bounds=(0, 1)))\n        &gt;&gt;&gt; mean_1_5 = np.mean(create_behavior_matrix([\"X_0\", \"+\", \"C\"], X, num_consts_sampled=32, consts_bounds=(1, 5)))\n        &gt;&gt;&gt; mean_0_1 &lt; mean_1_5\n        True\n        &gt;&gt;&gt; # Deterministic expressions always produce the same behavior matrix\n        &gt;&gt;&gt; bm1 = create_behavior_matrix([\"X_0\", \"+\", \"X_1\"], X)\n        &gt;&gt;&gt; bm2 = create_behavior_matrix([\"X_0\", \"+\", \"X_1\"], X)\n        &gt;&gt;&gt; np.array_equal(bm1, bm2)\n        True\n\n\n    Args:\n        expr: An expression given as a list of tokens in the infix notation.\n        X: Points on which the expression is evaluated to determine the behavior\n        num_consts_sampled: Number of sets of constants sampled\n        consts_bounds: Bounds between which constant values are sampled\n        symbol_library: Symbol library used to transform the expression into an executable function.\n        seed: Random seed. If None, generation will be random.\n\n    Raises:\n        Exception: If expr is not a list of tokens or an instance of SRToolkit.utils.expression_tree.Node.\n\n    Returns:\n        A matrix of size (X.shape[0], num_consts_sampled) that represents the behavior of an expression.\n    \"\"\"\n    if isinstance(expr, list):\n        num_constants = expr.count(\"C\")\n    elif isinstance(expr, Node):\n        num_constants = expr.to_list(notation=\"postfix\").count(\"C\")\n    else:\n        raise Exception(\"Expression should be a list of strings (tokens) or a Node\")\n\n    expr = expr_to_executable_function(expr, symbol_library)\n\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\", over=\"ignore\", under=\"ignore\"):\n        if num_constants &gt; 0:\n            lho = LatinHypercube(num_constants, seed=seed)\n            constants = (\n                lho.random(num_consts_sampled) * (consts_bounds[1] - consts_bounds[0])\n                + consts_bounds[0]\n            )\n            ys = []\n            for c in constants:\n                ys.append(expr(X, c))\n            return np.array(ys).T\n        else:\n            return np.repeat(expr(X, None)[:, None], num_consts_sampled, axis=1)\n</code></pre>"},{"location":"references/utils/measures/#SRToolkit.utils.measures.bed","title":"bed","text":"<pre><code>bed(expr1: Union[Node, List[str], ndarray], expr2: Union[Node, List[str], ndarray], X: Optional[ndarray] = None, num_consts_sampled: int = 32, num_points_sampled: int = 64, domain_bounds: Optional[List[Tuple[float, float]]] = None, consts_bounds: Tuple[float, float] = (-5, 5), symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(), seed: int = None) -&gt; float\n</code></pre> <p>Computes the Behavioral Embedding Distance (BED) between two expressions or behavior matrices over a given dataset or domain, using Wasserstein distance as a metric.</p> <p>The BED is computed either by using precomputed behavior matrices or by sampling points from a domain and evaluating the expressions over them.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.random.rand(10, 2) - 0.5\n&gt;&gt;&gt; expr1 = [\"X_0\", \"+\", \"C\"] # instances of SRToolkit.utils.expression_tree.Node work as well\n&gt;&gt;&gt; expr2 = [\"X_1\", \"+\", \"C\"]\n&gt;&gt;&gt; bed(expr1, expr2, X) &lt; 1\nTrue\n&gt;&gt;&gt; # Changing the number of sampled constants\n&gt;&gt;&gt; bed(expr1, expr2, X, num_consts_sampled=128, consts_bounds=(-2, 2)) &lt; 1\nTrue\n&gt;&gt;&gt; # Sampling X instead of giving it directly by defining a domain\n&gt;&gt;&gt; bed(expr1, expr2, domain_bounds=[(0, 1), (0, 1)]) &lt; 1\nTrue\n&gt;&gt;&gt; bed(expr1, expr2, domain_bounds=[(0, 1), (0, 1)], num_points_sampled=128) &lt; 1\nTrue\n&gt;&gt;&gt; # You can use behavior matrices instead of expressions (this has potential computational advantages if same expression is used multiple times)\n&gt;&gt;&gt; bm1 = create_behavior_matrix(expr1, X)\n&gt;&gt;&gt; bed(bm1, expr2, X) &lt; 1\nTrue\n&gt;&gt;&gt; bm2 = create_behavior_matrix(expr2, X)\n&gt;&gt;&gt; bed(bm1, bm2) &lt; 1\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expr1</code> <code>Union[Node, List[str], ndarray]</code> <p>The first expression or behavior matrix. If it is an expression, it must be provided as a Node or a list of string representations. If it is already a behavior matrix, it should be a numpy array of size (num_points_sampled, num_consts_sampled).</p> required <code>expr2</code> <code>Union[Node, List[str], ndarray]</code> <p>The second expression or behavior matrix. Similar to expr1, it should be either a Node, list of strings representing the expression, or a numpy array representing the behavior matrix.</p> required <code>X</code> <code>Optional[ndarray]</code> <p>Array of points over which behavior is evaluated. If not provided, the domain bounds parameter will be used to sample points.</p> <code>None</code> <code>num_consts_sampled</code> <code>int</code> <p>Number of constants sampled for behavior evaluation if expressions are given as Nodes or lists rather than matrices. Default is 32.</p> <code>32</code> <code>num_points_sampled</code> <code>int</code> <p>Number of points sampled from the domain if X is not provided. Default is 64.</p> <code>64</code> <code>domain_bounds</code> <code>Optional[List[Tuple[float, float]]]</code> <p>The bounds of the domain for sampling points when X is not given. Each tuple represents the lower and upper bounds for a domain feature (e.g., [(0, 1), (0, 2)]).</p> <code>None</code> <code>consts_bounds</code> <code>Tuple[float, float]</code> <p>The lower and upper bounds for sampling constants when evaluating expressions. Default is (-5, 5).</p> <code>(-5, 5)</code> <code>symbol_library</code> <code>SymbolLibrary</code> <p>The library of symbols used to parse and evaluate expressions. Default is the default symbol library from SymbolLibrary.</p> <code>default_symbols()</code> <code>seed</code> <code>int</code> <p>Seed for random number generation during sampling for deterministic results. Default is None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The mean Wasserstein distance computed between the behaviors of the two expressions or</p> <code>float</code> <p>matrices over the sampled points.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If X is not provided and domain_bounds is missing, this exception is raised to ensure proper sampling of points for behavior evaluation.</p> <code>AssertionError</code> <p>Raised when the shapes of the behavior matrices or sampling points do not match the expected dimensions.</p> Source code in <code>SRToolkit/utils/measures.py</code> <pre><code>def bed(\n    expr1: Union[Node, List[str], np.ndarray],\n    expr2: Union[Node, List[str], np.ndarray],\n    X: Optional[np.ndarray] = None,\n    num_consts_sampled: int = 32,\n    num_points_sampled: int = 64,\n    domain_bounds: Optional[List[Tuple[float, float]]] = None,\n    consts_bounds: Tuple[float, float] = (-5, 5),\n    symbol_library: SymbolLibrary = SymbolLibrary.default_symbols(),\n    seed: int = None,\n) -&gt; float:\n    \"\"\"\n    Computes the Behavioral Embedding Distance (BED) between two expressions or behavior matrices over a\n    given dataset or domain, using Wasserstein distance as a metric.\n\n    The BED is computed either by using precomputed behavior matrices or by sampling points from a\n    domain and evaluating the expressions over them.\n\n    Examples:\n        &gt;&gt;&gt; X = np.random.rand(10, 2) - 0.5\n        &gt;&gt;&gt; expr1 = [\"X_0\", \"+\", \"C\"] # instances of SRToolkit.utils.expression_tree.Node work as well\n        &gt;&gt;&gt; expr2 = [\"X_1\", \"+\", \"C\"]\n        &gt;&gt;&gt; bed(expr1, expr2, X) &lt; 1\n        True\n        &gt;&gt;&gt; # Changing the number of sampled constants\n        &gt;&gt;&gt; bed(expr1, expr2, X, num_consts_sampled=128, consts_bounds=(-2, 2)) &lt; 1\n        True\n        &gt;&gt;&gt; # Sampling X instead of giving it directly by defining a domain\n        &gt;&gt;&gt; bed(expr1, expr2, domain_bounds=[(0, 1), (0, 1)]) &lt; 1\n        True\n        &gt;&gt;&gt; bed(expr1, expr2, domain_bounds=[(0, 1), (0, 1)], num_points_sampled=128) &lt; 1\n        True\n        &gt;&gt;&gt; # You can use behavior matrices instead of expressions (this has potential computational advantages if same expression is used multiple times)\n        &gt;&gt;&gt; bm1 = create_behavior_matrix(expr1, X)\n        &gt;&gt;&gt; bed(bm1, expr2, X) &lt; 1\n        True\n        &gt;&gt;&gt; bm2 = create_behavior_matrix(expr2, X)\n        &gt;&gt;&gt; bed(bm1, bm2) &lt; 1\n        True\n\n    Args:\n        expr1: The first expression or behavior matrix. If it is\n            an expression, it must be provided as a Node or a list of string representations. If it is\n            already a behavior matrix, it should be a numpy array of size (num_points_sampled, num_consts_sampled).\n        expr2: The second expression or behavior matrix. Similar\n            to expr1, it should be either a Node, list of strings representing the expression, or a\n            numpy array representing the behavior matrix.\n        X: Array of points over which behavior is evaluated. If not provided, the domain bounds parameter will be\n            used to sample points.\n        num_consts_sampled: Number of constants sampled for behavior evaluation if expressions\n            are given as Nodes or lists rather than matrices. Default is 32.\n        num_points_sampled: Number of points sampled from the domain if X is not provided. Default is 64.\n        domain_bounds: The bounds of the domain for sampling points when X is not given. Each tuple represents the\n            lower and upper bounds for a domain feature (e.g., [(0, 1), (0, 2)]).\n        consts_bounds: The lower and upper bounds for sampling constants when evaluating expressions. Default is (-5, 5).\n        symbol_library: The library of symbols used to parse and evaluate expressions. Default is the default symbol\n            library from SymbolLibrary.\n        seed: Seed for random number generation during sampling for deterministic results. Default is None.\n\n    Returns:\n        float: The mean Wasserstein distance computed between the behaviors of the two expressions or\n        matrices over the sampled points.\n\n    Raises:\n        Exception: If X is not provided and domain_bounds is missing, this exception is raised to\n            ensure proper sampling of points for behavior evaluation.\n        AssertionError: Raised when the shapes of the behavior matrices or sampling points do not match\n            the expected dimensions.\n    \"\"\"\n\n    if (\n        X is None\n        and not isinstance(expr1, np.ndarray)\n        and not isinstance(expr2, np.ndarray)\n    ):\n        if domain_bounds is None:\n            raise Exception(\n                \"If X is not given and both expressions are not given as a behavior matrix, \"\n                \"then domain_bounds parameter must be given\"\n            )\n        interval_length = np.array([ub - lb for (lb, ub) in domain_bounds])\n        lower_bound = np.array([lb for (lb, ub) in domain_bounds])\n        lho = LatinHypercube(len(domain_bounds), optimization=\"random-cd\", seed=seed)\n        X = lho.random(num_points_sampled) * interval_length + lower_bound\n    elif X is None and (isinstance(expr1, np.ndarray) != isinstance(expr2, np.ndarray)):\n        raise Exception(\n            \"If X is not given, both expressions must be given as a behavior matrix or as a list of \"\n            \"tokens/SRToolkit.utils.Node objects. Otherwise, behavior matrices are uncomparable.\"\n        )\n\n    if isinstance(expr1, list) or isinstance(expr1, Node):\n        expr1 = create_behavior_matrix(\n            expr1, X, num_consts_sampled, consts_bounds, symbol_library, seed\n        )\n\n    if isinstance(expr2, list) or isinstance(expr2, Node):\n        expr2 = create_behavior_matrix(\n            expr2, X, num_consts_sampled, consts_bounds, symbol_library, seed\n        )\n\n    assert expr1.shape[0] == expr2.shape[0], (\n        \"Behavior matrices must have the same number rows (points \"\n        \"on which behavior is evaluated.)\"\n    )\n    assert expr1.shape[0] &gt; 0, (\n        \"Behavior matrices must have at least one row. if your expressions are given as behavior\"\n        \"matrices, make sure they are not empty. Otherwise, if X is given, make sure it contains\"\n        \"at least one point. If X is not given, make sure num_points_sampled is greater than 0.\"\n    )\n    wds = []\n    for i in range(expr1.shape[0]):\n        u = expr1[i][np.isfinite(expr1[i])]\n        v = expr2[i][np.isfinite(expr2[i])]\n        if u.shape[0] &gt; 0 and v.shape[0] &gt; 0:\n            wds.append(_custom_wasserstein(u, v))\n        elif u.shape[0] == 0 and v.shape[0] == 0:\n            wds.append(0)\n        else:\n            wds.append(np.inf)\n\n    return float(np.mean(wds))\n</code></pre>"},{"location":"references/utils/symbol_library/","title":"Symbol Library","text":""},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library","title":"SRToolkit.utils.symbol_library","text":"<p>This module contains the SymbolLibrary class, which is used for managing symbols and their properties.</p>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary","title":"SymbolLibrary","text":"<pre><code>SymbolLibrary(symbols: List[str] = None, num_variables: int = 0, preamble: List[str] = None)\n</code></pre> <p>Initializes an instance of the SymbolLibrary class. This class is used for managing symbols and their properties for other functionality in this package.</p> <p>By default, the library uses the numpy package for inference of operators, functions, and numpy arrays as the data structure for data and constants. If you want to define these symbols using other libraries, you should populate the preamble argument with the import statements for those libraries.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\", \"x\")\n&gt;&gt;&gt; library.get_type(\"x\")\n'var'\n&gt;&gt;&gt; library.get_precedence(\"x\")\n0\n&gt;&gt;&gt; library.get_np_fn(\"x\")\n'x'\n&gt;&gt;&gt; library.remove_symbol(\"x\")\n&gt;&gt;&gt; library = SymbolLibrary.default_symbols()\n&gt;&gt;&gt; # You can also initialize the library with a list of symbols (listed in SymbolLibrary.default_symbols)\n&gt;&gt;&gt; # and the number of variables.\n&gt;&gt;&gt; library2 = SymbolLibrary([\"+\", \"*\", \"sin\"], num_variables=2)\n&gt;&gt;&gt; len(library2)\n5\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>List[str]</code> <p>A list of symbols to be added to the library. If None, the library is initialized with no symbols. Check the SymbolLibrary.default_symbols() function for a list of supported symbols.</p> <code>None</code> <code>num_variables</code> <code>int</code> <p>The number of variables to add to the library. If None, the library is initialized with ] no variables. Variables added this way will be labeled 'X_0', 'X_1', ..., 'X_{num_variables-1}'.</p> <code>0</code> <code>preamble</code> <code>List[str]</code> <p>A list of import statements for libraries used in the preamble of the generated function. If None, the preamble is set to [\"import numpy as np\"].</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>symbols</code> <p>dict A dictionary mapping symbols to their properties (type, precedence, numpy function).</p> <p>Functions:</p> Name Description <code>add_symbol</code> <p>Adds a symbol to the library.</p> <code>remove_symbol</code> <p>Removes a symbol from the library.</p> <code>get_type</code> <p>Retrieves the type of a symbol from the library.</p> <code>get_precedence</code> <p>Returns the precedence of the given symbol.</p> <code>get_np_fn</code> <p>Returns the numpy function corresponding to the given symbol.</p> <code>default_symbols</code> <p>Returns a SymbolLibrary with the default symbols.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def __init__(self, symbols: List[str]=None, num_variables: int = 0, preamble: List[str]=None):\n    \"\"\"\n    Initializes an instance of the SymbolLibrary class. This class is used for managing symbols and their\n    properties for other functionality in this package.\n\n    By default, the library uses the numpy package for inference of operators, functions, and numpy arrays as the\n    data structure for data and constants. If you want to define these symbols using other libraries, you should\n    populate the preamble argument with the import statements for those libraries.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\", \"x\")\n        &gt;&gt;&gt; library.get_type(\"x\")\n        'var'\n        &gt;&gt;&gt; library.get_precedence(\"x\")\n        0\n        &gt;&gt;&gt; library.get_np_fn(\"x\")\n        'x'\n        &gt;&gt;&gt; library.remove_symbol(\"x\")\n        &gt;&gt;&gt; library = SymbolLibrary.default_symbols()\n        &gt;&gt;&gt; # You can also initialize the library with a list of symbols (listed in SymbolLibrary.default_symbols)\n        &gt;&gt;&gt; # and the number of variables.\n        &gt;&gt;&gt; library2 = SymbolLibrary([\"+\", \"*\", \"sin\"], num_variables=2)\n        &gt;&gt;&gt; len(library2)\n        5\n\n    Args:\n        symbols: A list of symbols to be added to the library. If None, the library is initialized with no symbols.\n            Check the SymbolLibrary.default_symbols() function for a list of supported symbols.\n        num_variables: The number of variables to add to the library. If None, the library is initialized with ]\n            no variables. Variables added this way will be labeled 'X_0', 'X_1', ..., 'X_{num_variables-1}'.\n        preamble: A list of import statements for libraries used in the preamble of the generated function. If\n            None, the preamble is set to [\"import numpy as np\"].\n\n    Attributes:\n        symbols : dict\n            A dictionary mapping symbols to their properties (type, precedence, numpy function).\n\n    Methods:\n        add_symbol(symbol, symbol_type, precedence, np_fn):\n            Adds a symbol to the library.\n        remove_symbol(symbol):\n            Removes a symbol from the library.\n        get_type(symbol):\n            Retrieves the type of a symbol from the library.\n        get_precedence(symbol):\n            Returns the precedence of the given symbol.\n        get_np_fn(symbol):\n            Returns the numpy function corresponding to the given symbol.\n        default_symbols():\n            Returns a SymbolLibrary with the default symbols.\n    \"\"\"\n    if preamble is None:\n        self.preamble = [\"import numpy as np\"]\n    else:\n        self.preamble = preamble\n\n    if symbols is None and num_variables == 0:\n        self.symbols = dict()\n        self.num_variables = 0\n    else:\n        if symbols is None:\n            symbols = []\n\n        self.symbols = SymbolLibrary.from_symbol_list(symbols, num_variables).symbols\n        self.num_variables = num_variables\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.add_symbol","title":"add_symbol","text":"<pre><code>add_symbol(symbol: str, symbol_type: str, precedence: int, np_fn: str, latex_str: str = None)\n</code></pre> <p>Adds a symbol to the library. A symbol should have a type, precedence, a numpy function, and a LaTeX template associated with it. Type \"op\" should be used for symbols operating on two operands, \"fn\" for symbols operating on one operand, \"lit\" for constants with a known value (such as pi or e), \"const\" for constants/parameters without a value that need to be optimized, and \"var\" for variables whose values are provided as input data.</p> <p>We recommend you use a single token of \"const\" type as using multiple might lead to more work, errors, and less readability.</p> <p>If the argument 'latex_str' is ommited, a default LaTeX template will be generated for the symbol. In case of symbol 'symb', the default template will be '{} \\text{symb} {}' for an operator,'\\text{symb} {}' for a function, and '\\text{symb}' otherwise.</p> <p>For example, look at the default_symbols function for the SymbolLibrary class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; library.add_symbol(\"sin\", \"fn\", 5, \"np.sin({})\", r\"\\sin {}\")\n&gt;&gt;&gt; library.add_symbol(\"C\", \"const\", 5, \"C[{}]\", r\"c_{}\")\n&gt;&gt;&gt; library.add_symbol(\"X_0\", \"var\", 5, \"X[:, 0]\", r\"X_0\")\n&gt;&gt;&gt; library.add_symbol(\"pi\", \"lit\", 5, \"np.pi\", r\"\\pi\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol to be added to the library.</p> required <code>symbol_type</code> <code>str</code> <p>The type of the symbol, one of \"op\" (operator), \"fn\" (function), \"lit\" (literal), \"const\" (constant), or \"var\" (variable).</p> required <code>precedence</code> <code>int</code> <p>The precedence of the symbol, used to determine the order of operations.</p> required <code>np_fn</code> <code>str</code> <p>A string representing the numpy function associated with this symbol.</p> required <code>latex_str</code> <code>str</code> <p>A string that represents how the symbol is written in LaTeX</p> <code>None</code> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def add_symbol(\n    self,\n    symbol: str,\n    symbol_type: str,\n    precedence: int,\n    np_fn: str,\n    latex_str: str = None,\n):\n    r\"\"\"\n    Adds a symbol to the library. A symbol should have a type, precedence, a numpy function, and a LaTeX template associated with it.\n    Type \"op\" should be used for symbols operating on two operands, \"fn\" for symbols operating on one operand,\n    \"lit\" for constants with a known value (such as pi or e), \"const\" for constants/parameters without a value that\n    need to be optimized, and \"var\" for variables whose values are provided as input data.\n\n    We recommend you use a single token of \"const\" type as using multiple might lead to more work, errors, and less\n    readability.\n\n    If the argument 'latex_str' is ommited, a default LaTeX template will be generated for the symbol. In case of symbol 'symb', the default template\n    will be '{} \\text{symb} {}' for an operator,'\\text{symb} {}' for a function, and '\\text{symb}' otherwise.\n\n    For example, look at the default_symbols function for the SymbolLibrary class.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; library.add_symbol(\"sin\", \"fn\", 5, \"np.sin({})\", r\"\\sin {}\")\n        &gt;&gt;&gt; library.add_symbol(\"C\", \"const\", 5, \"C[{}]\", r\"c_{}\")\n        &gt;&gt;&gt; library.add_symbol(\"X_0\", \"var\", 5, \"X[:, 0]\", r\"X_0\")\n        &gt;&gt;&gt; library.add_symbol(\"pi\", \"lit\", 5, \"np.pi\", r\"\\pi\")\n\n    Args:\n        symbol: The symbol to be added to the library.\n        symbol_type: The type of the symbol, one of \"op\" (operator), \"fn\" (function), \"lit\" (literal), \"const\" (constant), or \"var\" (variable).\n        precedence: The precedence of the symbol, used to determine the order of operations.\n        np_fn: A string representing the numpy function associated with this symbol.\n        latex_str: A string that represents how the symbol is written in LaTeX\n    \"\"\"\n    if latex_str is None:\n        if symbol_type == \"var\":\n            latex_str = f\"{{}} \\text{{{symbol}}} {{}}\"\n        elif symbol_type == \"fn\":\n            latex_str = f\"\\text{{{symbol}}} {{}}\"\n        else:\n            latex_str = f\"\\text{{{symbol}}}\"\n\n    if symbol_type == \"var\" and (np_fn is None or np_fn == \"\"):\n        np_fn = \"X[:, {}]\".format(self.num_variables)\n\n    if symbol_type == \"var\":\n        self.num_variables += 1\n\n    self.symbols[symbol] = {\n        \"symbol\": symbol,\n        \"type\": symbol_type,\n        \"precedence\": precedence,\n        \"np_fn\": np_fn,\n        \"latex_str\": latex_str,\n    }\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.remove_symbol","title":"remove_symbol","text":"<pre><code>remove_symbol(symbol: str)\n</code></pre> <p>Removes a symbol from the library.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; len(library.symbols)\n1\n&gt;&gt;&gt; library.remove_symbol(\"x\")\n&gt;&gt;&gt; len(library.symbols)\n0\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol to be removed from the library.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If the symbol does not exist in the library.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def remove_symbol(self, symbol: str):\n    \"\"\"\n    Removes a symbol from the library.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; len(library.symbols)\n        1\n        &gt;&gt;&gt; library.remove_symbol(\"x\")\n        &gt;&gt;&gt; len(library.symbols)\n        0\n\n    Args:\n        symbol: The symbol to be removed from the library.\n\n    Raises:\n        KeyError: If the symbol does not exist in the library.\n    \"\"\"\n    del self.symbols[symbol]\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.get_type","title":"get_type","text":"<pre><code>get_type(symbol: str) -&gt; str\n</code></pre> <p>Retrieves the type of a symbol from the library.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; library.get_type(\"x\")\n'var'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol whose type is to be retrieved.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The type of the symbol if it exists in the library, otherwise an empty string.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def get_type(self, symbol: str) -&gt; str:\n    \"\"\"\n    Retrieves the type of a symbol from the library.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; library.get_type(\"x\")\n        'var'\n\n    Args:\n        symbol: The symbol whose type is to be retrieved.\n\n    Returns:\n        The type of the symbol if it exists in the library, otherwise an empty string.\n    \"\"\"\n    if symbol in self.symbols:\n        return self.symbols[symbol][\"type\"]\n    else:\n        return \"\"\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.get_precedence","title":"get_precedence","text":"<pre><code>get_precedence(symbol: str) -&gt; int\n</code></pre> <p>Retrieves the precedence of the given symbol.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; library.get_precedence(\"x\")\n0\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol whose precedence is to be retrieved.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The precedence of the symbol if it exists in the library, otherwise -1.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def get_precedence(self, symbol: str) -&gt; int:\n    \"\"\"\n    Retrieves the precedence of the given symbol.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; library.get_precedence(\"x\")\n        0\n\n    Args:\n        symbol: The symbol whose precedence is to be retrieved.\n\n    Returns:\n        The precedence of the symbol if it exists in the library, otherwise -1.\n    \"\"\"\n    if symbol in self.symbols:\n        return self.symbols[symbol][\"precedence\"]\n    else:\n        return -1\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.get_np_fn","title":"get_np_fn","text":"<pre><code>get_np_fn(symbol: str) -&gt; str\n</code></pre> <p>Returns the numpy function corresponding to the given symbol.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; library.get_np_fn(\"x\")\n'x'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol to look up.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The numpy function corresponding to the given symbol, or an empty string if the symbol was not found.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def get_np_fn(self, symbol: str) -&gt; str:\n    \"\"\"\n    Returns the numpy function corresponding to the given symbol.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; library.get_np_fn(\"x\")\n        'x'\n\n    Args:\n        symbol: The symbol to look up.\n\n    Returns:\n        The numpy function corresponding to the given symbol, or an empty string if the symbol was not found.\n    \"\"\"\n    if symbol in self.symbols:\n        return self.symbols[symbol][\"np_fn\"]\n    else:\n        return \"\"\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.get_latex_str","title":"get_latex_str","text":"<pre><code>get_latex_str(symbol: str) -&gt; str\n</code></pre> <p>Returns the LaTeX template for the corresponding symbol.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\", \"test\")\n&gt;&gt;&gt; library.get_latex_str(\"x\")\n'test'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The symbol to look up.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The LaTeX template for the corresponding symbol, or an empty string if the symbol was not found.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def get_latex_str(self, symbol: str) -&gt; str:\n    \"\"\"\n    Returns the LaTeX template for the corresponding symbol.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\", \"test\")\n        &gt;&gt;&gt; library.get_latex_str(\"x\")\n        'test'\n\n    Args:\n        symbol: The symbol to look up.\n\n    Returns:\n        The LaTeX template for the corresponding symbol, or an empty string if the symbol was not found.\n    \"\"\"\n    if symbol in self.symbols:\n        return self.symbols[symbol][\"latex_str\"]\n    else:\n        return \"\"\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.get_symbols_of_type","title":"get_symbols_of_type","text":"<pre><code>get_symbols_of_type(symbol_type: str) -&gt; List[str]\n</code></pre> <p>Returns a list of symbols with the requested type (\"op\", \"fn\", \"var\", \"const\", \"lit\").</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; library.add_symbol(\"y\", \"var\", 0, \"y\")\n&gt;&gt;&gt; library.get_symbols_of_type(\"var\")\n['x', 'y']\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbol_type</code> <code>str</code> <p>Type of symbols you want to get.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of symbols with the requested type</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def get_symbols_of_type(self, symbol_type: str) -&gt; List[str]:\n    \"\"\"\n    Returns a list of symbols with the requested type (\"op\", \"fn\", \"var\", \"const\", \"lit\").\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; library.add_symbol(\"y\", \"var\", 0, \"y\")\n        &gt;&gt;&gt; library.get_symbols_of_type(\"var\")\n        ['x', 'y']\n\n    Args:\n        symbol_type: Type of symbols you want to get.\n\n    Returns:\n        A list of symbols with the requested type\n    \"\"\"\n    symbols = list()\n    for symbol in self.symbols.keys():\n        if self.get_type(symbol) == symbol_type:\n            symbols.append(symbol)\n\n    return symbols\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.symbols2index","title":"symbols2index","text":"<pre><code>symbols2index() -&gt; Dict[str, int]\n</code></pre> <p>Generates a dictionary mapping symbols to their indices in the symbol list.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n&gt;&gt;&gt; library.add_symbol(\"y\", \"var\", 0, \"y\")\n&gt;&gt;&gt; print(library.symbols2index())\n{'x': 0, 'y': 1}\n&gt;&gt;&gt; library.remove_symbol(\"x\")\n&gt;&gt;&gt; print(library.symbols2index())\n{'y': 0}\n</code></pre> <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>A dictionary mapping symbols to their indices in the symbol list.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def symbols2index(self) -&gt; Dict[str, int]:\n    \"\"\"\n    Generates a dictionary mapping symbols to their indices in the symbol list.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\")\n        &gt;&gt;&gt; library.add_symbol(\"y\", \"var\", 0, \"y\")\n        &gt;&gt;&gt; print(library.symbols2index())\n        {'x': 0, 'y': 1}\n        &gt;&gt;&gt; library.remove_symbol(\"x\")\n        &gt;&gt;&gt; print(library.symbols2index())\n        {'y': 0}\n\n    Returns:\n        A dictionary mapping symbols to their indices in the symbol list.\n    \"\"\"\n    return {s: i for i, s in enumerate(self.symbols.keys())}\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.from_symbol_list","title":"from_symbol_list  <code>staticmethod</code>","text":"<pre><code>from_symbol_list(symbols: List[str], num_variables: int = 25) -&gt; SymbolLibrary\n</code></pre> <p>Creates an instance of SymbolLibrary from a list of symbols and number of variables. The list of currently supported symbols (by default) can be seen in the SymbolLibrary.default_symbols() function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary().from_symbol_list([\"+\", \"*\", \"C\"], num_variables=2)\n&gt;&gt;&gt; len(library.symbols)\n5\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>symbols</code> <code>List[str]</code> <p>List of symbols you want.</p> required <code>num_variables</code> <code>int</code> <p>Number of variables you want.</p> <code>25</code> <p>Returns:</p> Type Description <code>SymbolLibrary</code> <p>An instance of SymbolLibrary</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>@staticmethod\ndef from_symbol_list(\n    symbols: List[str], num_variables: int = 25\n) -&gt; \"SymbolLibrary\":\n    \"\"\"\n    Creates an instance of SymbolLibrary from a list of symbols and number of variables. The list of currently\n    supported symbols (by default) can be seen in the SymbolLibrary.default_symbols() function.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary().from_symbol_list([\"+\", \"*\", \"C\"], num_variables=2)\n        &gt;&gt;&gt; len(library.symbols)\n        5\n\n    Args:\n        symbols: List of symbols you want.\n        num_variables: Number of variables you want.\n\n    Returns:\n        An instance of SymbolLibrary\n    \"\"\"\n    variables = [f\"X_{i}\" for i in range(num_variables)]\n    symbols = symbols + variables\n\n    sl = SymbolLibrary.default_symbols(num_variables)\n\n    all_symbols = list(sl.symbols.keys())\n    for symbol in all_symbols:\n        if symbol not in symbols:\n            sl.remove_symbol(symbol)\n\n    return sl\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.default_symbols","title":"default_symbols  <code>staticmethod</code>","text":"<pre><code>default_symbols(num_variables: int = 25) -&gt; SymbolLibrary\n</code></pre> <p>Creates a SymbolLibrary instance populated with default mathematical symbols.</p> <p>This method adds a set of predefined symbols to a SymbolLibrary instance, representing common mathematical operations, functions, constants, and optional variables. The symbols include basic arithmetic operations, trigonometric and exponential functions, and mathematical constants like pi and e.</p> <p>If num_variables is greater than 0, it adds variables labeled 'X_0' to 'X_{num_variables-1}', each  associated with a column in a data array X.</p> <p>By default, we currently support the following symbols: \"+\", \"-\", \"*\", \"/\", \"^\", \"u-\" (unary minus), \"sqrt\", \"sin\", \"cos\", \"exp\", \"tan\", \"arcsin\", \"arccos\", \"arctan\", \"sinh\", \"cosh\", \"tanh\", \"floor\", \"ceil\", \"ln\", \"log\", \"^-1\", \"^2\", \"^3\", \"^4\", \"^5\", \"pi\", \"e\", \"C\" (unknown constant).</p> <p>Notes: The variables in the default_symbols function are added in the predefined order, which is the same order as the columns in the data array X.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary.default_symbols()\n&gt;&gt;&gt; len(library.symbols)\n54\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>num_variables</code> <code>int</code> <p>The number of variables to add to the library (default is 25).</p> <code>25</code> <p>Returns:</p> Type Description <code>SymbolLibrary</code> <p>A SymbolLibrary instance populated with default mathematical symbols.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>@staticmethod\ndef default_symbols(num_variables: int = 25) -&gt; \"SymbolLibrary\":\n    \"\"\"\n    Creates a SymbolLibrary instance populated with default mathematical symbols.\n\n    This method adds a set of predefined symbols to a SymbolLibrary instance,\n    representing common mathematical operations, functions, constants, and optional\n    variables. The symbols include basic arithmetic operations, trigonometric and\n    exponential functions, and mathematical constants like pi and e.\n\n    If num_variables is greater than 0, it adds variables labeled 'X_0' to 'X_{num_variables-1}', each\n     associated with a column in a data array X.\n\n    By default, we currently support the following symbols: \"+\", \"-\", \"*\", \"/\", \"^\", \"u-\" (unary minus), \"sqrt\",\n    \"sin\", \"cos\", \"exp\", \"tan\", \"arcsin\", \"arccos\", \"arctan\", \"sinh\", \"cosh\", \"tanh\", \"floor\", \"ceil\", \"ln\", \"log\",\n    \"^-1\", \"^2\", \"^3\", \"^4\", \"^5\", \"pi\", \"e\", \"C\" (unknown constant).\n\n    Notes: The variables in the default_symbols function are added in the predefined order,\n    which is the same order as the columns in the data array X.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary.default_symbols()\n        &gt;&gt;&gt; len(library.symbols)\n        54\n\n    Args:\n        num_variables: The number of variables to add to the library (default is 25).\n\n    Returns:\n        A SymbolLibrary instance populated with default mathematical symbols.\n    \"\"\"\n    sl = SymbolLibrary()\n    sl.add_symbol(\n        \"+\",\n        symbol_type=\"op\",\n        precedence=0,\n        np_fn=\"{} = {} + {}\",\n        latex_str=r\"{} + {}\",\n    )\n    sl.add_symbol(\n        \"-\",\n        symbol_type=\"op\",\n        precedence=0,\n        np_fn=\"{} = {} - {}\",\n        latex_str=r\"{} - {}\",\n    )\n    sl.add_symbol(\n        \"*\",\n        symbol_type=\"op\",\n        precedence=1,\n        np_fn=\"{} = {} * {}\",\n        latex_str=r\"{} \\cdot {}\",\n    )\n    sl.add_symbol(\n        \"/\",\n        symbol_type=\"op\",\n        precedence=1,\n        np_fn=\"{} = {} / {}\",\n        latex_str=r\"\\frac{{{}}}{{{}}}\",\n    )\n    sl.add_symbol(\n        \"^\",\n        symbol_type=\"op\",\n        precedence=2,\n        np_fn=\"{} = np.power({},{})\",\n        latex_str=r\"{}^{{{}}}\",\n    )\n    sl.add_symbol(\n        \"u-\", symbol_type=\"fn\", precedence=5, np_fn=\"{} = -{}\", latex_str=r\"- {}\"\n    )\n    sl.add_symbol(\n        \"sqrt\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.sqrt({})\",\n        latex_str=r\"\\sqrt {{{}}}\",\n    )\n    sl.add_symbol(\n        \"sin\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.sin({})\",\n        latex_str=r\"\\sin {}\",\n    )\n    sl.add_symbol(\n        \"cos\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.cos({})\",\n        latex_str=r\"\\cos {}\",\n    )\n    sl.add_symbol(\n        \"exp\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.exp({})\",\n        latex_str=r\"e^{{{}}}\",\n    )\n    sl.add_symbol(\n        \"tan\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.tan({})\",\n        latex_str=r\"\\tan {}\",\n    )\n    sl.add_symbol(\n        \"arcsin\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.arcsin({})\",\n        latex_str=r\"\\arcsin {}\",\n    )\n    sl.add_symbol(\n        \"arccos\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.arccos({})\",\n        latex_str=r\"\\arccos {}\",\n    )\n    sl.add_symbol(\n        \"arctan\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.arctan({})\",\n        latex_str=r\"\\arctan {}\",\n    )\n    sl.add_symbol(\n        \"sinh\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.sinh({})\",\n        latex_str=r\"\\sinh {}\",\n    )\n    sl.add_symbol(\n        \"cosh\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.cosh({})\",\n        latex_str=r\"\\cosh {}\",\n    )\n    sl.add_symbol(\n        \"tanh\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.tanh({})\",\n        latex_str=r\"\\tanh {}\",\n    )\n    sl.add_symbol(\n        \"floor\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.floor({})\",\n        latex_str=r\"\\lfloor {} \\rfloor\",\n    )\n    sl.add_symbol(\n        \"ceil\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.ceil({})\",\n        latex_str=r\"\\lceil {} \\rceil\",\n    )\n    sl.add_symbol(\n        \"ln\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.log({})\",\n        latex_str=r\"\\ln {}\",\n    )\n    sl.add_symbol(\n        \"log\",\n        symbol_type=\"fn\",\n        precedence=5,\n        np_fn=\"{} = np.log10({})\",\n        latex_str=r\"\\log_{{10}} {}\",\n    )\n    sl.add_symbol(\n        \"^-1\",\n        symbol_type=\"fn\",\n        precedence=-1,\n        np_fn=\"{} = 1/{}\",\n        latex_str=r\"{}^{{-1}}\",\n    )\n    sl.add_symbol(\n        \"^2\", symbol_type=\"fn\", precedence=-1, np_fn=\"{} = {}**2\", latex_str=r\"{}^2\"\n    )\n    sl.add_symbol(\n        \"^3\", symbol_type=\"fn\", precedence=-1, np_fn=\"{} = {}**3\", latex_str=r\"{}^3\"\n    )\n    sl.add_symbol(\n        \"^4\", symbol_type=\"fn\", precedence=-1, np_fn=\"{} = {}**4\", latex_str=r\"{}^4\"\n    )\n    sl.add_symbol(\n        \"^5\", symbol_type=\"fn\", precedence=-1, np_fn=\"{} = {}**5\", latex_str=r\"{}^5\"\n    )\n    sl.add_symbol(\n        \"pi\",\n        symbol_type=\"lit\",\n        precedence=5,\n        np_fn=\"np.full(X.shape[0], np.pi)\",\n        latex_str=r\"\\pi\",\n    )\n    sl.add_symbol(\n        \"e\",\n        symbol_type=\"lit\",\n        precedence=5,\n        np_fn=\"np.full(X.shape[0], np.e)\",\n        latex_str=r\"e\",\n    )\n    sl.add_symbol(\n        \"C\",\n        symbol_type=\"const\",\n        precedence=5,\n        np_fn=\"np.full(X.shape[0], C[{}])\",\n        latex_str=r\"C_{{{}}}\",\n    )\n\n    if num_variables &gt; 0:\n        for i in range(num_variables):\n            sl.add_symbol(\n                f\"X_{i}\", \"var\", 5, \"X[:, {}]\".format(i), \"X_{{{}}}\".format(i)\n            )\n\n    return sl\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict\n</code></pre> <p>Creates a dictionary representation of the SymbolLibrary instance.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the symbol library's data.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"\n    Creates a dictionary representation of the SymbolLibrary instance.\n\n    Returns:\n        A dictionary containing the symbol library's data.\n    \"\"\"\n    return {\"type\": \"SymbolLibrary\",\n            \"symbols\": self.symbols,\n            \"preamble\": self.preamble,\n            \"num_variables\": self.num_variables}\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.from_dict","title":"from_dict  <code>staticmethod</code>","text":"<pre><code>from_dict(d: dict) -&gt; SymbolLibrary\n</code></pre> <p>Creates a SymbolLibrary instance from its dictionary representation.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>the dictionary containing data about the symbol library.</p> required <p>Returns:</p> Type Description <code>SymbolLibrary</code> <p>The SymbolLibrary instance created from the dictionary.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>@staticmethod\ndef from_dict(d: dict) -&gt; \"SymbolLibrary\":\n    \"\"\"\n    Creates a SymbolLibrary instance from its dictionary representation.\n\n    Args:\n        d: the dictionary containing data about the symbol library.\n\n    Returns:\n        The SymbolLibrary instance created from the dictionary.\n    \"\"\"\n    sl = SymbolLibrary()\n    sl.symbols = d[\"symbols\"]\n    sl.preamble = d[\"preamble\"]\n    sl.num_variables = d[\"num_variables\"]\n    return sl\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Returns the number of symbols currently stored in the SymbolLibrary.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary.default_symbols(5)\n&gt;&gt;&gt; len(library)\n34\n&gt;&gt;&gt; library.add_symbol(\"a\", \"lit\", 5, \"a\", \"a\")\n&gt;&gt;&gt; len(library)\n35\n</code></pre> <p>Returns     Number of symbols currently stored in the SymbolLibrary.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Returns the number of symbols currently stored in the SymbolLibrary.\n\n    Examples:\n         &gt;&gt;&gt; library = SymbolLibrary.default_symbols(5)\n         &gt;&gt;&gt; len(library)\n         34\n         &gt;&gt;&gt; library.add_symbol(\"a\", \"lit\", 5, \"a\", \"a\")\n         &gt;&gt;&gt; len(library)\n         35\n\n    Returns\n        Number of symbols currently stored in the SymbolLibrary.\n    \"\"\"\n    return len(self.symbols)\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Returns a string representation of the SymbolLibrary instance.</p> <p>This method provides a comma-separated string of all the symbol keys currently stored in the SymbolLibrary.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; library = SymbolLibrary()\n&gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\", \"x\")\n&gt;&gt;&gt; str(library)\n'x'\n&gt;&gt;&gt; library.add_symbol(\"sin\", \"fn\", 5, \"{} = np.sin({})\", r\"\\sin {}\")\n&gt;&gt;&gt; str(library)\n'x, sin'\n</code></pre> <p>Returns:</p> Type Description <code>str</code> <p>A string containing all symbols in the library, separated by commas.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def __str__(self) -&gt; str:\n    r\"\"\"\n    Returns a string representation of the SymbolLibrary instance.\n\n    This method provides a comma-separated string of all the symbol keys\n    currently stored in the SymbolLibrary.\n\n    Examples:\n        &gt;&gt;&gt; library = SymbolLibrary()\n        &gt;&gt;&gt; library.add_symbol(\"x\", \"var\", 0, \"x\", \"x\")\n        &gt;&gt;&gt; str(library)\n        'x'\n        &gt;&gt;&gt; library.add_symbol(\"sin\", \"fn\", 5, \"{} = np.sin({})\", r\"\\sin {}\")\n        &gt;&gt;&gt; str(library)\n        'x, sin'\n\n    Returns:\n        A string containing all symbols in the library, separated by commas.\n    \"\"\"\n    return \", \".join(self.symbols.keys())\n</code></pre>"},{"location":"references/utils/symbol_library/#SRToolkit.utils.symbol_library.SymbolLibrary.__copy__","title":"__copy__","text":"<pre><code>__copy__() -&gt; SymbolLibrary\n</code></pre> <p>Creates a copy of the SymbolLibrary instance.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; old_symbols = SymbolLibrary()\n&gt;&gt;&gt; old_symbols.add_symbol(\"x\", \"var\", 0, \"x\", \"x\")\n&gt;&gt;&gt; print(old_symbols)\nx\n&gt;&gt;&gt; new_symbols = copy.copy(old_symbols)\n&gt;&gt;&gt; new_symbols.add_symbol(\"sin\", \"fn\", 5, \"{} = np.sin({})\", r\"\\sin {}\")\n&gt;&gt;&gt; print(old_symbols)\nx\n&gt;&gt;&gt; print(new_symbols)\nx, sin\n</code></pre> <p>Returns:</p> Type Description <code>SymbolLibrary</code> <p>A copy of the SymbolLibrary instance.</p> Source code in <code>SRToolkit/utils/symbol_library.py</code> <pre><code>def __copy__(self) -&gt; \"SymbolLibrary\":\n    r\"\"\"\n    Creates a copy of the SymbolLibrary instance.\n\n    Examples:\n        &gt;&gt;&gt; old_symbols = SymbolLibrary()\n        &gt;&gt;&gt; old_symbols.add_symbol(\"x\", \"var\", 0, \"x\", \"x\")\n        &gt;&gt;&gt; print(old_symbols)\n        x\n        &gt;&gt;&gt; new_symbols = copy.copy(old_symbols)\n        &gt;&gt;&gt; new_symbols.add_symbol(\"sin\", \"fn\", 5, \"{} = np.sin({})\", r\"\\sin {}\")\n        &gt;&gt;&gt; print(old_symbols)\n        x\n        &gt;&gt;&gt; print(new_symbols)\n        x, sin\n\n    Returns:\n        A copy of the SymbolLibrary instance.\n    \"\"\"\n    sl = SymbolLibrary()\n    sl.symbols = copy.deepcopy(self.symbols)\n    sl.preamble = self.preamble\n    sl.num_variables = self.num_variables\n    return sl\n</code></pre>"}]}